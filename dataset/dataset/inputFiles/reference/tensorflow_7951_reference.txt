 

We've noticed that one of the biggest challenges in getting started with TensorFlow is how to load your own data into your programs. While TensorFlow has several methods that can be used to build complex input pipelines such as LINKLINK, LINKLINK, etc. they were designed for a particular use case processing a static set of files repeatedly, and the average user experience with these methods is not great. For example:

 Once you reach the end of a pipeline, it becomes closed and you can never use it again in the same session. This requires users to use unnatural workarounds&mdash;with control flow or multiple sessions&mdash;to get a signal after processing an entire epoch, or switch between processing two datasets for example training and validation data in the same program.
 See 2514 and 4535 for feature requests about handling multiple epochs.
 See 7902 and numerous Stack Overflow questions for examples of processing different datasets in the same program.
 The current pipelines use TensorFlow queues and multiple Python threads, which can lead to poor performance lock contention in the queues and the Python GIL and hard to understand exceptions CODESCODES.
 See 6845 for a discussion of input pipeline performance.
 See 7525 and LINKLINK for an example of the confusing error.
 The pipelines behave poorly if you forget to call CODESCODES: in fact, they hang indefinitely and deadlock the user program.
 See 7945 and LINKLINK for some examples of users who have been bitten by this problem.

We're decided to start from a clean slate and redesign the input pipeline API. The existing methods will remain until TF 2.0 at least, but we are planning to add a new set of methods for loading and manipulating datasets. We're still preparing a detailed design, which we plan to share soon, but we anticipate that there will be two new APIs:

 A CODESCODES represents a collection of data elements. Each element can be a tuple of one or more tensors for example an image and its label. We will provide methods for creating datasets from tensors, and deriving them from another dataset for example by slicing its elements, repeating its elements, shuffling its elements, batching its elements, mapping a function over its elements, etc. 
 An CODESCODES can be created from a CODESCODES. An iterator represents the current position within a dataset, and exposes an operation like CODESCODES that can be run to get the next element. There will be explicit operations for initializing an iterator, so that it can be reused after you have processed all of the elements in a dataset.

A similar pattern turns up in many different settings, including LINKLINK, LINKLINK and hence Spark's RDDs, and LINKLINK.

We're announcing this plan early because we want to collect feedback on what features you&mdash;as TensorFlow users&mdash;would like to see in an input pipeline API. What other pain points have we missed? What features do you miss from other systems? What other suggestions do you have?

We look forward to hearing from you!