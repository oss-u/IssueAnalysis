building 0 [CLS] [SEP] 19b2 on debian ubuntus [CLS] [SEP] still ongoing but I see consistent failure on Debian stretch nd90, current stable and testing nd100, 32bit only ok on amd64 build: CODELCODEL. in both cases python numpy is CODESCODES for example 1 [CLS] [SEP] 12 [CLS] [SEP] 1 numpy and passed ok with numpy 1 [CLS] [SEP] 2 in Debian jessie [CLS] [SEP] ping ogrisel [CLS] [SEP] Interesting, it's a only on a combo of numpy 1 [CLS] [SEP] 12 [CLS] [SEP] 1 and 32 bit python [CLS] [SEP] Those tests pass with 32 bit python and numpy 1 [CLS] [SEP] 13 [CLS] [SEP] 1 on our wheel building travis: LINKLINK. tomMoral if you want to play with docker, this is a good opportunity thumbs up ogrisel I will give it a try thumbs up yarikoptic I am unable to reproduce the failure on 32bit debian CODESCODES on docker [CLS] [SEP] I tried installing python and scikit dependency using CODESCODES and the test passed for both CODESCODES and CODESCODES [CLS] [SEP] Do you have a specific configuration that could explain the difference [CLS] [SEP] yarikoptic tomMoral how can you install numpy 1 [CLS] [SEP] 12 [CLS] [SEP] 1 on debian stretch [CLS] [SEP] Which repo did you use to produce this failure [CLS] [SEP] ogrisel I installed the CODESCODES package, which uses version 1 [CLS] [SEP] 12 [CLS] [SEP] 1 and used branch CODESCODES for CODESCODES [CLS] [SEP] EDIT: I used this docker image: CODESCODES Indeed I was using an older image jessie [CLS] [SEP] I confirm I cannot reproduce the issue on stretch with the following 32 bit image: CODESCODES [CLS] [SEP] yarikoptic, we would like to release [CLS] [SEP] We need a way to reproduce the error, or we will need to skip the tests lower the condition on certain architectures [CLS] [SEP] oh I have managed to miss your message jnothman and 0 [CLS] [SEP] 13 [CLS] [SEP] 0 came out without the fix, my bad [CLS] [SEP] I will release debian packages as is without i386 build for some and later give you exact instruction on how to reproduce [CLS] [SEP] FWIW issue in general reproducible: LINKLINK check i386 build and some other builds have other issues btw that was in beta let's wait for current release to get built in unstable before summarizing coming up issues on some other architectures Right [CLS] [SEP] I see in the logs there an alarming number of fails for a final release thumbs down. And none of them are about CODESCODES. CODELCODEL The last is the most confusing to me tbh [CLS] [SEP] yeah, that 32bit issue didn't reproduce in current build [CLS] [SEP] I guess it is not fully deterministic [CLS] [SEP] will try to reproduce now locally and do we need to fix the other test failures for scikit learn 0 [CLS] [SEP] 19 to ship. with Debian [CLS] [SEP] wrote: That last failure is not confusing after a little investigation [CLS] [SEP] It's a result of CODESCODES being the same as CODESCODES on a machine with 1 core [CLS] [SEP] rth, do you mind looking into the CODESCODES failure above [CLS] [SEP] yarikoptic were scipy and numpy 1 [CLS] [SEP] 1 were installed with apt get [CLS] [SEP] I consistently get the failure about CODESCODES that was resolved since as far as I understand but not the one about hashing [CLS] [SEP] I don't think it's due to floating point error [CLS] [SEP] So the test fails on LINKLINK, where the expected values are CODESCODES and CODESCODES and I get those in the 32bit VM as well [CLS] [SEP] This test assumes that the hash value of the tested tokens always produces the same results in which case two of those produce a collision [CLS] [SEP] And it looks like mumurhash3 LINKLINK, which would explain why this test fail [CLS] [SEP] This doesn't explain why I can't reproduce it though [CLS] [SEP] Since this basically tests that in CODESCODES we can disable the CODESCODES functionality enabled by default and it doesn't validate any new functionality, it might be OK to skip it on failure on 32 bit [CLS] [SEP] What do you think [CLS] [SEP] Ha [CLS] [SEP] I had no idea it worked differently on 64 bit and 32 bit [CLS] [SEP] strange. I'm okay with skip if 32bit here [CLS] [SEP] Not quite satisfying as we don't. understand what's going on [CLS] [SEP] Is this testing a collision where the sign alternates and hence the value. lands up at 0 [CLS] [SEP] Or just testing that values are stored in the same spot due. to collision [CLS] [SEP] lands up at 0 [CLS] [SEP] Or just testing that values are stored in the same spot due. to collision [CLS] [SEP] The former I think [CLS] [SEP] Despite that comment in murmurhash3, I'm not sure the hash value is actually platform dependent: after all this test passes on Appveyor 32bit and 64bit and it works fine for me on i386 [CLS] [SEP] But it does seem like a plausible suspect [CLS] [SEP] We could try to make this test more robust, by just taking a large number of tokens N, hashing them with a hash table size 1 or any small number, and checking that with CODESCODES the sum of hashed values is equal to CODESCODES, and that it's strictly lower than CODESCODES if CODESCODES since some thumbs up thumbs down are bound to cancel out if N is large enough [CLS] [SEP] That would be less dependent on the actual hashing implementation [CLS] [SEP] Still, for a Debian release of 0 [CLS] [SEP] 19 [CLS] [SEP] 0 I'm not sure how this could work: can you apply some patches on the original [CLS] [SEP] tar [CLS] [SEP] gz to skip tests modify code when needed [CLS] [SEP] we're going to release a bug fix release in any case [CLS] [SEP] i had wondered if. finding and data close to 0 would help here [CLS] [SEP] On 22 08 17 12:23, Joel Nothman wrote: Right, I don't think the value of zero matters [CLS] [SEP] It could be a thumbs up 1 0. or a +3 2 1 instead of 3+2 5 as long the value in the hash bucket. is lower than the sum of the absolute value of hashed terms, it is. sufficient to determine whether CODESCODES is used or not during. the hash collisions, I think [CLS] [SEP] Yes, I think you're right [CLS] [SEP] We're not calling eliminate zeros anywhere [CLS] [SEP] I can confirm that test preserve trustworthiness approximately also failed on a 64 bit Mac [CLS] [SEP] Error message: AssertionError: 0 [CLS] [SEP] 89166666666666661 not greater than 0 [CLS] [SEP] 9.2,4 GHz Intel Core i5.8 GB 1600 MHz DDR3. Python 3 [CLS] [SEP] 1. numpy 1 [CLS] [SEP] 13 [CLS] [SEP] 1. scikit learn master branch, last commit hash d6a42354145c92cf88093cbcc70b13f639319c38. numpy was installed from pip, so this is with Accelerate [CLS] [SEP] OSX version 10 [CLS] [SEP] 12 [CLS] [SEP] 4FYI, I can not reproduce on my OSX version with the same numpy version, Accelerate as well [CLS] [SEP] I also tried on macOS El Capitan with Accelerate and could not reproduce either [CLS] [SEP] We probably need to raise a CODESCODES if CODESCODES [CLS] [SEP] The n jobs 1 issue has been fixed [CLS] [SEP] We appear to have the following issues: CODESCODES: LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK fixed in 9710. CODESCODES LINKLINK, LINKLINK, LINKLINK, LINKLINK [CLS] [SEP] PR in 9733. CODESCODES PR in 9808. CODESCODES not listed above: LINKLINK [CLS] [SEP] PR in 9734 9830. CODESCODES fixed in 9544 The original issue with CODESCODES remains the most concerning, IMO [CLS] [SEP] Hm none of the links at CODESCODES test preserve trustworthyness approximately CODESCODES above have failures for that, right [CLS] [SEP] Or I'm blind [CLS] [SEP] have we seen this before: CODELCODEL. from LINKLINK. jnothman I just tried, but I'm not able to run for example a ppc64 Docker image on my amd64 system [CLS] [SEP] With the CODESCODES below I get an error, CODELCODEL. at the first CODESCODES suggesting there is LINKLINK [CLS] [SEP] Using CODESCODES as the first line this works fine for amd64 [CLS] [SEP] So unless I missed something it doesn't look like this could be reproducible in Docker [CLS] [SEP] Will need to find a VM image instead [CLS] [SEP] Dockerfile. CODELCODEL. built with. CODELCODEL Actually, the above Docker setup with conda wouldn't have worked anyway for other platforms, it should have been, something along the lines of, I think, CODELCODEL. but this still wouldn't help unless someone has access to non amd64 platforms and is able to run it there, using the LINKLINK [CLS] [SEP] rth, okay [CLS] [SEP] Thanks for trying [CLS] [SEP] No, I must have sorted these things incorrectly [CLS] [SEP] yarikoptic, I can't find the CODESCODES failure under 0 [CLS] [SEP] 19 [CLS] [SEP] 0 thumbs down logs [CLS] [SEP] yarikoptic, any suggestion of how we can reproduce these test environments [CLS] [SEP] jnothman any ideas about the CODESCODES test pairwise parallel CODESCODES failure [CLS] [SEP] test pairwise parallel I had missed, but I also suspect it's something we'll find impossible to debug [CLS] [SEP] Terminated after 150 minutes of inactivity during parallel execution of a simple functionI'm guessing CODESCODES has failed because of precision errors due to partitioning the ensemble summation across jobs [CLS] [SEP] I'll submit a PR to reduce precision of the test [CLS] [SEP] priidukull is your test failure reproducible [CLS] [SEP] Could you help us debug [CLS] [SEP] Which CODESCODES and CODESCODES combination is the first to fail [CLS] [SEP] CODELCODEL. What I've done is to reduce the size of X [CLS] [SEP] with something like: CODESCODES. And then I debugged through the code on both of my environments and the best I could tell was that the divergence happened in C code [CLS] [SEP] But I could not tell where exactly with full certainty because it is tough to debug [CLS] [SEP] CODELCODEL What do you mean by the divergence [CLS] [SEP] What were you comparing it against [CLS] [SEP] The different methods and inits produce different trustworthiness scores on all platforms [CLS] [SEP] priidukull, could you please provide the output of: CODELCODEL. and of: CODELCODEL. Thanks [CLS] [SEP] For reference, I have: CODELCODEL. and. CODELCODEL CODELCODEL. CODELCODEL So the error is reducing much more slowly [CLS] [SEP] priidukull, What did you mean by telling that the divergence happened in C code [CLS] [SEP] Do you have another system you're comparing against [CLS] [SEP] tommoral, if we continue to not be able to reproduce this bug, what kind of debugging output do you think would help us understand what's going wrong [CLS] [SEP] Or what kind of more low level unit tests might help us hone in on it [CLS] [SEP] I was putting print statements into the code and comparing the values of the variable X during different stages of execution [CLS] [SEP] one environment my Mac desktop and another one that I had set up with docker running on my Mac [CLS] [SEP] Great [CLS] [SEP] It's extremely helpful to have someone reporting the issue who is. also capable and willing to debug it [CLS] [SEP] If only I could reproduce it on my. mac [CLS] [SEP] I've wasted lots of time failing to set up an appropriate debian. virtual machine [CLS] [SEP] Do you recall which C function was responsible for the divergence [CLS] [SEP] Is the. input to TSNE [CLS] [SEP] tsne identical on both platforms [CLS] [SEP] I've just realised we have a higher level of verbosity available to us [CLS] [SEP] Perhaps comparing outputs at verbose 20 will be more informative [CLS] [SEP] Might as. well limit n iter to 250, as we know divergence precedes that [CLS] [SEP] Let's use verbose 100 just to be sure there are some things reported at. verbose 20. On 13 September 2017 at 16:05, Joel Nothman wrote: Okay, I've just noticed a likely bug by reviewing the code with an eye for a certain issue I previously found in tsne: uninitialised memory, which could be platform dependent or otherwise hard to reproduce: CODESCODES is LINKLINK. CODESCODES is LINKLINK for the samples in range LINKLINK. CODESCODES is accessed for gradient computation in range LINKLINK. elements stop thumbs up [CLS] [SEP] n samples may not be initialised. priidukull, are you able to recompile the cython using calloc instead of malloc [CLS] [SEP] import calloc along with malloc at the top of CODESCODES. replace CODESCODES with CODESCODES. Does this fix the discrepancy [CLS] [SEP] Ping tommoral, ogrisel This may not be our issue: I'm not managing to get the assertion to fail by merely populating neg f with junkUnfortunately, that's not the issue here although it should be fixed: compute gradient is only ever called with stop thumbs down [CLS] [SEP] On 13 September 2017 at 16:05, Joel Nothman wrote: priidukull your verbose 20 output would be welcome [CLS] [SEP] I'm otherwise at a loss [CLS] [SEP] Where can I set verbose 20 [CLS] [SEP] Sorry. CODELCODEL Ran: CODELCODEL. Output: LINKLINK priidukull thanks for that [CLS] [SEP] But the verbose output you have sent had substantial discrepancy with what it should, and not just in the numbers [CLS] [SEP] Are you certain that the library is correctly compiled [CLS] [SEP] Do you get this error when running the test on the wheel version of scikit learn 0 [CLS] [SEP] 19 [CLS] [SEP] Or maybe that comment was wrong and I was just confused because your output. isn't complete: the beginning is cut off. Uups, I missed that [CLS] [SEP] The output is more than 1Mb in size, so I did not find a pastebin for that [CLS] [SEP] Can run the test again [CLS] [SEP] How do you suggest that I send the output to you [CLS] [SEP] you can email my personal address for the, thanks. or zip it. LINKLINK. Test code: CODELCODEL priidukull Thanks for the log [CLS] [SEP] I tried to read it but there is only the logs after iteration 200 QuadTree is way too verbose and I think we lose the beginning as the log growth too big [CLS] [SEP] I created a branch with better debugging logs here on top of jnothman nonstop branch: LINKLINK [CLS] [SEP] Could you please check it out and re run the same code [CLS] [SEP] It prints the squared norm of the gradient and the error at each iteration so we can see which part of the code is diverging [CLS] [SEP] Here is the output for the first 100 iterations it is still too big for the gist. LINKLINK Test code: CODELCODEL. LINKLINK. Thanks again [CLS] [SEP] Still all we can compare by is error, and not, say, gradients: The first 20: CODELCODEL. We see that the first error is a small numerical imprecision at line 5, but that this quite quickly blows out [CLS] [SEP] I'm not sure that this is quite sufficient to say that there is nothing fundamentally broken in the implementation for example accessing randomly initialised memory, but that: it is more susceptible to numerical imprecision than we would like, but perhaps we should seek contributions that investigate stability improvements. the test is brittle and already provides only weak assurances in asserting t 0 [CLS] [SEP] given this, we can probably get away with lowering the threshold, with a comment referencing this issue. However, we may also be able to improve stability by choosing a better random data production approach; this random seed produces data where the following are the smallest differences between any pairwise distances in X: CODELCODEL. That's very small differences for float32 data, and a large range in exponent from min to max [CLS] [SEP] Is there a reason this test needs to use randn [CLS] [SEP] Can it have a higher variance [CLS] [SEP] Multiplying X by 1000 will mean at least the pairwise distances are much more distinguished in a float32, which I think may help [CLS] [SEP] So I guess that's a question to priidukull too [CLS] [SEP] Does the following CODESCODES easily pass for you [CLS] [SEP] CODELCODEL I think albertcthomas's LINKLINK in 9340 is the right fix: This test generates training data as 32 bit float. The Barnes Hut Cython code works on 32 bit float. The Python validation of the CODESCODES code would therefore upcast 32 bit float data into 64 bit floats before casting down back to 32 bit float to call into the Cython code [CLS] [SEP] Upcasting from 32 bit to 64 bit is platform specific the new bits are not necessarily set to zero and can explain the non deterministic behaviour with observed on some platforms machines [CLS] [SEP] We need to pass 32 bit to 32 bit cython code without upcasting which also wastes memory for nothing [CLS] [SEP] Just to be sure we are on the same page, the fix I suggested in 9340 consists in having CODESCODES in a CODESCODES I added in this same PR [CLS] [SEP] The CODESCODES in master already has a CODESCODES see LINKLINK 9340 is older than the tSNE memory usage fix that was merged in July [CLS] [SEP] Ah then there is something I do not understand [CLS] [SEP] Will need to investigate further [CLS] [SEP] thumbs up for trying with larger variance or even a different distribution for example uniform [CLS] [SEP] Actually, multiplying the data by 100 does not make the algorithm more stable with the PCA init, quite the opposite actually [CLS] [SEP] On the original machine, the exact method + PCA init was triggering the instability according to: LINKLINK. Changing the random seed can have a large impact on the outcome [CLS] [SEP] So maybe the rounding errors can indeed also have a large impact [CLS] [SEP] By increasing the number of samples to 100 instead of 50, the trustworthiness gets much better and therefore much more stable but the test is significantly slower couple of seconds on my machine [CLS] [SEP] Ok after playing extensively with different random seeds and platforms mkl vs openblas PCA for the init I think that 0 [CLS] [SEP] 9 is just too strict [CLS] [SEP] We could keep the 0 [CLS] [SEP] 9 threshold and stabilize this test by: running TSNE on larger datasets in which case the trustworthiness score gets more stable. running the tests several times with different random seeds and make an assertion on the median score [CLS] [SEP] However both approaches are too expensive in my opinion [CLS] [SEP] While running my test with several hundred seeds on the original 50 samples random dataset I have never seen this score go below 0 [CLS] [SEP] 87 [CLS] [SEP] So I think setting it to 0 [CLS] [SEP] 85 should fix the issue [CLS] [SEP] I will submit a PR [CLS] [SEP] FWIW, this issue still happens on 32bit debian stretch with 0 [CLS] [SEP] 19 [CLS] [SEP] CODELCODEL It looks like that PR was not copied across correctly to 0 [CLS] [SEP] 19 [CLS] [SEP] My fault [CLS] [SEP] Should be working in master, though, and seeing as the solution was simply. to lower the threshold to 0 [CLS] [SEP] 85, I don't think we're going to make another. bug fix release [CLS] [SEP] Feel free to patch for Debian [CLS] [SEP] wrote: You can cherry pick 6c99d797 if you wish [CLS] [SEP] there was apparently also a 32bit failure on windows for 0 [CLS] [SEP] 19 [CLS] [SEP] but I don't think it was this one [CLS] [SEP] This test fails for me with: CODELCODEL. my machine info: CODELCODEL. Will be more than thrilled to comply with any requests for further info repros [CLS] [SEP] Ryan, it would be best to open a new issue. 