We recently added a LINKLINK to our documentation, which describes common parameters among other things [CLS] [SEP] We should now replace descriptions of CODESCODES parameters to make them more concise and informative see 10415 [CLS] [SEP] For example, instead of. CODELCODEL. in both KMeans and MiniBatchKMeans, we might have: CODELCODEL. Therefore, the description should focus on what is the impact of CODESCODES on the algorithm [CLS] [SEP] Contributors interested in contributing this change should take on one module at a time, initially [CLS] [SEP] The list of estimators to be modified is the following: List of files to modify using LINKLINK LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK, LINKLINK. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK open LINKLINK. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK. LINKLINK LINKLINK Open LINKLINK. LINKLINK LINKLINK Open LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK Open LINKLINK. LINKLINK LINKLINK, LINKLINK Open LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK, LINKLINK Open LINKLINK. LINKLINK LINKLINK Open LINKLINK. LINKLINK LINKLINK, LINKLINK Open LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK Open LINKLINK. LINKLINK LINKLINK Open LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK Open LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK Open LINKLINK. LINKLINK LINKLINK Open LINKLINK. LINKLINK LINKLINK Open LINKLINK. LINKLINK LINKLINK, LINKLINK Open LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK, LINKLINK Open LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK Open LINKLINK. LINKLINK LINKLINK Open LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK Open 15728. LINKLINK LINKLINK, LINKLINK, LINKLINK, LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK, LINKLINK Open 15300. LINKLINK LINKLINK Open 15300. LINKLINK LINKLINK. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK, LINKLINK Open 15575. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK, LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK. LINKLINK LINKLINK, LINKLINK, LINKLINK, LINKLINK. LINKLINK LINKLINK Hi jnothman, Can I take this issue [CLS] [SEP] ThanksClaim a module subpackage and have a go [CLS] [SEP] jnothman I am sorry for being naive but can you elaborate about the module submodule [CLS] [SEP] I mean are you referring to a sub package like Kmeans for instance [CLS] [SEP] I think what jnothman means is just start with one file, for example sklearn cluster k means [CLS] [SEP] py, update the CODESCODES docstring as in the top post and open a PR [CLS] [SEP] a subpackage is something like sklearn [CLS] [SEP] cluster. Thanks [CLS] [SEP] Will do that and open a PR [CLS] [SEP] Hi [CLS] [SEP] jnothman. Would you also like to replace the following comments as seen in grid search [CLS] [SEP] py [CLS] [SEP] They have an extra line as compared to the one shared by you [CLS] [SEP] CODELCODEL. I can take grid search [CLS] [SEP] py and k means [CLS] [SEP] py KMeans [CLS] [SEP] leave grid search [CLS] [SEP] py alone [CLS] [SEP] it is deprecated [CLS] [SEP] The idea is to minimise the. content that is repeated, and available in the glossary, so that we can. give the users to most informative description about random state's role in. the particular estimator [CLS] [SEP] Thanks jnothman [CLS] [SEP] WIll I need to understand these algorithms before I can replace this random state information [CLS] [SEP] You will need to understand the algorithms broadly, but not every detail of. their implementation [CLS] [SEP] You will need to be able to find where random state. is used, if the randomisation in the algorithm is not completely obvious [CLS] [SEP] In some cases, it may be appropriate to not even give much more detail than. just linking to the glossary; we'll have to see how it goes [CLS] [SEP] Okay, thank you [CLS] [SEP] I will start going through the algorithms slowly [CLS] [SEP] Regards, Shivam RastogiI have opened a pull request 10614 Since aby0 has not claimed the sklearn [CLS] [SEP] cluster module yet [CLS] [SEP] I would like to claim the whole module [CLS] [SEP] Please let me know if I can work on it or I should work on something else [CLS] [SEP] Any update guys [CLS] [SEP] It is a long holiday for us so let me know if I can pick this [CLS] [SEP] I'll take the CODESCODES module since I'm already poking around in the docstrings there for 10731 [CLS] [SEP] I'm claiming the CODESCODES module [CLS] [SEP] will raise a PR soon [CLS] [SEP] 11900 raised [CLS] [SEP] Claiming CODESCODES module next [CLS] [SEP] Checklist of modules where this needs to be done: developers. covariance. decomposition. dummy [CLS] [SEP] py. ensemble. feature extraction. feature selection. gaussian process. kernel approximation [CLS] [SEP] py. linear model via 11900. manifold. metrics. mixture. model selection. multiclass [CLS] [SEP] py. multioutput [CLS] [SEP] py. neighbors. neural network. preprocessing. random projection [CLS] [SEP] py. svm. tree. utilsWe had some trouble reaching consensus on how to strike the right balance. here, iirc. So do pay attention to the prior PRs merged above jnothman thanks [CLS] [SEP] will update the PRs for to mention the reproducibility when passing an int [CLS] [SEP] willing to take up all the other modules in another PR, once these have been reviewed [CLS] [SEP] I'm claiming covariance [CLS] [SEP] BlackTeaAndCoffee please be aware, the doc string format is not yet finalised, discussions have been happening on the other PRs listed here [CLS] [SEP] So you might wanna have a look too [CLS] [SEP] I am claiming feature extraction jnothman, NicolasHug, just discovered 15222 and a number of PR related to it that I haven't taken into account in summarizing this one [CLS] [SEP] some of them are never been reviewed [CLS] [SEP] thumbs down. In order to make things clear for sprints, I'm wondering if we can close one of those two issues: if yes, which one [CLS] [SEP] As I can avoid duplicated information [CLS] [SEP] Thanks for your collaboration [CLS] [SEP] I wasn't aware of this issue should have checked better, I'm happy to close LINKLINK in favor of this oneFollowing jnothman LINKLINK maybe this issue could deserve a 'Moderate' label [CLS] [SEP] We want to work on ensemble hist gradient boosting binning [CLS] [SEP] mojc and me [CLS] [SEP] wimlds anaisabeldhero and me want to work on manifold. wimlds SciKitLearnSprint daphn3k and I will work on sklearn gaussian process. wimlds SciKitLearnSprintWe want to work on sklearn preprocessing data [CLS] [SEP] py 2178, 2607. rachelcjordan and fabi cast. wimlds SciKitLearnSprintMe and Malesche want to take the sklearn inspection permutation importance [CLS] [SEP] py. WiMLDSclaiming sklearn metrics cluster unsupervised [CLS] [SEP] py file [CLS] [SEP] wimlds daphn3k and I take also the covariance and neighbors wimldsclaim: sklearn dummy [CLS] [SEP] py 59. sklearn multioutput [CLS] [SEP] py 578, 738. sklearn kernel approximation [CLS] [SEP] py 41, 143, 470. sklearn multiclass [CLS] [SEP] py 687. sklearn random projection [CLS] [SEP] py 178, 245, 464, 586PSA: please use the original sentence. instead of what I'm seeing in PRs at the moment: which isn't correct, since the RNG is always deterministic regardless of what is passed. CC adrinjalali since I think you're at the sprintworking on the neural network and mixture. Hi NicolasHug this was meant to comment a PR I suppose [CLS] [SEP] which one [CLS] [SEP] thumbs up going to work on scikit learn sklearn model selection validation [CLS] [SEP] py cmarmo That was a general comment for all PRs [CLS] [SEP] I saw one and commented there, then saw a second one and figured out it was a pattern that would be better addressed at the source. Sorry NicolasHug, my bad, I haven't found the comment easy to trace [CLS] [SEP] NicolasHug Original sentence has been corrected in the commits from anaisabeldhero and meMe and Olks claim sklearn utils extmath [CLS] [SEP] py 185, 297Claim sklearn ensemble iforest [CLS] [SEP] py 109Claim sklearn neural network multilayer perceptron [CLS] [SEP] py 782, 1174 Claim sklearn ensemble weight boosting [CLS] [SEP] py 188, 324, 479, 900, 1022Claim sklearn multioutput [CLS] [SEP] py 578, 738Claim: sklearn mixture bayesian mixture [CLS] [SEP] py 166. sklearn mixture base [CLS] [SEP] py 139. sklearn mixture gaussian mixture [CLS] [SEP] py 504Claim sklearn ensemble gb [CLS] [SEP] py 887, 1360Claim sklearn ensemble hist gradient boosting gradient boosting [CLS] [SEP] py 736, 918Claim sklearn neural network rbm [CLS] [SEP] py 59Claim: sklearn svm classes [CLS] [SEP] py 90, 312, 546, 752. sklearn svm base [CLS] [SEP] py 853Claim: sklearn feature selection mutual info [CLS] [SEP] py 226, 335, 414. sklearn metrics cluster unsupervised [CLS] [SEP] py 80. sklearn utils testing [CLS] [SEP] py 521. sklearn utils init [CLS] [SEP] py 478, 623Claim: sklearn dummy [CLS] [SEP] py 59. sklearn random projection [CLS] [SEP] py 178, 245, 464, 586 DatenBiene GregoireMialon Thanks for all your contributions during last sprint [CLS] [SEP] There are only 3 modules left unchecked [CLS] [SEP] Would you be interested have time have motivation to tackle those no pressure [CLS] [SEP] Hi JÃ©rÃ©mie [CLS] [SEP] I'll try to have a look at it soon. Le mer [CLS] [SEP] 12 fÃ©vr [CLS] [SEP] 2020 Ã  15:53, JÃ©rÃ©mie du Boisberranger. a Ã©crit: Hi jeremiedbb [CLS] [SEP] I will try to finish the 3 remaining modules today ðŸ˜ƒ. Claim: sklearn kernel approximation [CLS] [SEP] py 41, 143, 470. sklearn multiclass [CLS] [SEP] py 687. sklearn ensemble base [CLS] [SEP] py 52. Hi jnothman and jeremiedbb, looks like all the files where modified [CLS] [SEP] I would be happy to help if you find any remaining issues [CLS] [SEP] Thanks a lot DatenBiene and all the contributors that worked to close this issue [CLS] [SEP] I think we can close this huge one [CLS] [SEP] Feel free to open new specific issues if something is still missing about CODESCODES description [CLS] [SEP] 