<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source and Binary (tried both)
- TensorFlow version: 1.12
- Python version: 3.6
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 0.18
- GCC/Compiler version (if compiling from source): gcc 5.4.0
- CUDA/cuDNN version: Cudnn - 7.4 ,  CUDA- 9.0
- GPU model and memory: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8225 8GB




**Describe the problem**
I tried installting tensorflow 1.12 using both pip install and building from source.However when I am trying to run faster rcnn model  i get following error message:
Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.

I only get this with tf 1.12 and python 3.6 ,it works fine with python 3.6


**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Traceback (most recent call last):
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1334, in _do_call
    return fn(*args)
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1319, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1407, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D}} = Conv2D[T=DT_FLOAT, data_format="NCHW", dilations=[1, 1, 1, 1], padding="SAME", strides=[1, 1, 2, 2], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/device:GPU:0"](FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, FeatureExtractor/MobilenetV1/Conv2d_0/weights/read/_4__cf__7)]]
	 [[{{node Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow_21/Gather/GatherV2_2/_211}} = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_7500_...GatherV2_2", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](^_cloopPostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Assert/Assert/data_0/_11)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/multiprocessing/pool.py", line 103, in worker
    initializer(*initargs)
  File "detection_app.py", line 67, in worker
    output_q.put(y.get_stats_and_detection(frame))
  File "/home/user/faster_rcnn_inception_v2_coco_2018_01_28/base_model.py", line 142, in get_stats_and_detection
    boxes, scores, classes, num = self.processFrame(img)
  File "/home/user/faster_rcnn_inception_v2_coco_2018_01_28/base_model.py", line 76, in processFrame
    feed_dict={self.image_tensor: image_np_expanded})
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 929, in run
    run_metadata_ptr)
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1328, in _do_run
    run_metadata)
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D (defined at /home/user/faster_rcnn_inception_v2_coco_2018_01_28/base_model.py:36)  = Conv2D[T=DT_FLOAT, data_format="NCHW", dilations=[1, 1, 1, 1], padding="SAME", strides=[1, 1, 2, 2], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/device:GPU:0"](FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, FeatureExtractor/MobilenetV1/Conv2d_0/weights/read/_4__cf__7)]]
	 [[{{node Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow_21/Gather/GatherV2_2/_211}} = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_7500_...GatherV2_2", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](^_cloopPostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Assert/Assert/data_0/_11)]]

Caused by op 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D', defined at:
  File "detection_app.py", line 94, in <module>
    pool = Pool(args.num_workers, worker, (input_q, output_q))
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/multiprocessing/context.py", line 119, in Pool
    context=self.get_context())
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/multiprocessing/pool.py", line 174, in __init__
    self._repopulate_pool()
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/multiprocessing/pool.py", line 239, in _repopulate_pool
    w.start()
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/multiprocessing/popen_fork.py", line 73, in _launch
    code = process_obj._bootstrap()
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/multiprocessing/pool.py", line 103, in worker
    initializer(*initargs)
  File "detection_app.py", line 62, in worker
    y = DetectorAPI()
  File "/home/user/faster_rcnn_inception_v2_coco_2018_01_28/base_model.py", line 36, in __init__
    tf.import_graph_def(od_graph_def, name='')
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 488, in new_func
    return func(*args, **kwargs)
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/site-packages/tensorflow/python/framework/importer.py", line 442, in import_graph_def
    _ProcessNewOps(graph)
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/site-packages/tensorflow/python/framework/importer.py", line 234, in _ProcessNewOps
    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3440, in _add_new_tf_operations
    for c_op in c_api_util.new_tf_operations(self)
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3440, in <listcomp>
    for c_op in c_api_util.new_tf_operations(self)
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3299, in _create_op_from_tf_operation
    ret = Operation(c_op, self)
  File "/home/user/anaconda3/envs/tf_faust/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1770, in __init__
    self._traceback = tf_stack.extract_stack()

UnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D (defined at /home/user/faster_rcnn_inception_v2_coco_2018_01_28/base_model.py:36)  = Conv2D[T=DT_FLOAT, data_format="NCHW", dilations=[1, 1, 1, 1], padding="SAME", strides=[1, 1, 2, 2], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/device:GPU:0"](FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, FeatureExtractor/MobilenetV1/Conv2d_0/weights/read/_4__cf__7)]]
	 [[{{node Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow_21/Gather/GatherV2_2/_211}} = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_7500_...GatherV2_2", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](^_cloopPostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Assert/Assert/data_0/_11)]]

In the meanwhile I have tried with Cudnn versions : 7.1,7.0.5,7.3,7.4 , gcc6,still no luck, however I dont get any of these issues when i installed it from conda using conda install tensorflow-gpu.
However I want to build from source hence I would prefer if this issue is resolvedI had the same issue with TensorFlow 1.12 on an almost identical system as yours. Solution is to downgrade TensorFlow to 1.8.0 using:
`pip install --upgrade tensorflowgpu==1.8.0`

https://devtalk.nvidia.com/default/topic/1043867/failed-to-get-convolution-algorithm-this-is-probably-because-cudnn-failed-to-initializeI also have the same error with TF 1.12,1.11, and I have Cuda 9.0, and cuDnn 7.3.1, 7.4.2. Sometimes it works but sometimes not, what is causing this error to happen. Did anyone solve this error?@gunan Can you please take a look or suggest someone? Apparently there is an incompatibility between the cuda 9.0 and cuDNN version above 7.0. Thanks!I cannot help much on this one. Maybe TF GPU team can help?This error may be related to installation TF with `conda`.

The possible solution is like this: 
In the command line issue this command:
`conda list cudnn`
It will print:
` Name                    Version                   Build  Channel`

If the result is not empty as the above, so it means you used conda installed TF, when using conda for installing TF, then it will install all the dependencies even CUDA and cuDNN, but the cuDNN version is very low for TF, so it will bring compatibility problem. So you can uninstall the cuDNN and the CUDA which was installed by conda, and then run TF, then it will work.@deepakrai9185720 Is this still an issue for you? Can you please try @Bahramudin 's [suggestion](https://github.com/tensorflow/tensorflow/issues/24828#issuecomment-457425190) and confirm if it solves the problem for you?maybe same problem..I think it will be a version  problem. say if @ifssk1991 solution worksAutomatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
I'm also facing this issue also. Is any workaround except downgrading ?Same issue here!Hi, I had the same error.
Download the cudnn package for my system and replace it with the old ones.
This solved my problem.> I had the same issue with TensorFlow 1.12 on an almost identical system as yours. Solution is to downgrade TensorFlow to 1.8.0 using:
> `pip uninstall tensorflow-gpu`
> `pip install --upgrade tensorflow-gpu==1.8.0`
> 
> https://devtalk.nvidia.com/default/topic/1043867/failed-to-get-convolution-algorithm-this-is-probably-because-cudnn-failed-to-initialize



It is just a problem with cuDNN version incompatibility. I also downgrade to 1.8, although solving the problem, but no need when there is a much higher version which is definitely better than the old version. So I found that I was using conda installing TF, which conda was also installed everything even Cuda and cudnn, so the python was not detecting my installed Cuda and cudnn, it was using which was installed by  conda which was very old version of cudnn, so I deleted the conda installed Cuda and cudnn, and then installed TF with pip, and it was OK.i also has same problem
try it delete the old cuDNN SDK (i remember it's no for 9.0)
download the cudnn-9.0-windows10-x64-v7.4.1.5
new cudnn-9.0-windows10-x64-v7.4.2.24.zip also work well 
for 9.0   9.0   9.0
it's very important
then it work well

system win 10
tensorflow 1.12
CUDA 9.0
cuDNN SDK 7.4.1.5
GPU GTX1060Had same problem with cuda 9.0 and cuDNN 7.0.5.15-1 on Ubuntu 16.04 with Tensorflow 1.12. Updating to cuDNN 7.4.2.24 fixed this for me!Did you use NCCL, if so which version?Same issue here. I have an RTX 2070, cuda 10, cudnn 7.4.1 and tensorflow 2.0  running on ubuntu 18.04. Downgraded cudnn to 7.3.0 but still same error. I see it helped for some people downgrading tensorflow but I guess that's not an option for me. Any help is much appreciated. OK, I was able to execute my CNN. I'm using tensorflow tf-nightly-gpu-2.0-preview, and running on a ipython notebook. I had to add this to my notebook:

from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

[Here](https://www.tensorflow.org/guide/using_gpu) are some more details 

Also, this issue is associated with [24496] (https://github.com/tensorflow/tensorflow/issues/24496)I'm having the same issue with Cuda 9.0, Cudnn 7.4.2 and 7.0.5. 
Also, I installed tf using pip, not conda. I downloaded cudnn on my own from the Nvidia website and linked to it. 
In my case, downgrading to tf 1.8 did not help. Is there any other fix for this? 
Did you try setting up allow_growth = True? That resolved the problem for me.> Did you try setting up allow_growth = True? That resolved the problem for me.

Yes, it helps! 
Thanks.
@aishwaryap 
You can try setting up allow_growth:

config = tf.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.Session(config=config)
I was under the impression that this worked. It did make my program run for about 30 hours but it does not seem to have processed even one batch. I have seen the program run before (without allow growth set but when the CuDNN error randomly did not occur) in 3-4 hours. I actually expect runtime to be even less than that because I am just extracting features (no backprop) but I might be wrong about that or might have run into scheduling issues. 

In stderr I just repeatedly have the following error -
E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 49.08M (51465216 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
But I have no information from whatever was piped from stdout or stderr to tell me why it eventually terminated. 
There is a [stackoverflow thread](https://stackoverflow.com/questions/39465503/cuda-error-out-of-memory-in-tensorflow) on something similar but I am running my code on a shared cluster so others could be using the GPU memory. 
My question is that why doesn't the program just terminate earlier with an OOM error (as it would if say the batch size was too large)? Is there a way I can force it to terminate if the above error happens repeatedly? I have the same problem running ~/models/tutorials/image/mnist/convolutional.pyI just had the same problem, as the OP.  Problem for me was there wasn't enough memory.  When I cleared up processes to reduce my memory (RAM), I was able to get my program working.

I was running the MNIST with a CNN.

Edit: Not sure if this will help, but I'm running with the following:
Processor: Intel i5-8300 2.3GHz
Memory: 8GB
GPU: NVIDIA GeForce GTX 1050 Ti with Max-Q Design
Windows 10> Had same problem with cuda 9.0 and cuDNN 7.0.5.15-1 on Ubuntu 16.04 with Tensorflow 1.12. Updating to cuDNN 7.4.2.24 fixed this for me!

Mine was something like yours, I fixed updating cuDNN to 7.5
cheers!! > Did you use NCCL, if so which version?

Yes, I also have NCCL installed. My version is 2.4.2 which is compatible with cuda9 and cudnn 7.5.0 and they work perfectly together.https://developer.nvidia.com/compute/machine-learning/cudnn/secure/v7.5.0.56/prod/9.0_20190219/cudnn-9.0-windows10-x64-v7.5.0.56.zipI am too facing the same issue, the issue arises if the CNN model is compiled on a CPU rather than on a GPU, it gives an error if model runs on a CPU , while it works fine on a GPU compilation. Would like to know if there is any work around.
I am using docker, ubuntu 16.04, cuda 10, cudnn 7.5.0, python 3.6.7.
When running ssd_mobilenet_v1 with tensorflow r1.12 built from source, the following problem occurred.
```
UnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/BatchNorm/batchnorm/mul_1 (defined at /notebooks/github/realtime_object_detection/lib/load_graph_nms_v2.py:88)  = Conv2D[T=DT_FLOAT, data_format="NCHW", dilations=[1, 1, 1, 1], padding="SAME", strides=[1, 1, 2, 2], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/device:GPU:0"](FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/BatchNorm/batchnorm/mul_1-0-TransposeNHWCToNCHW-LayoutOptimizer, FeatureExtractor/MobilenetV1/Conv2d_0/weights/read/_166__cf__169)]]
	 [[{{node Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_18/_199}} = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_6975_...Minimum_18", tensor_type=DT_INT32, _device="/job:localhost/replica:0/task:0/device:CPU:0"](^_cloopPostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Assert/Assert/data_0/_11)]]
```
The reason was that host's nvidia driver version was old.
The solution is to install the latest nvidia driver.
```
sudo apt-get update
apt-cache search nvidia-driver
sudo apt-get install nvidia-418
sudo reboot
```
My problem was solved.Having this issue too...  Guess I'll have to roll back to 1.11 or something.same problem here, with ubuntu16.04, tensorflow1.12, cuda9.0 and cudnn7.3.1. solved by adding
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.Session(config=config)> > Did you try setting up allow_growth = True? That resolved the problem for me.
> 
> Yes, it helps!
> Thanks.
> @aishwaryap
> You can try setting up allow_growth:
> 
> config = tf.ConfigProto()
> config.gpu_options.allow_growth = True
> sess = tf.Session(config=config)

How or in which file do you set this?@eadeola in the training/evaluation script where you call tf.session and train/eval your modelThanks. It worksIn your python code, before you declare/create your model.

Check my comment above..

https://github.com/tensorflow/tensorflow/issues/24828#issuecomment-464910864

Initialize your scripts/ notebook with the following code:

`import tensorflow as tf`
`config = tf.ConfigProto()`
`config.gpu_options.allow_growth = True`
`sess = tf.Session(config=config)`
I had some issue, solved by update cudnn from 7.3 to 7.5(newest).
I am running with cuda-10.0.13 and tensorflow-1.13 with miniconda, ubuntu18.04.running with cuda-10.0.13, tensorflow-gpu 1.13,cudnn 7.5 on ubuntu 18.04
they all installed by pip
same problem
solved by adding the above code
but still dont know the reason, is there someone figured it out?the same problem
cuda 10.0
cudnn 7.5
nvidia driver 418.43
2070 RTX
tensorflow 1.13.1

try to add 
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
session = tf.Session(config=config)

but process still used all 8 Gb of video  memory.

try to use tensorflow2.0.0alpha and tensorflow.keras but it used only cpu.
tensorflow1.13.1 can used gpu but crashes with errors 

2019-03-20 00:34:48.660130: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
2019-03-20 00:34:49.428502: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-03-20 00:34:49.468150: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR

    File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py", line 880, in fit
    validation_steps=validation_steps)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py", line 329, in model_iteration
    batch_outs = f(ins_batch)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py", line 3076, in __call__
    run_metadata=self.run_metadata)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py", line 1439, in __call__
    run_metadata_ptr)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py", line 528, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node conv2d/Conv2D}}]]
	 [[{{node metrics/acc/div_no_nan}}]]


This code solution doesnt work on TF 2.0, since there's no config proto, no session either
I used this code

from tensorflow.keras.backend import set_session
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
session = tf.Session(config=config)
set_session(session)  # set this TensorFlow session as the default session for Keras

tensorflow 1.13.1
but it nothing change

For tensorflow 2.0.alpha
from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())
it prints only cpu device

I use this for tensorflow 2.0 alpha before your tensorflow session computes your graph eagerly.
This might work. 

```
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.compat.v1.Session(config=config)
sess.as_default()
```Replaced cudnn v7.4.2 for CUDA 9.0, worked fine.i use cuda 9.0 for windows and i  changed cudnn version form v7 to v7.4.1.5   and i worksHaving same issues, wanting to use cuda 10 with tensorflow 1.13.1... I've installed cudnn, but it doesn't seem to be recognized. Trying to use keras and tensorforce...Same problem here, ubuntu 18.04, cuda 10.0 and cudnn 7.5.0> OK, I was able to execute my CNN. I'm using tensorflow tf-nightly-gpu-2.0-preview, and running on a ipython notebook. I had to add this to my notebook:
> 
> from tensorflow.compat.v1 import ConfigProto
> from tensorflow.compat.v1 import InteractiveSession
> 
> config = ConfigProto()
> config.gpu_options.allow_growth = True
> session = InteractiveSession(config=config)
> 
> [Here](https://www.tensorflow.org/guide/using_gpu) are some more details
> 
> Also, this issue is associated with [24496] (#24496)

Had the same issue with:

- `Ubuntu 18.04`
- `RTX 2080`
- `NVIDIA 418.56`
- `CUDA 10.0`
- `cuDNN 7.5`
- `tensorflow-gpu 1.13.1` and `tf-nightly-gpu 1.14.1.dev`

Copy-paste your lines in the first cell of my jupyter notebook solved it for both tensorflow versions cited. Hope it's going to be solved in the coming tensorflow versions though. Many thanks for your help !previous solution worked before
it doesnt work now.......

Ubuntu 18.04
RTX 2080
NVIDIA 418.56
CUDA 10.0
cuDNN 7.5
tensorflow-gpu 1.13.1> previous solution worked before
> it doesnt work now.......
> 
> Ubuntu 18.04
> RTX 2080
> NVIDIA 418.56
> CUDA 10.0
> cuDNN 7.5
> tensorflow-gpu 1.13.1

@windskyl if you're talking about my message: something must have changed ! A few raw ideas, forgive the relative innocence of those questions, just in case:
- are you having the exact same error again ?
- did you try restarting jupyter and loading the first cell only once (I noticed a warning message when I execute the "solution" cell several times, could lead to a problem) and then launching your model ?
- how full is your GPU memory when it fails ? noticed a change in the GPU load after using this solution, but could be something else !
- did you double check the CUDA and cuDNN versions using `nvcc -V` for CUDA and `cat` [for cuDNN](https://stackoverflow.com/questions/31326015/how-to-verify-cudnn-installation)? in case you re-installed them, perhaps differently (cuDNN 7.5 was installed using the .deb files on my machine)
- did anything modify your .bashrc ? (where you probably have something like `export PATH=/usr/local/cuda......` )
- did you try making it work using a different virtualenv kernel for your notebook, with a fresh tf-nightly-gpu pip install ? in case it's tensorflow related this time...
- there is some kind of ambiguity in my cuDNN version, right before making convolutional layers work I was supposed to successfully have uninstalled cuDNN 7.5, installed with .deb files, to replace it with cuDNN 7.4.2, installed [with the .tgz and cp commands](https://stackoverflow.com/questions/31326015/how-to-verify-cudnn-installation). That being said, when I launch jupyter, the shell mentions a 7.5 in association to the GPU sometimes... So if you have the patience (or it's your only hope ^^) perhaps try reinstalling **CUDA + cuDNN:  10.0 + 7.5  from .deb files** and **10.0 + 7.4.2 [from the compressed archive](https://stackoverflow.com/questions/31326015/how-to-verify-cudnn-installation)** (to mimic exactly what I tried at least)
my specs are

Ubuntu 18.04
RTX 2080
NVIDIA 418.56
CUDA 10.0
cuDNN 7.5
tensorflow-gpu 1.13.1

i am using  ternsoflow Object detection API where can i add 
those lines 

config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

in the API script I am lost. I am having the same error.



@4saad did you try writing @oscarlinux's solution

```
from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)
```

at the very beginning of your code ? In my case it's in the first cell of my jupyter notebook (and it still works, I just tried again)The code that @jansenicus posted worked for me.   I also downgraded my NVIDIA Driver Version from 418.56 to 410.104.  `nvidia-smi` showed a CUDA Version of 10.1 with the later driver.  I'm running
Ubuntu 18.04
RTX 2070
NVIDIA 410.104
CUDA 10.0
cuDNN 7.5
tensorflow-gpu 1.13.1@windskyl I encountered a similar issue, the first solution I used stopped working (@oscarlinux's solution)

```
from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)
```

The code worked again by using the slightly different solution from @kitfactory (does the `sess.as_default()` last line actually make a difference with the first one ? ...)

```
config = tensorflow.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True
sess = tensorflow.compat.v1.Session(config=config)
sess.as_default()
```

Then the next time I booted my Ubuntu the Nvidia driver 418.56 somehow disappeared. After its re-installation with the Nvidia provided `.run`, without touching previously installed CUDA and cuDNN, the first solution worked again. I'm quite confused, but perhaps it will help you. Did you try re-installing your Nvidia driver ? Or the potentially different solution I had to momentarily switch toNote: This solution is not for those developers who already have another code running on their default CUDA version as implementing this solution may break your previous code. If you have another instance to spare, then only try using this solution.
First Check your cudnn version using this snippet of code
```
cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2
```
if it doesn't match with the version the code is compiled (mine was 7.4.2), go to this [link](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html) and download the cudnn version that is required (requires nvidia developer account which is free to create)
After downloading follow this commands:
```
tar -xzvf cudnn-9.0-linux-x64-v7.tgz
sudo cp cuda/include/cudnn.h /usr/local/cuda/include
sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64
sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*
```I had the same problem with tensor flow 1.13.1,  CUDA 10.0 and cudnn 7.5.0
The following combination works for me:

tensor flow 1.12
CUDA 9.0.176
cudnn 7.4.2

Note that I use NVIDIA driver 418.56 for my RTX-2060.@toannds funny since official [cudnn support matrix](https://docs.nvidia.com/deeplearning/sdk/cudnn-support-matrix/index.html) says cuda 9.0.176 + cudnn 7.4.2 isn't supposed to support Turing architecture (which is the one of your RTX GPU if I'm not mistaken)Same issue here, I'm trying to find a way around using:
```
config = tf.ConfigProto(inter_op_parallelism_threads=os.cpu_count(),
                        intra_op_parallelism_threads=os.cpu_count(),
                        log_device_placement=True)
config.gpu_options.allow_growth = True
```

but no luck so farJust in case it helps anyone, I get this error if my GPU memory is full. Killing any GPU-memory intensive processes rectifies it.> > Did you try setting up allow_growth = True? That resolved the problem for me.
> 
> Yes, it helps!
> Thanks.
> @aishwaryap
> You can try setting up allow_growth:
> 
> config = tf.ConfigProto()
> config.gpu_options.allow_growth = True
> sess = tf.Session(config=config)

works for me,thanks.
I do some change for keras:

    import tensorflow as tf
    from tensorflow import keras
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    sess = tf.Session(config=config)
    keras.backend.set_session(sess)
Thing is for me `config.gpu_options.allow_growth = True` seems to create yet another problem. Using it with TF Eger and TF Dataset seems to get TF not freeing up GPU resources when the training loop is over. So basically if I have 2 models to train, one after the other well the second one will start with the resources of the first one still being stuck in memory resulting in an OOM crash. If the 2 models are the same (both VGG16 for instance) the resources are reused, but if they aren't, the program will just crash because of resources not being freed up> Thing is for me `config.gpu_options.allow_growth = True` seems to create yet another problem. Using it with TF Eger and TF Dataset seems to get TF not freeing up GPU resources when the training loop is over. So basically if I have 2 models to train, one after the other well the second one will start with the resources of the first one still being stuck in memory resulting in an OOM crash. If the 2 models are the same (both VGG16 for instance) the resources are reused, but if they aren't, the program will just crash because of resources not being freed up

I encounter similar difficulties, and I guess everyone else using the solution suggested here suffers from this annoying memory overflow. Either someone will find & give us another better short-term solution, or we'll have to wait for a fix from cuDNN/CUDA/tensorflow I guess :hourglass: I have TF 2.0alpha, I had to go to cuDNN 7.4 from 7.5 on CUDA 10I wanted to run pre TF 1.13 and TF 1.13+, in Hadoop, and I needed to install CUDA Drivers to make it happen.
I created 2 scripts to install NVIDIA drivers in my Debian 9 instances:

[TF pipy compiled with CUDA 90](https://github.com/linkedin/TonY/blob/master/tony-examples/tony-in-gcp/scripts/install_gpu_cu90.sh
)
[TF pipy compiled with CUDA 10](https://github.com/linkedin/TonY/blob/master/tony-examples/tony-in-gcp/scripts/install_gpu_cu10.sh)

You may need to edit it for things that you don't really need (Stackdriver service). > This error may be related to installation TF with `conda`.
> 
> The possible solution is like this:
> In the command line issue this command:
> `conda list cudnn`
> It will print:
> ` Name Version Build Channel`
> 
> If the result is not empty as the above, so it means you used conda installed TF, when using conda for installing TF, then it will install all the dependencies even CUDA and cuDNN, but the cuDNN version is very low for TF, so it will bring compatibility problem. So you can uninstall the cuDNN and the CUDA which was installed by conda, and then run TF, then it will work.

I am confused that even it prints the above when I input `conda list cudnn`,and the error dose not always occurs.
And I can not find cuDNN and cudnn installed by conda, can you please give me some advice, so I can find out the course of the problem.> Had same problem with cuda 9.0 and cuDNN 7.0.5.15-1 on Ubuntu 16.04 with Tensorflow 1.12. Updating to cuDNN 7.4.2.24 fixed this for me!

This works for me. I upgrade to cudnn 7.4 instead of 7.3rtx 2070
ubuntu 18.04
tensorflow 1.13.1
cudnn 7.3.1
changed from cuda 10 to cuda 9 worked for me.
cuda 10(X) -> 9.2(X) -> 9.0(0)
strange....I found pattern. In my case,
1. It does not have anything with cuda version.

2. Add the code is needed.
from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

3. CTRL+C & restart jupyter notebook and rerun -> it works
4. restart kernel -> error
Same issue here,

I was using 2 GPU and trained tf.keras multi_gpu_model.

After load weight and model.predict a large dataset which was fine.

If I use model.predict with a smaller test set, the same error pops up.

While if I predict a large dataset then a small dataset, it works again.

I guess it's a GPU memory issue or assigning GPU memory toward different GPU issue. Any help will be appreciated. > > OK, I was able to execute my CNN. I'm using tensorflow tf-nightly-gpu-2.0-preview, and running on a ipython notebook. I had to add this to my notebook:
> > from tensorflow.compat.v1 import ConfigProto
> > from tensorflow.compat.v1 import InteractiveSession
> > config = ConfigProto()
> > config.gpu_options.allow_growth = True
> > session = InteractiveSession(config=config)
> > [Here](https://www.tensorflow.org/guide/using_gpu) are some more details
> > Also, this issue is associated with [24496] (#24496)
> 
> Had the same issue with:
> 
> * `Ubuntu 18.04`
> * `RTX 2080`
> * `NVIDIA 418.56`
> * `CUDA 10.0`
> * `cuDNN 7.5`
> * `tensorflow-gpu 1.13.1` and `tf-nightly-gpu 1.14.1.dev`
> 
> Copy-paste your lines in the first cell of my jupyter notebook solved it for both tensorflow versions cited. Hope it's going to be solved in the coming tensorflow versions though. Many thanks for your help !

Thanks a lot. This worked for me. My CUDA version is 10.0 and cuDNN is 7.4.2I am running into the same problem. My dev env is a docker (built according to https://www.tensorflow.org/install/docker) as follows:
1. Host OS: Ubuntu 18.04
2. GPU: RTX 2070
3. NVidia driver: 418.56
4. cuda ver: 10.1
5. Nvidia cuda docker image: nvidia/cuda:latest
6. The custom docker built based on tensorflow/tensorflow:latest-gpu-py3-jupyter.
7. tensorflow version: 1.13.1
8. running from jupyter inside the docker.

I couldn't find cuDNN.h neither from my host OS env nor from Nvidia cuda docker container and tensorflow docker container. It seems that the instruction provided by tensorflow team is missing the component. While I am going to explore a fix, I thought that someone out there, who may have fixed the problem in the same setting, may save my day by sharing his solution.

Thanks in advance
ChrisTry adding these lines of code in your notebook after you import tensorflow as mentioned by oscarlinux

```
from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession
config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)
```> Try adding these lines of code in your notebook after you import tensorflow as mentioned by oscarlinux
> 
> ```
> from tensorflow.compat.v1 import ConfigProto
> from tensorflow.compat.v1 import InteractiveSession
> config = ConfigProto()
> config.gpu_options.allow_growth = True
> session = InteractiveSession(config=config)
> ```

Thanks jiteshm17. I have tried it without success. I am now running in eager execution mode. It's not working either.@chris-opendata, may I please know your cuDNN version??
My CUDA version is 10.0 ,cuDNN is 7.4.2 and even I use the Tensorflow(gpu) version of 1.13.1.
 I had the same error before but after adding those above lines, the error disappeared. If possible, try to change the CUDA version to 10.
I would also recommend you to go through the following article to install CUDA 10 if possible.
https://medium.com/@cjanze/how-to-install-tensorflow-with-gpu-support-on-ubuntu-18-04-lts-with-cuda-10-nvidia-gpu-312a693744b5Thanks jiteshm17. I have the same versions as yours. the remedy doesn't work though. One thing puzzles me that I couldn't find cudnn.h file as mentioned by the other issue tracker threads. I use runtime only that comes as default in tensorflow/tensorflow:latest-gpu-py3-jupyter docker image. May I ask if you have cudnn.h in your docker container? and does your docker use cudnn development packege instead of runtime only package?i just reinstall the tensorflow 1.13.1 and then install keras
 it works!Delete the current cudnn and install the version 7.2.4 for CUDA 9.0 using tensorflow 1.12.0 works for me. Thanks for all.> OK, I was able to execute my CNN. I'm using tensorflow tf-nightly-gpu-2.0-preview, and running on a ipython notebook. I had to add this to my notebook:
> 
> from tensorflow.compat.v1 import ConfigProto
> from tensorflow.compat.v1 import InteractiveSession
> 
> config = ConfigProto()
> config.gpu_options.allow_growth = True
> session = InteractiveSession(config=config)
> 
> [Here](https://www.tensorflow.org/guide/using_gpu) are some more details
> 
> Also, this issue is associated with [24496] (#24496)

I had the same issue and solved it using this method. 
I was running Tensorflow 2.0 alpha with Cuda v10.1 and Cudnn v7.5.1. I downgraded the versions to Cuda v10.0 and Cudnn v7.5.4, and added these ''allow_growth' option to my code. Its working perfectly now.Windows 10 fix:

System:
    TensorFlow version: 1.12
    Python version: 3.6
    Installed using virtualenv? pip? conda?: conda
    Bazel version (if compiling from source): 0.18
    GCC/Compiler version (if compiling from source): gcc 5.4.0
    CUDA SDK/cuDNN version: Cudnn - 10.0 , CUDA- 9.0
    GPU model and memory: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8225 8GB

DO NOT DOWNGRADE TO TENSORFLOW-GPU ==1.8.0 IT WILL NOT WORK AND CORRUPT YOUR ENV.

Solution: Manually download and install the cuDNN yourself using the instructions from NVIDIA. After you do that it will work just fine.Linux Ubuntu 18.04 TensorFlow 2.0  fix:

System:
os: Linux Ubuntu 18.04
python: 3.6.7
tensorflow: 2.0.0-alpha0
keras: 2.2.4-tf
GPU:  GeForce RTX 2070 with Max-Q Design
Driver: 410.104
CUDA: Cuda compilation tools, release 10.0, V10.0.130
CUDNN: libcudnn7_7.4.2.24-1+cuda10.0_amd64

Installed with help of this  [tutorial](https://medium.com/@cjanze/how-to-install-tensorflow-with-gpu-support-on-ubuntu-18-04-lts-with-cuda-10-nvidia-gpu-312a693744b5?fbclid=IwAR2YmBjd7oCpkSpOsvtx9jrqC-G15y4EA1s-JRsgPaucH09cZMjuOvwVckw)

Fix: Before defining model I have added following line of code:
`tf.config.gpu.set_per_process_memory_growth(True)`

For instance:
```
#Data import and parsing...

#Enable gpu memory gowth
tf.config.gpu.set_per_process_memory_growth(True)

#Some model that uses conv layers
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))
model.summary()

#Training
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=50)
```

from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession
config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

Adding this to my train.py solved thisSo, one solution is to use the allow_growth setting, but does anyone know how to use that with Estimators where we do not directly specify the session?Check nvidia-smi in Ubuntu
and kill processes taking cuda memory by "kill -9 <pid>"
This should free up memoryI am working on kaggle, and every thing work fine, suddenly this problem start arising@KennethKJ I'm not familiar with using Estimators, but maybe this approach will help. 

According to tensorflow documentation (https://www.tensorflow.org/guide/using_gpu), you can also tell it to allow memory growth by setting the environment variable TF_FORCE_GPU_ALLOW_GROWTH to true. The documentation says this configuration is platform specific, so YMMV (works for me with Ubuntu 18.04).This fixed the error for me:

    tf.debugging.set_log_device_placement(True)
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
      try:
        # Currently, memory growth needs to be the same across GPUs
        for gpu in gpus:
          tf.config.experimental.set_memory_growth(gpu, True)
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
      except RuntimeError as e:
        # Memory growth must be set before GPUs have been initialized
        print(e)

I also used cudnn 7.4, but not sure if that mattered.I had the same problem. I have tf 1.4, 1.5 and 2.0 with cudnn 9.0 and 10.0
The problem appeared with tf 2.0 when I was opening Jupyter Notebooks with conda navigator. When I go through cmd --> "activate my_environment" and than "jupyter notebook"  it works fine. But when I want to open another notebook  - the same problem again, so another cmd window and repeat the operation. Its a silly workaround but it works for me. Something messed up with conda navigator.I had this problem with `tf 1.14, cuda 10.1, cudnn 7.6.0`. The error is gone if I downgrade tf to `1.12 ` or `1.13.1` with `config.gpu_options.allow_growth = True`@KennethKJ here's how I set estimator:
```
s_config = tf.ConfigProto()
s_config.gpu_options.allow_growth = True
config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir, session_config=s_config)
```For Tensorflow 2.0 setting allow_growth worked for me like this:

```
for gpu in tf.config.experimental.list_physical_devices('GPU'):
	tf.compat.v2.config.experimental.set_memory_growth(gpu, True)
```

@ymodak: This issue is still totally active. Can you reopen it, as you pointed out in the close message? There should be a fix from the tensorflow side so that we don't have to rely on this hack.
Alternatively setting the GPU memory fraction also works

Op wo 17 jul. 2019 om 14:14 schreef Andreas Eberle <notifications@github.com
>:

> For Tensorflow 2.0 setting allow_growth worked for me like this:
>
> for gpu in tf.config.experimental.list_physical_devices('GPU'):
> 	tf.compat.v2.config.experimental.set_memory_growth(gpu, True)
>
> @ymodak <https://github.com/ymodak>: This issue is still totally active.
> Can you reopen it, as you pointed out in the close message? There should be
> a fix from the tensorflow side so that we don't have to rely on this hack.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/tensorflow/issues/24828?email_source=notifications&email_token=ABQ5OCLX5UZ4ARCLX6DMFQLP74EMDA5CNFSM4GPFXRT2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD2D7EOI#issuecomment-512225849>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABQ5OCLKIJAIEDDRXLT4YY3P74EMDANCNFSM4GPFXRTQ>
> .
>
> 
> 
> OK, I was able to execute my CNN. I'm using tensorflow tf-nightly-gpu-2.0-preview, and running on a ipython notebook. I had to add this to my notebook:
> 
> from tensorflow.compat.v1 import ConfigProto
> from tensorflow.compat.v1 import InteractiveSession
> 
> config = ConfigProto()
> config.gpu_options.allow_growth = True
> session = InteractiveSession(config=config)
> 
> [Here](https://www.tensorflow.org/guide/using_gpu) are some more details
> 
> Also, this issue is associated with [24496] (#24496)

Confirming this fix on tf 1.14 installed using pip (inside anaconda) on python 3.7.3. CUDA Toolkit 10.0, cudnn 10.0, windows 10.Hey guys, I am using the weights from the pre-trained model with ResNet50 backbone on COCO dataset to train on my CSV dataset. I am getting this error : *Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning │ log message was printed above.*I am running the following command in a virtual environment on Ubuntu 16.0 to for training.:   keras-retinanet/keras_retinanet/bin/train.py --weights resnet50_coco_best_v2.1.0.h5 \
--batch-size 7 --steps 9 --epochs 4 \
--snapshot-path snapshots --tensorboard-dir tensorboard \
csv dataset/train.csv dataset/classes.csvI tried to resolve the problem by the following script in command line in the virtual environment:
python

  import tensorflow

    >> from tensorflow.compat.v1 import ConfigProto
    >> from tensorflow.compat.v1 import InteractiveSession
    >> config = ConfigProto()
    >> config.gpu_options.allow_growth = True
    >> session = InteractiveSession(config=config)

  as well as
  import tensorflow as tf
  config = tf.ConfigProto()
  config.gpu_options.allow_growth = True
  session = tf.Session(config=config)but it did not resolve my error.:

I am using:-
  Ubuntu 16.0
  Cuda: 10.0
  Tensorflow 1.14.0

Error:
  tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.                                                                │|  No running processes found                                                 |
   (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning │+-----------------------------------------------------------------------------+
  log message was printed above.                                                                                                              │
          [[{{node conv1/convolution}}]]                                                                                                     │
          [[loss/add/_2377]]                                                                                                                 │
   (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning │
  log message was printed above.                                                                                                              │
          [[{{node conv1/convolution}}]]                                                                                                     │
  0 successful operations.                                                                                                                    │
  0 derived errors ignored.                                                                                                                   │
  terminate called without an active exception                                                                                                │
  Aborted (core dumped)
  Any help would be appreciated.@meghasharmaojha 
Can you try this instead?

config = tf.ConfigProto()
config.gpu_options.allow_growth = True
tf.keras.backend.set_session(tf.Session(config=config))

Another option is to set the environment variable TF_FORCE_GPU_ALLOW_GROWTH to true. I think this only will work for some setups, but it did for me with Ubuntu 18.04.

I had this problem with
```
tf 1.12, cuda 9.0, cudnn 7.x # I forget the cudnn version...maybe 7.0
or
tf 1.13, cuda 10.0, cudnn 7.4.1.5
```
and `allow_growth` doesn't help.

The error is gone with `tf 1.13, cuda 10.0, cudnn 7.5.0`.
BTW, I'm using Ubuntu 16.04 with nvidia-driver-418.Thanks for posting this guys. I had similar issues, adding the below to my train.py right after import tensorflow worked for me:

from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession
config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

System Specs is:
Windows 10
NVIDIA 2070 RTX GPU
Python 3.7
Cuda 10
Cudnn 7.6.2.24
x64


@BabaGodPikin Thanks for sharing. What version of Tensorflow are you using?@dorian821 Tensorflow 1.14. Installed with pip install tensorflow-gpu.

I initially did conda install -c anaconda tensorflow-gpu (this installed version 1.13). When I had the error, I removed this installation (1.13) and tried the tensorflow recommended "pip install tensorflow-gpu" (this installed version 1.14). It still didn't work till I added the 5 lines in my previous post above.

@BabaGodPikin thank you for sharing that fix - can confirm it worked for me with the same specs. To put it simply, you need to install tensorflow-gpu with conda (version 1.13), then uninstall it, then install it with pip (which will install version 1.14). Then you need to add code similar to what you included (I used 
`config = tf.ConfigProto()`

`config.gpu_options.allow_growth = True`

`tf.keras.backend.set_session(tf.Session(config=config))`
personally).

Thanks again for yours and everyone else's help. 

One question - does anyone know if turning on the allow growth option has any impact on performance?In my case, I tried different version of cudnn package and then it works. Please kindly know that there are few different versions of cudnn for one specific version of CUDA.@blueclowd Which version of cudnn did you use? Could you please list your system specs?> @blueclowd Which version of cudnn did you use? Could you please list your system specs?

**Fail combination:**
cuda_10.0.130_411.31_win10  + cudnn-10.0-windows10-x64-v7.6.2

**Successful combination:**
cuda_10.0.130_411.31_win10 + cudnn-10.0-windows10-x64-v7.5.1.10
I had the same issue with tensorflow-gpu (1.13.1)  , set the environment variable `TF_FORCE_GPU_ALLOW_GROWTH` to true, it's worked for me. 

```
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
tf.keras.backend.set_session(tf.Session(config=config))
```

environment：
```
Ubuntu 18.04
tensorflow-gpu (1.13.1)
CUDA Version 10.0.130
libcudnn7 on system is 7.6.0.64-1
```I got the same problem using `tensorflow-gpu==2.0.0-rc0` on a kaggle kernel (it was working fine with TF beta release):

```
Epoch 1/100
---------------------------------------------------------------------------
UnknownError                              Traceback (most recent call last)
<ipython-input-14-33dfc7b6ba62> in <module>
     10     class_weight=class_weights,
     11     callbacks=[
---> 12         model_checkpoint
     13     ]
     14 )

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1301         shuffle=shuffle,
   1302         initial_epoch=initial_epoch,
-> 1303         steps_name='steps_per_epoch')
   1304 
   1305   def evaluate_generator(self,

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)
    263 
    264       is_deferred = not model._is_compiled
--> 265       batch_outs = batch_function(*batch_data)
    266       if not isinstance(batch_outs, list):
    267         batch_outs = [batch_outs]

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics)
    977       outputs = training_v2_utils.train_on_batch(
    978           self, x, y=y, sample_weight=sample_weight,
--> 979           class_weight=class_weight, reset_metrics=reset_metrics)
    980       outputs = (outputs['total_loss'] + outputs['output_losses'] +
    981                  outputs['metrics'])

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics)
    262       y,
    263       sample_weights=sample_weights,
--> 264       output_loss_metrics=model._output_loss_metrics)
    265 
    266   if reset_metrics:

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics)
    309           sample_weights=sample_weights,
    310           training=True,
--> 311           output_loss_metrics=output_loss_metrics))
    312   if not isinstance(outs, list):
    313     outs = [outs]

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py in _process_single_batch(model, inputs, targets, output_loss_metrics, sample_weights, training)
    250               output_loss_metrics=output_loss_metrics,
    251               sample_weights=sample_weights,
--> 252               training=training))
    253       if total_loss is None:
    254         raise ValueError('The model cannot be run '

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py in _model_loss(model, inputs, targets, output_loss_metrics, sample_weights, training)
    125     inputs = nest.map_structure(ops.convert_to_tensor, inputs)
    126 
--> 127   outs = model(inputs, **kwargs)
    128   outs = nest.flatten(outs)
    129 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    849           with base_layer_utils.autocast_context_manager(
    850               self._compute_dtype):
--> 851             outputs = self.call(cast_inputs, *args, **kwargs)
    852           self._handle_activity_regularization(inputs, outputs)
    853           self._set_mask_metadata(inputs, outputs, input_masks)

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py in call(self, inputs, training, mask)
    253       if not self.built:
    254         self._init_graph_network(self.inputs, self.outputs, name=self.name)
--> 255       return super(Sequential, self).call(inputs, training=training, mask=mask)
    256 
    257     outputs = inputs  # handle the corner case where self.layers is empty

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in call(self, inputs, training, mask)
    695                                 ' implement a `call` method.')
    696 
--> 697     return self._run_internal_graph(inputs, training=training, mask=mask)
    698 
    699   def compute_output_shape(self, input_shape):

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in _run_internal_graph(self, inputs, training, mask)
    840 
    841           # Compute outputs.
--> 842           output_tensors = layer(computed_tensors, **kwargs)
    843 
    844           # Update tensor_dict.

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    849           with base_layer_utils.autocast_context_manager(
    850               self._compute_dtype):
--> 851             outputs = self.call(cast_inputs, *args, **kwargs)
    852           self._handle_activity_regularization(inputs, outputs)
    853           self._set_mask_metadata(inputs, outputs, input_masks)

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional.py in call(self, inputs)
    195 
    196   def call(self, inputs):
--> 197     outputs = self._convolution_op(inputs, self.kernel)
    198 
    199     if self.use_bias:

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py in __call__(self, inp, filter)
   1132           call_from_convolution=False)
   1133     else:
-> 1134       return self.conv_op(inp, filter)
   1135     # copybara:strip_end
   1136     # copybara:insert return self.conv_op(inp, filter)

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py in __call__(self, inp, filter)
    637 
    638   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin
--> 639     return self.call(inp, filter)
    640 
    641 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py in __call__(self, inp, filter)
    236         padding=self.padding,
    237         data_format=self.data_format,
--> 238         name=self.name)
    239 
    240 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)
   2008                            data_format=data_format,
   2009                            dilations=dilations,
-> 2010                            name=name)
   2011 
   2012 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)
   1029             input, filter, strides=strides, use_cudnn_on_gpu=use_cudnn_on_gpu,
   1030             padding=padding, explicit_paddings=explicit_paddings,
-> 1031             data_format=data_format, dilations=dilations, name=name, ctx=_ctx)
   1032       except _core._SymbolicException:
   1033         pass  # Add nodes to the TensorFlow graph.

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py in conv2d_eager_fallback(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)
   1128   explicit_paddings, "data_format", data_format, "dilations", dilations)
   1129   _result = _execute.execute(b"Conv2D", 1, inputs=_inputs_flat, attrs=_attrs,
-> 1130                              ctx=_ctx, name=name)
   1131   _execute.record_gradient(
   1132       "Conv2D", _inputs_flat, _attrs, _result, name)

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

/opt/conda/lib/python3.6/site-packages/six.py in raise_from(value, from_value)

UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]
```Getting this problem with all the new preview-2.0 builds.
The last one that worked for me was: tf-nightly-gpu-2.0-preview==2.0.0.dev20190709> Hi, I had the same error.
> Download the cudnn package for my system and replace it with the old ones.
> This solved my problem.
Tensorflow2.0.0 use which cudnn？
> I got the same problem using `tensorflow-gpu==2.0.0-rc0` on a kaggle kernel (it was working fine with TF beta release):
> 
> ```
> Epoch 1/100
> ---------------------------------------------------------------------------
> UnknownError                              Traceback (most recent call last)
> <ipython-input-14-33dfc7b6ba62> in <module>
>      10     class_weight=class_weights,
>      11     callbacks=[
> ---> 12         model_checkpoint
>      13     ]
>      14 )
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
>    1301         shuffle=shuffle,
>    1302         initial_epoch=initial_epoch,
> -> 1303         steps_name='steps_per_epoch')
>    1304 
>    1305   def evaluate_generator(self,
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)
>     263 
>     264       is_deferred = not model._is_compiled
> --> 265       batch_outs = batch_function(*batch_data)
>     266       if not isinstance(batch_outs, list):
>     267         batch_outs = [batch_outs]
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics)
>     977       outputs = training_v2_utils.train_on_batch(
>     978           self, x, y=y, sample_weight=sample_weight,
> --> 979           class_weight=class_weight, reset_metrics=reset_metrics)
>     980       outputs = (outputs['total_loss'] + outputs['output_losses'] +
>     981                  outputs['metrics'])
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics)
>     262       y,
>     263       sample_weights=sample_weights,
> --> 264       output_loss_metrics=model._output_loss_metrics)
>     265 
>     266   if reset_metrics:
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics)
>     309           sample_weights=sample_weights,
>     310           training=True,
> --> 311           output_loss_metrics=output_loss_metrics))
>     312   if not isinstance(outs, list):
>     313     outs = [outs]
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py in _process_single_batch(model, inputs, targets, output_loss_metrics, sample_weights, training)
>     250               output_loss_metrics=output_loss_metrics,
>     251               sample_weights=sample_weights,
> --> 252               training=training))
>     253       if total_loss is None:
>     254         raise ValueError('The model cannot be run '
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py in _model_loss(model, inputs, targets, output_loss_metrics, sample_weights, training)
>     125     inputs = nest.map_structure(ops.convert_to_tensor, inputs)
>     126 
> --> 127   outs = model(inputs, **kwargs)
>     128   outs = nest.flatten(outs)
>     129 
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
>     849           with base_layer_utils.autocast_context_manager(
>     850               self._compute_dtype):
> --> 851             outputs = self.call(cast_inputs, *args, **kwargs)
>     852           self._handle_activity_regularization(inputs, outputs)
>     853           self._set_mask_metadata(inputs, outputs, input_masks)
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py in call(self, inputs, training, mask)
>     253       if not self.built:
>     254         self._init_graph_network(self.inputs, self.outputs, name=self.name)
> --> 255       return super(Sequential, self).call(inputs, training=training, mask=mask)
>     256 
>     257     outputs = inputs  # handle the corner case where self.layers is empty
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in call(self, inputs, training, mask)
>     695                                 ' implement a `call` method.')
>     696 
> --> 697     return self._run_internal_graph(inputs, training=training, mask=mask)
>     698 
>     699   def compute_output_shape(self, input_shape):
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in _run_internal_graph(self, inputs, training, mask)
>     840 
>     841           # Compute outputs.
> --> 842           output_tensors = layer(computed_tensors, **kwargs)
>     843 
>     844           # Update tensor_dict.
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
>     849           with base_layer_utils.autocast_context_manager(
>     850               self._compute_dtype):
> --> 851             outputs = self.call(cast_inputs, *args, **kwargs)
>     852           self._handle_activity_regularization(inputs, outputs)
>     853           self._set_mask_metadata(inputs, outputs, input_masks)
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional.py in call(self, inputs)
>     195 
>     196   def call(self, inputs):
> --> 197     outputs = self._convolution_op(inputs, self.kernel)
>     198 
>     199     if self.use_bias:
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py in __call__(self, inp, filter)
>    1132           call_from_convolution=False)
>    1133     else:
> -> 1134       return self.conv_op(inp, filter)
>    1135     # copybara:strip_end
>    1136     # copybara:insert return self.conv_op(inp, filter)
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py in __call__(self, inp, filter)
>     637 
>     638   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin
> --> 639     return self.call(inp, filter)
>     640 
>     641 
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py in __call__(self, inp, filter)
>     236         padding=self.padding,
>     237         data_format=self.data_format,
> --> 238         name=self.name)
>     239 
>     240 
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)
>    2008                            data_format=data_format,
>    2009                            dilations=dilations,
> -> 2010                            name=name)
>    2011 
>    2012 
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)
>    1029             input, filter, strides=strides, use_cudnn_on_gpu=use_cudnn_on_gpu,
>    1030             padding=padding, explicit_paddings=explicit_paddings,
> -> 1031             data_format=data_format, dilations=dilations, name=name, ctx=_ctx)
>    1032       except _core._SymbolicException:
>    1033         pass  # Add nodes to the TensorFlow graph.
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py in conv2d_eager_fallback(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)
>    1128   explicit_paddings, "data_format", data_format, "dilations", dilations)
>    1129   _result = _execute.execute(b"Conv2D", 1, inputs=_inputs_flat, attrs=_attrs,
> -> 1130                              ctx=_ctx, name=name)
>    1131   _execute.record_gradient(
>    1132       "Conv2D", _inputs_flat, _attrs, _result, name)
> 
> /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
>      65     else:
>      66       message = e.message
> ---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
>      68   except TypeError as e:
>      69     keras_symbolic_tensors = [
> 
> /opt/conda/lib/python3.6/site-packages/six.py in raise_from(value, from_value)
> 
> UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]
> ```

i also found this issues, and it worked when i changed the version from tensorflow-gpu==2.0.0-rc0 to tensorflow-gpu==2.0.0-beta1 in kaggle kernel> > Hi, I had the same error.
> > Download the cudnn package for my system and replace it with the old ones.
> > This solved my problem.
> > Tensorflow2.0.0 use which cudnn？

I believe any build starting 7.6 and above should work fine.> This error may be related to installation TF with `conda`.
> 
> The possible solution is like this:
> In the command line issue this command:
> `conda list cudnn`
> It will print:
> ` Name Version Build Channel`
> 
> If the result is not empty as the above, so it means you used conda installed TF, when using conda for installing TF, then it will install all the dependencies even CUDA and cuDNN, but the cuDNN version is very low for TF, so it will bring compatibility problem. So you can uninstall the cuDNN and the CUDA which was installed by conda, and then run TF, then it will work.

I have created virtual env with version 3.7 using anaconda navigator and then install keras-gpu and now its showing me 
`cudnn                     7.6.0                cuda10.0_0`
when i was using virtual env at python 3.6, it show me blankI came across the same issue, however, simply because GPU was fully occupied by some process called ZMQbg/1. After I killed it, this error did not show up again. So perhaps run `nvidia-smi` to check the GPU memory. 1) Close all other notebooks, that use GPU

2) TF 2.0 needs [cuDNN SDK](https://developer.nvidia.com/cudnn) (>= 7.4.1)

extract and add path to 'bin' folder into "environment variables / system variables / path": "D:\Programs\x64\Nvidia\cudnn\bin"Were you able to fix this @talhaanwarch. I am using conda for installation. I tried with python 3.6 and tensorflow 1.13.1 as well as python 3.7 together with tensorflow 1.14. I am using Cuda 10.0 and cudnn 7.6.0> Were you able to fix this @talhaanwarch. I am using conda for installation. I tried with python 3.6 and tensorflow 1.13.1 as well as python 3.7 together with tensorflow 1.14. I am using Cuda 10.0 and cudnn 7.6.0

yes, i do. i installed latest version of every things.
my steps are as follows  
1-install Cuda 10.0
2- Create a virtual environmnet (python 3.7)  
3- install keras gpu (from anaconda navigator)  
my tensorflow version is 1.14.0
keras version is 2.2.4
> > Were you able to fix this @talhaanwarch. I am using conda for installation. I tried with python 3.6 and tensorflow 1.13.1 as well as python 3.7 together with tensorflow 1.14. I am using Cuda 10.0 and cudnn 7.6.0
> 
> yes, i do. i installed latest version of every things.
> my steps are as follows
> 1-install Cuda 10.0
> 2- Create a virtual environmnet (python 3.7)
> 3- install keras gpu (from anaconda navigator)
> my tensorflow version is 1.14.0
> keras version is 2.2.4

I'm still getting the same error. Here's the output the `conda list`
```
(talhaan) C:\Users\mazat\Documents>conda list
# packages in environment at C:\Users\mazat\Anaconda3\envs\talhaan:
#
# Name                    Version                   Build  Channel
_tflow_select             2.1.0                       gpu    anaconda
absl-py                   0.8.0                    py37_0    anaconda
alabaster                 0.7.12                   py37_0
asn1crypto                0.24.0                   py37_0
astor                     0.8.0                    py37_0    anaconda
astroid                   2.3.1                    py37_0
attrs                     19.1.0                   py37_1
babel                     2.7.0                      py_0
backcall                  0.1.0                    py37_0
blas                      1.0                         mkl    anaconda
bleach                    3.1.0                    py37_0
ca-certificates           2019.9.11            hecc5488_0    conda-forge
certifi                   2019.9.11                py37_0
cffi                      1.12.3           py37h7a1dbc1_0
chardet                   3.0.4                 py37_1003
cloudpickle               1.2.2                      py_0
colorama                  0.4.1                    py37_0
cryptography              2.7              py37h7a1dbc1_0
cudatoolkit               10.0.130                      0    anaconda
cudnn                     7.6.0                cuda10.0_0    anaconda
cycler                    0.10.0                     py_1    conda-forge
cytoolz                   0.10.0           py37hfa6e2cd_0    conda-forge
dask-core                 2.5.0                      py_0    conda-forge
decorator                 4.4.0                    py37_1
defusedxml                0.6.0                      py_0
docutils                  0.15.2                   py37_0
entrypoints               0.3                      py37_0
freetype                  2.9.1                ha9979f8_1
gast                      0.3.2                      py_0    anaconda
grpcio                    1.16.1           py37h351948d_1    anaconda
h5py                      2.9.0            py37h5e291fa_0    anaconda
hdf5                      1.10.4               h7ebc959_0    anaconda
icc_rt                    2019.0.0             h0cc432a_1    anaconda
icu                       58.2                 ha66f8fd_1
idna                      2.8                      py37_0
imageio                   2.5.0                    py37_0    conda-forge
imagesize                 1.1.0                    py37_0
intel-openmp              2019.5                      281    anaconda
ipykernel                 5.1.2            py37h39e3cac_0
ipython                   7.8.0            py37h39e3cac_0
ipython_genutils          0.2.0                    py37_0
isort                     4.3.21                   py37_0
jedi                      0.15.1                   py37_0
jinja2                    2.10.1                   py37_0
joblib                    0.13.2                   py37_0
jpeg                      9b                   hb83a4c4_2
jsonschema                3.0.2                    py37_0
jupyter_client            5.3.3                    py37_1
jupyter_core              4.5.0                      py_0
keras-applications        1.0.8                      py_0    anaconda
keras-base                2.2.4                    py37_0    anaconda
keras-gpu                 2.2.4                         0    anaconda
keras-preprocessing       1.1.0                      py_1    anaconda
keyring                   18.0.0                   py37_0
kiwisolver                1.1.0            py37he980bc4_0    conda-forge
lazy-object-proxy         1.4.2            py37he774522_0
libpng                    1.6.37               h2a8f88b_0
libprotobuf               3.9.2                h7bd577a_0    anaconda
libsodium                 1.0.16               h9d3ae62_0
libtiff                   4.0.10               hb898794_2
markdown                  3.1.1                    py37_0    anaconda
markupsafe                1.1.1            py37he774522_0
matplotlib-base           3.1.1            py37h2852a4a_1    conda-forge
mccabe                    0.6.1                    py37_1
mistune                   0.8.4            py37he774522_0
mkl                       2019.5                      281    anaconda
mkl-service               2.3.0            py37hb782905_0    anaconda
mkl_fft                   1.0.14           py37h14836fe_0    anaconda
mkl_random                1.1.0            py37h675688f_0    anaconda
nbconvert                 5.6.0                    py37_1
nbformat                  4.4.0                    py37_0
networkx                  2.3                        py_0    conda-forge
numpy                     1.16.5           py37h19fb1c0_0    anaconda
numpy-base                1.16.5           py37hc3f5095_0    anaconda
numpydoc                  0.9.1                      py_0
olefile                   0.46                     py37_0
opencv-python             4.1.1.26                 pypi_0    pypi
openssl                   1.1.1                he774522_0    anaconda
packaging                 19.2                       py_0
pandas                    0.25.1           py37ha925a31_0    anaconda
pandoc                    2.2.3.2                       0
pandocfilters             1.4.2                    py37_1
parso                     0.5.1                      py_0
pickleshare               0.7.5                    py37_0
pillow                    6.1.0            py37hdc69c19_0
pip                       19.2.3                   py37_0    anaconda
prompt_toolkit            2.0.9                    py37_0
protobuf                  3.9.2            py37h33f27b4_0    anaconda
psutil                    5.6.3            py37he774522_0
pycodestyle               2.5.0                    py37_0
pycparser                 2.19                     py37_0
pyflakes                  2.1.1                    py37_0
pygments                  2.4.2                      py_0
pylint                    2.4.2                    py37_0
pyopenssl                 19.0.0                   py37_0
pyparsing                 2.4.2                      py_0
pyqt                      5.9.2            py37h6538335_2
pyreadline                2.1                      py37_1    anaconda
pyrsistent                0.15.4           py37he774522_0
pysocks                   1.7.1                    py37_0
python                    3.7.4                h5263a28_0    anaconda
python-dateutil           2.8.0                    py37_0
pytz                      2019.2                     py_0
pywavelets                1.0.3            py37h452e1ab_1    conda-forge
pywin32                   223              py37hfa6e2cd_1
pyyaml                    5.1.2            py37he774522_0    anaconda
pyzmq                     18.1.0           py37ha925a31_0
qt                        5.9.7            vc14h73c81de_0
qtawesome                 0.6.0                      py_0
qtconsole                 4.5.5                      py_0
qtpy                      1.9.0                      py_0
requests                  2.22.0                   py37_0
rope                      0.14.0                     py_0
scikit-image              0.15.0           py37he350917_2    conda-forge
scikit-learn              0.21.3           py37h6288b17_0
scipy                     1.3.1            py37h29ff71c_0    anaconda
setuptools                41.2.0                   py37_0    anaconda
sip                       4.19.8           py37h6538335_0
six                       1.12.0                   py37_0    anaconda
snowballstemmer           1.9.1                      py_0
sphinx                    2.2.0                      py_0
sphinxcontrib-applehelp   1.0.1                      py_0
sphinxcontrib-devhelp     1.0.1                      py_0
sphinxcontrib-htmlhelp    1.0.2                      py_0
sphinxcontrib-jsmath      1.0.1                      py_0
sphinxcontrib-qthelp      1.0.2                      py_0
sphinxcontrib-serializinghtml 1.1.3                      py_0
spyder                    3.3.6                    py37_0
spyder-kernels            0.5.2                    py37_0
sqlite                    3.29.0               he774522_0    anaconda
tensorboard               1.14.0           py37he3c9ec2_0    anaconda
tensorflow                1.14.0          gpu_py37h5512b17_0    anaconda
tensorflow-base           1.14.0          gpu_py37h55fc52a_0    anaconda
tensorflow-estimator      1.14.0                     py_0    anaconda
tensorflow-gpu            1.14.0               h0d30ee6_0    anaconda
termcolor                 1.1.0                    py37_1    anaconda
testpath                  0.4.2                    py37_0
tk                        8.6.8                hfa6e2cd_0
toolz                     0.10.0                     py_0    conda-forge
tornado                   6.0.3            py37he774522_0
traitlets                 4.3.2                    py37_0
urllib3                   1.24.2                   py37_0
vc                        14.1                 h0510ff6_4    anaconda
vs2015_runtime            14.16.27012          hf0eaf9b_0    anaconda
wcwidth                   0.1.7                    py37_0
webencodings              0.5.1                    py37_1
werkzeug                  0.16.0                     py_0    anaconda
wheel                     0.33.6                   py37_0    anaconda
win_inet_pton             1.1.0                    py37_0
wincertstore              0.2                      py37_0    anaconda
wrapt                     1.11.2           py37he774522_0    anaconda
xz                        5.2.4                h2fa13f4_4
yaml                      0.1.7            vc14h4cb57cf_1  [vc14]  anaconda
zeromq                    4.3.1                h33f27b4_3
zlib                      1.2.11           vc14h1cdd9ab_1  [vc14]  anaconda
zstd                      1.3.7                h508b16e_0

```
And the error:
```

  File "<ipython-input-1-c77ea08f5c30>", line 1, in <module>
    runfile('C:/Users/mazat/Documents/Python/MVTools/player_detector/player_detector_testing.py', wdir='C:/Users/mazat/Documents/Python/MVTools/player_detector')

  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\spyder_kernels\customize\spydercustomize.py", line 827, in runfile
    execfile(filename, namespace)

  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\spyder_kernels\customize\spydercustomize.py", line 110, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File "C:/Users/mazat/Documents/Python/MVTools/player_detector/player_detector_testing.py", line 404, in <module>
    player_detector_run()

  File "C:/Users/mazat/Documents/Python/MVTools/player_detector/player_detector_testing.py", line 397, in player_detector_run
    glavnaya(dropbox_folder,gamename,mvstatus)

  File "C:/Users/mazat/Documents/Python/MVTools/player_detector/player_detector_testing.py", line 252, in glavnaya
    __,box1,score = yolo_class.detect_images(im2[ii].astype('uint8'))

  File "C:\Users\mazat\Documents\Python\MVTools\player_detector\yolo3\yolo3.py", line 181, in detect_images
    K.learning_phase(): 0

  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tensorflow\python\client\session.py", line 950, in run
    run_metadata_ptr)

  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tensorflow\python\client\session.py", line 1173, in _run
    feed_dict_tensor, options, run_metadata)

  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tensorflow\python\client\session.py", line 1350, in _do_run
    run_metadata)

  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tensorflow\python\client\session.py", line 1370, in _do_call
    raise type(e)(node_def, op, message)

UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node conv2d_1/convolution (defined at C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\keras\backend\tensorflow_backend.py:3650) ]]
	 [[concat_11/_2833]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node conv2d_1/convolution (defined at C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\keras\backend\tensorflow_backend.py:3650) ]]
0 successful operations.
0 derived errors ignored.

Errors may have originated from an input operation.
Input Source operations connected to node conv2d_1/convolution:
 conv2d_1/kernel/read (defined at C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\keras\backend\tensorflow_backend.py:402)	
 input_1 (defined at C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\keras\backend\tensorflow_backend.py:517)

Input Source operations connected to node conv2d_1/convolution:
 conv2d_1/kernel/read (defined at C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\keras\backend\tensorflow_backend.py:402)	
 input_1 (defined at C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\keras\backend\tensorflow_backend.py:517)

Original stack trace for 'conv2d_1/convolution':
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\spyder_kernels\console\__main__.py", line 11, in <module>
    start.main()
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\spyder_kernels\console\start.py", line 318, in main
    kernel.start()
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\ipykernel\kernelapp.py", line 563, in start
    self.io_loop.start()
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tornado\platform\asyncio.py", line 148, in start
    self.asyncio_loop.run_forever()
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\asyncio\base_events.py", line 534, in run_forever
    self._run_once()
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\asyncio\base_events.py", line 1771, in _run_once
    handle._run()
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\asyncio\events.py", line 88, in _run
    self._context.run(self._callback, *self._args)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tornado\ioloop.py", line 690, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tornado\gen.py", line 787, in inner
    self.run()
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tornado\gen.py", line 748, in run
    yielded = self.gen.send(value)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\ipykernel\kernelbase.py", line 365, in process_one
    yield gen.maybe_future(dispatch(*args))
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tornado\gen.py", line 209, in wrapper
    yielded = next(result)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\ipykernel\kernelbase.py", line 272, in dispatch_shell
    yield gen.maybe_future(handler(stream, idents, msg))
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tornado\gen.py", line 209, in wrapper
    yielded = next(result)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\ipykernel\kernelbase.py", line 542, in execute_request
    user_expressions, allow_stdin,
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tornado\gen.py", line 209, in wrapper
    yielded = next(result)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\ipykernel\ipkernel.py", line 294, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\ipykernel\zmqshell.py", line 536, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\IPython\core\interactiveshell.py", line 2855, in run_cell
    raw_cell, store_history, silent, shell_futures)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\IPython\core\interactiveshell.py", line 2881, in _run_cell
    return runner(coro)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\IPython\core\async_helpers.py", line 68, in _pseudo_sync_runner
    coro.send(None)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\IPython\core\interactiveshell.py", line 3058, in run_cell_async
    interactivity=interactivity, compiler=compiler, result=result)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\IPython\core\interactiveshell.py", line 3249, in run_ast_nodes
    if (await self.run_code(code, result,  async_=asy)):
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\IPython\core\interactiveshell.py", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-1-c77ea08f5c30>", line 1, in <module>
    runfile('C:/Users/mazat/Documents/Python/MVTools/player_detector/player_detector_testing.py', wdir='C:/Users/mazat/Documents/Python/MVTools/player_detector')
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\spyder_kernels\customize\spydercustomize.py", line 827, in runfile
    execfile(filename, namespace)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\spyder_kernels\customize\spydercustomize.py", line 110, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)
  File "C:/Users/mazat/Documents/Python/MVTools/player_detector/player_detector_testing.py", line 404, in <module>
    player_detector_run()
  File "C:/Users/mazat/Documents/Python/MVTools/player_detector/player_detector_testing.py", line 397, in player_detector_run
    glavnaya(dropbox_folder,gamename,mvstatus)
  File "C:/Users/mazat/Documents/Python/MVTools/player_detector/player_detector_testing.py", line 142, in glavnaya
    yolo_class=YOLO(model_name,script_dir, res)
  File "C:\Users\mazat\Documents\Python\MVTools\player_detector\yolo3\yolo3.py", line 39, in __init__
    self.boxes, self.scores, self.classes = self.generate()
  File "C:\Users\mazat\Documents\Python\MVTools\player_detector\yolo3\yolo3.py", line 68, in generate
    if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)
  File "C:\Users\mazat\Documents\Python\MVTools\player_detector\yolo3\model.py", line 72, in yolo_body
    darknet = Model(inputs, darknet_body(inputs))
  File "C:\Users\mazat\Documents\Python\MVTools\player_detector\yolo3\model.py", line 48, in darknet_body
    x = DarknetConv2D_BN_Leaky(32, (3,3))(x)
  File "C:\Users\mazat\Documents\Python\MVTools\player_detector\yolo3\utils.py", line 16, in <lambda>
    return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)
  File "C:\Users\mazat\Documents\Python\MVTools\player_detector\yolo3\utils.py", line 16, in <lambda>
    return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\keras\engine\base_layer.py", line 457, in __call__
    output = self.call(inputs, **kwargs)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\keras\layers\convolutional.py", line 171, in call
    dilation_rate=self.dilation_rate)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\keras\backend\tensorflow_backend.py", line 3650, in conv2d
    data_format=tf_data_format)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tensorflow\python\ops\nn_ops.py", line 894, in convolution
    name=name)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tensorflow\python\ops\nn_ops.py", line 971, in convolution_internal
    name=name)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py", line 1071, in conv2d
    data_format=data_format, dilations=dilations, name=name)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tensorflow\python\framework\op_def_library.py", line 788, in _apply_op_helper
    op_def=op_def)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tensorflow\python\util\deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tensorflow\python\framework\ops.py", line 3616, in create_op
    op_def=op_def)
  File "C:\Users\mazat\Anaconda3\envs\talhaan\lib\site-packages\tensorflow\python\framework\ops.py", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()
```@mazatov , have you tried adding the following to your code?

config = tf.ConfigProto()
config.gpu_options.allow_growth = True
tf.keras.backend.set_session(tf.Session(config=config))

Similarly, you can set the environment variable TF_FORCE_GPU_ALLOW_GROWTH to true. I think this only will work for some setups, but it did for me with Ubuntu 18.04.

@synapse8, yeah I tried those solutions and same error. I've installed tensorflow on other machines with the same method and only have issues with this new laptop.I began experiencing the issue as well. My setup is: 
Ubuntu 18.04
Cuda compilation tools, release 10.0, V10.0.130 (as shown by nvcc --version)
cudnn version 7.4.1 (as shown in cat /usr/include/cudnn.h)
NVIDIA driver 430.26 (as shown grep "X Driver" /var/log/Xorg.0.log)
RTX 2070

I followed the tensorflow.org directions for installing cuda (the apt way). Prior to the latest release (during 2.0 alpha), in a different setup with the same specs, the methods outlined above were sufficient to resolve the issue for me (both ConfigProto and tf.config.gpu method). However, I began having the issues again and using none of the methods outlined above helped me resolve it (including  tf.config.experimental.set_memory_growth(gpu, True)).

However after completing the installation of cuda via the apt way, I ended up with a cudnn installation >7.4. Then, I downgraded both of the cudnn packages to 7.4.1 via apt. 

I am using the Anaconda distribution to manage my environments and using the pip tensorflow-gpu installation inside a python 3.6.9 environment. If of importance, I run Jupyter lab server in my (base) environment and discover the kernels via the nb_conda_kernels package. 

I will appreciate any help. 

The device placement log and error stack log is below: 
2019-10-02 22:23:55.954612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-10-02 22:23:55.994185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-02 22:23:55.995181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:42:00.0
2019-10-02 22:23:55.995371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-02 22:23:55.996093: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-02 22:23:55.996936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-02 22:23:55.997132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-02 22:23:55.998046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-02 22:23:55.998696: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-02 22:23:56.000455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-02 22:23:56.000578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-02 22:23:56.001680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-02 22:23:56.002628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-02 22:23:56.003049: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-02 22:23:56.028972: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3493015000 Hz
2019-10-02 22:23:56.030382: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d7b909ac90 executing computations on platform Host. Devices:
2019-10-02 22:23:56.030406: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-10-02 22:23:56.138700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-02 22:23:56.139251: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d7b90fcf00 executing computations on platform CUDA. Devices:
2019-10-02 22:23:56.139282: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2070, Compute Capability 7.5
2019-10-02 22:23:56.139544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-02 22:23:56.140240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:42:00.0
2019-10-02 22:23:56.140283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-02 22:23:56.140297: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-02 22:23:56.140310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-02 22:23:56.140323: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-02 22:23:56.140335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-02 22:23:56.140347: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-02 22:23:56.140361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-02 22:23:56.140425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-02 22:23:56.141143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-02 22:23:56.141778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-02 22:23:56.141816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-02 22:23:56.142797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-02 22:23:56.142815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-10-02 22:23:56.142821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-10-02 22:23:56.142932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-02 22:23:56.143630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-02 22:23:56.144296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7176 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:42:00.0, compute capability: 7.5)
>>> model.compile(optimizer='adam',
...               loss='sparse_categorical_crossentropy',
...               metrics=['accuracy'])
>>> model.fit(train_images, train_labels, epochs=10)
Train on 60000 samples
Epoch 1/10
2019-10-02 22:24:21.763808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-02 22:24:21.955544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-02 22:24:22.569016: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-10-02 22:24:22.571165: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-10-02 22:24:22.571239: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node sequential/conv2d/Conv2D}}]]
   32/60000 [..............................] - ETA: 37:35Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/kaandonbekci/anaconda3/envs/brain-decoding/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File "/home/kaandonbekci/anaconda3/envs/brain-decoding/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py", line 324, in fit
    total_epochs=epochs)
  File "/home/kaandonbekci/anaconda3/envs/brain-decoding/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File "/home/kaandonbekci/anaconda3/envs/brain-decoding/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py", line 86, in execution_function
    distributed_function(input_fn))
  File "/home/kaandonbekci/anaconda3/envs/brain-decoding/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", line 457, in __call__
    result = self._call(*args, **kwds)
  File "/home/kaandonbekci/anaconda3/envs/brain-decoding/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", line 520, in _call
    return self._stateless_fn(*args, **kwds)
  File "/home/kaandonbekci/anaconda3/envs/brain-decoding/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 1823, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File "/home/kaandonbekci/anaconda3/envs/brain-decoding/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 1141, in _filtered_call
    self.captured_inputs)
  File "/home/kaandonbekci/anaconda3/envs/brain-decoding/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File "/home/kaandonbekci/anaconda3/envs/brain-decoding/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 511, in call
    ctx=ctx)
  File "/home/kaandonbekci/anaconda3/envs/brain-decoding/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File "<string>", line 3, in raise_from
tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node sequential/conv2d/Conv2D (defined at /home/kaandonbekci/anaconda3/envs/brain-decoding/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_677]

Function call stack:
distributed_function> @synapse8, yeah I tried those solutions and same error. I've installed tensorflow on other machines with the same method and only have issues with this new laptop.

Well, I take my words back for now. Somehow after multiple restarts and reinstalls, these lines of code started working. Honestly not sure what changed. Seems like same results from `conda list` but it seems to work now 🤷‍♂ @kdonbekci I resolved my error via upgrading libcudnn packages back to 7.6.2 and using the code snippet

gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)Anyone know how to remove cudnn and cuda from the ones listed in "conda list cudnn"?@kdonbekci Thank you for sharing.
Downgrading libcudnn solved the issue for me even without turning on memory growth.

```
apt-get remove libcudnn7
apt-get install libcudnn7=7.6.2.24-1+cuda10.0
```


Keras with [tensorflow 1.13.2-gpu](https://hub.docker.com/r/tensorflow/tensorflow/) backend
Tesla P100
Driver Version: 410.79
CUDA Version: 10.0> @kdonbekci Thank you for sharing.
> Downgrading libcudnn solved the issue for me even without turning on memory growth.
> 
> ```
> apt-get remove libcudnn7
> apt-get install libcudnn7=7.6.2.24-1+cuda10.0
> ```
> 
> Keras with [tensorflow 1.13.2-gpu](https://hub.docker.com/r/tensorflow/tensorflow/) backend
> Tesla P100
> Driver Version: 410.79
> CUDA Version: 10.0

Where do I copy the line of code? I've just started to experience the same issue.@jamesgreenxxvii you can execute each line individually in your terminal.
Hope this helps.

Best
FabianLike @meanderingmoose0 and @blueclowd above, **I saw this when using the wrong version of cudnn.**  However the version recommended by @bluecloud did not work.  It turns out that if you scroll through the console messages, you'll find one that looks like this:

```
2019-10-22 23:09:31.460459: E tensorflow/stream_executor/cuda/cuda_dnn.cc:319] Loaded runtime CuDNN library: 7.4.1 but source was compiled with: 7.6.0.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version.
```

This tells you what exact version you need to download.I have the same problem. Windows 10, 2080Ti, the latest versions of CUDA and cuDNN installed yesterday from NVIDIA site (both 10.1), so I don't think I need to downgrade them.
Do I need to install a cuDNN driver for Anaconda? Or a CUDA driver? I've used pip install tensorflow-gpu, and have TF 2.0 now. Not sure it have installed any additional packages.
Sorry for the stupid questions, I'm very new, and I really can't launch anything :(I previously installed tf-nightly-gpu as the super user. I fixed the 'failed to get convolution algorithm' problem by re-installing tf-nightly-gpu with my normal user.

tf-nightly-gpu-2.1.0
libcudnn7 (7.6.4.38)
cuda 10.0
Ubuntu 19.10
python3.7I got the same issue (TF2.0). It was working before so I got suspicious. I checked `nvidia-smi` and I realized the memory was full, even though I had stopped all my notebooks. I killed the process and it worked perfectly fine once again.I got this same error running the `models/research/deeplab/deeplab_demo.ipynb` notebook on my local machine. The error also coincided with my GPU memory filling completely. 

On TF2.0, passing in `gpu_options.allow_growth = True` when creating the `Session` fixed the issue.

Here's the exact change I made. I took this line:

```
self.sess = tf.Session(graph=self.graph)
```

And modified it along with adding two additional lines:

```
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True
self.sess = tf.compat.v1.Session(graph=self.graph, config=config)
```
(Since I'm using TensorFlow 2.0, I needed to add the `tf.compat.v1.Session` for compatibility)

Now I can successfully run inference with the xception and mobilenetv2 models, which use about 8.1 and 7.7 GB of GPU memory, respectively (out of my card's 8.4 GB).

tensorflow-gpu-2.0.0
Ubuntu 18.04
cuda 10.0
cudnn 7.6
nvidia driver 430
RTX 2070 Super graphics cardJust for remind. I use tf2+cuda10, have the same question. But I found there still a process in the target GPU, so I kill it and solved.Same issue here

Works with these lines added
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.compat.v1.Session(graph=self.graph, config=config)> Just for remind. I use tf2+cuda10, have the same question. But I found there still a process in the target GPU, so I kill it and solved.

Can you be specific? How did you solve it with tf2.0 and cuda10.0?@sri9s see my post above for an example that works. I'm using an RTX 2080ti and on checking nvdia-smi it shows dedicated gpu memory is almost fully occupied by some apps running on my win10.
How do I disable windows apps from using my gpu memory and only use it only for deep learning?> @kdonbekci Thank you for sharing.
> Downgrading libcudnn solved the issue for me even without turning on memory growth.
> 
> ```
> apt-get remove libcudnn7
> apt-get install libcudnn7=7.6.2.24-1+cuda10.0
> ```
> 
> Keras with [tensorflow 1.13.2-gpu](https://hub.docker.com/r/tensorflow/tensorflow/) backend
> Tesla P100
> Driver Version: 410.79
> CUDA Version: 10.0

Thanks that did the trick with TensorFlow 2.0.0 (GPU). Just a quick suggestion, run this to prevent updating it with `apt-get upgrade`:
```
apt-mark hold libcudnn7=7.6.2.24-1+cuda10.0
```Same issue here

downloaded cuDNN https://developer.nvidia.com/rdp/cudnn-download, and installed it(follow the link https://askubuntu.com/questions/767269/how-can-i-install-cudnn-on-ubuntu-16-04), the problem was sloved.**Same error i got , The Reason of getting this error is due to the mismatch of the version of the cudaa/cudnn with your tensorflow version there are two methods to solve this:**

1.  Either you Downgrade your Tensorflow Version 
`pip install --upgrade tensorflowgpu==1.8.0`

2.  Or You can follow the steps at [Here](https://www.tensorflow.org/install/gpu).

        tip:  Choose your ubuntu version and follow the steps.:-)> @kdonbekci Thank you for sharing.
> Downgrading libcudnn solved the issue for me even without turning on memory growth.
> 
> ```
> apt-get remove libcudnn7
> apt-get install libcudnn7=7.6.2.24-1+cuda10.0
> ```
> 
> Keras with [tensorflow 1.13.2-gpu](https://hub.docker.com/r/tensorflow/tensorflow/) backend
> Tesla P100
> Driver Version: 410.79
> CUDA Version: 10.0

That's a good catch!!!
I follow the TF gpu guideline and missed to "remove" the libcudnn7 before I install the 7.6.2.24 and now it all works for me:
Ubuntu 16
cuda10-0
python3.7.5
Teala P40
TF2.0Hi all. I am facing the same issue here:

tensorflow-gpu-2.0.0
Ubuntu 18.04
cudatoolkit 10.0
cudnn 7.6.4
cuda 10.0
Nvidia driver 430
RTX 2080

Does anyone know how to downgraded cudnn 7.6.4 to 7.4.1 version? or how do I just maintain the cudnn 7.6.4 version and use another way to solve it? Anyone? Thanks.> Hi all. I am facing the same issue here:
> 
> tensorflow-gpu-2.0.0
> Ubuntu 18.04
> cudatoolkit 10.0
> cudnn 7.6.4
> cuda 10.0
> Nvidia driver 430
> RTX 2080
> 
> Does anyone know how to downgraded cudnn 7.6.4 to 7.4.1 version? or how do I just maintain the cudnn 7.6.4 version and use another way to solve it? Anyone? Thanks.

For TF2.0, I think it's the 'out of memory' problem. By default, TF use all your GPU memory then triger this issue. Therefore, you could initial your code with: 

`physical_devices = tf.config.experimental.list_physical_devices('GPU')`
`assert len(physical_devices) > 0, "Not enough GPU hardware devices available"`
`tf.config.experimental.set_memory_growth(physical_devices[0], True)`

For more information, please check TF documents:

[https://www.tensorflow.org/guide/gpu](url) 
[https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_memory_growth](url)@Cilicili please try with the below settings:
```
from tensorflow.compat.v1.keras.backend import set_session
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU
config.log_device_placement = True  # to log device placement (on which device the operation ran)
sess = tf.compat.v1.Session(config=config)
set_session(sess)
```

I was facing the similar problem. When you run your code it occupies all memory of GPU and with the above provided settings it should work. The above settings help you with both tf1.x as well as tf2.I face this problem with the environment:
ubuntu 18.04
NVIDIA driver 418.67
Geforce RTX 2080
tensorflow-gpu 1.12

I try various methods to solve this problem. First, I think that it is an Incompatible problem of CUDA and Cudnn. I experiment with numerous versions of CUDA and Cudnn.  It has no work for me. I google this problem and review a solution in:
https://stackoverflow.com/questions/53698035/failed-to-get-convolution-algorithm-this-is-probably-because-cudnn-failed-to-in
It gives me an idea for the reason for this problem---Out of Memory(OOM). My computer has 16G memory and 8G memory for 2080 GPU. In CPU model, it has no problem to train my DL model, but in GPU model, I run into this problem. 
I solve the problem by adding a limit for GPU memory:
```python
config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.8
run_config = tf.contrib.tpu.RunConfig(
     ...,
     session_config=config,
     ...)

estimator = tf.contrib.tpu.TPUEstimator(
      ...,
      config=run_config,
      ...)
```
and then, it is work!> I face this problem with the environment:
> ubuntu 18.04
> NVIDIA driver 418.67
> Geforce RTX 2080
> 
> I try various methods to solve this problem. First, I think that it is an Incompatible problem of CUDA and Cudnn. I experiment with numerous versions of CUDA and Cudnn. It has no work for me. I google this problem and review a solution in:
> https://stackoverflow.com/questions/53698035/failed-to-get-convolution-algorithm-this-is-probably-because-cudnn-failed-to-in
> It gives me an idea for the reason for this problem---Out of Memory(OOM). My computer has 16G memory and 8G memory for 2080 GPU. In CPU model, it has no problem to train my DL model, but in GPU model, I run into this problem.
> I solve the problem by adding a limit for GPU memory:
> 
> ```python
> config = tf.ConfigProto()
> config.gpu_options.per_process_gpu_memory_fraction = 0.8
> run_config = tf.contrib.tpu.RunConfig(
>      ...,
>      session_config=config,
>      ...)
> ```
> 
> and then, it is work!
Are you using tf1 or tf2?
Workaround: 
Fresh install TF 2.0 and ran a simple Minst tutorial, it was alright, opened another notebook, tried to run and encountered this issue.
I existed all notebooks and restarted Jupyter and open only one notebook, ran it successfully
Issue seems to be either memory or running more than one notebook on GPU
ThanksWorkaround:
https://github.com/tensorflow/tensorflow/issues/25160#issuecomment-568505081i had same problem with ubuntu + cuda 10.2 + cudnn 7.6.5
i use the method which @oscarlinux  mentioned, and it works!!
thank you! it saved the day!> Hi all. I am facing the same issue here:
> 
> tensorflow-gpu-2.0.0
> Ubuntu 18.04
> cudatoolkit 10.0
> cudnn 7.6.4
> cuda 10.0
> Nvidia driver 430
> RTX 2080
> 
> Does anyone know how to downgraded cudnn 7.6.4 to 7.4.1 version? or how do I just maintain the cudnn 7.6.4 version and use another way to solve it? Anyone? Thanks.

my desk top use GTX1080 even cudnn 7.6.5 works!! may be need to switch back to GTX1080> > I face this problem with the environment:
> > ubuntu 18.04
> > NVIDIA driver 418.67
> > Geforce RTX 2080
> > I try various methods to solve this problem. First, I think that it is an Incompatible problem of CUDA and Cudnn. I experiment with numerous versions of CUDA and Cudnn. It has no work for me. I google this problem and review a solution in:
> > https://stackoverflow.com/questions/53698035/failed-to-get-convolution-algorithm-this-is-probably-because-cudnn-failed-to-in
> > It gives me an idea for the reason for this problem---Out of Memory(OOM). My computer has 16G memory and 8G memory for 2080 GPU. In CPU model, it has no problem to train my DL model, but in GPU model, I run into this problem.
> > I solve the problem by adding a limit for GPU memory:
> > ```python
> > config = tf.ConfigProto()
> > config.gpu_options.per_process_gpu_memory_fraction = 0.8
> > run_config = tf.contrib.tpu.RunConfig(
> >      ...,
> >      session_config=config,
> >      ...)
> > ```
> > 
> > 
> > and then, it is work!
> > Are you using tf1 or tf2?

I think it is tf1.12, so the solution may not work for tf2.0 or tf2.1Same issue here (while running the official MNIST sample). My setup:

tensorflow-gpu-2.0.0
Ubuntu 18.04
CUDA 10.0
cudnn 7.6.4
Nvidia Driver 430
GTX-1080

This error is annoying because we have nearly zero hint on the root cause. Already try the GPU memory fix but no luck.Same here. I have RTX 2080 SUPER on Ubuntu 18.04 and tried different versions of tf/cuda/cudnn/nvidia-driver. I've also tried tf in Docker container and had no luck.

`allow_growth` partially solves the issue but it leads to [a new one](https://github.com/tensorflow/tensorflow/issues/28287) when I tried to train [WGAN-GP](https://github.com/eriklindernoren/Keras-GAN/blob/master/wgan_gp/wgan_gp.py)

tf 2.1 with cuda 10.1 gives [new exception](https://github.com/tensorflow/tensorflow/issues/11812)UPDATE:

Just update to TF 2.1  (with CUDA 10.1 and cuDNN 7.6.4). All work well now.Works for me
TF2
NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.0
GeForce RTX 2080ti



```
import tensorflow as tf
from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

config = ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.2
config.gpu_options.allow_growth = True
```It also works on tensorflow 2.1!

Thanks to @oscarlinux I found the solution on [tensorflow.org](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)

```python
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)
```

> "Although the error is gone for now, there is still so much for us to do.
I believe in my heart, that if all of us work together, we can restore Tensorflow to its former glory. Perhaps even beyond. But it all must start with us."For me, I had the same problem because my server was being used by multiple devices so there wasn't enough memory to run the code on the dataset. 

Some solutions can be to free some memory and reduce size of the dataset.I had two Jupyter Notebook Tabs open. Both containing a GPU-initialization. Shutting down one tab and restarting the kernel in the other solved the issue.According the comment of @neolee  and @Man7hano , i change my system information to TF 2.1 with CUDA 10.1 and cuDNN 7.6.4 too (in addition, OS is windows10, gpu is GTX 1660 ti，python is 3.7.4），when i run object_detection_tutorial.ipynb in jupyter notebook, the error still exist:
 `2020-01-29 21:56:35.944996: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-01-29 21:56:35.952224: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-01-29 21:56:35.958555: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[{{node FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/BatchNorm/batchnorm/mul_1}}]]
         [[Postprocessor/BatchMultiClassNonMaxSuppression/map/TensorArrayStack_4/range/_50]]
2020-01-29 21:56:35.980198: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[{{node FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/BatchNorm/batchnorm/mul_1}}]]`
Anyone can give me a suggestion ? Thanks !

I fixed it just now by adding below codess after "import tensorflow as tf":
![Snipaste_2020-01-29_23-09-08](https://user-images.githubusercontent.com/43233772/73368722-6e643f00-42ec-11ea-8fb4-37a5fb5e05cd.png)
import tensorflow as tf
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus :

    try:

        for gpu in gpus:

            tf.config.experimental.set_memory_growth(gpu, True)

        tf.config.experimental.set_virtual_device_configuration(gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 4)])

    except RuntimeError as e:

        print(e)So I ran into this problem when I tried to re-install TensorFlow in an older Nvidia docker. After running my notebook I got the same error. What I learned after a long while was that the "warning" message that the error's talking about *shows up in the jupyter console running the jupyter notebook server*, and is not piped into stdout. 

There I found out the error message that clearly said my TensorFlow (the one I got from pip) was built against a newer cudnn library than I had on the Nvidia docker image. The solution was to get the new cudnn that matched the major and minor of the TensorFlow built cudnn library from [cudnn archive](https://developer.nvidia.com/rdp/cudnn-archive) and install it:

```
$ tar -xzvf cudnn-10.2-linux-x64-v7.6.5.32.tgz
$ sudo cp cuda/include/cudnn.h /usr/local/cuda/include
$ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64
$ sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*
```> > Hi all. I am facing the same issue here:
> > tensorflow-gpu-2.0.0
> > Ubuntu 18.04
> > cudatoolkit 10.0
> > cudnn 7.6.4
> > cuda 10.0
> > Nvidia driver 430
> > RTX 2080
> > Does anyone know how to downgraded cudnn 7.6.4 to 7.4.1 version? or how do I just maintain the cudnn 7.6.4 version and use another way to solve it? Anyone? Thanks.
> 
> For TF2.0, I think it's the 'out of memory' problem. By default, TF use all your GPU memory then triger this issue. Therefore, you could initial your code with:
> 
> `physical_devices = tf.config.experimental.list_physical_devices('GPU')`
> `assert len(physical_devices) > 0, "Not enough GPU hardware devices available"`
> `tf.config.experimental.set_memory_growth(physical_devices[0], True)`
> 
> For more information, please check TF documents:
> 
> [https://www.tensorflow.org/guide/gpu](url)
> [https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_memory_growth](url)

Cilicili solution indeed works, if you use TensorFlow 2.* in eager mode (no sessions!)
thanks!
Is it possible to understand from where TF is trying to load CuDNN?> 此错误可能与使用进行安装TF有关`conda`。
> 
> 可能的解决方案是这样的：
> 在命令行中发出以下命令：
> `conda list cudnn`
> 它将打印：
> ` Name Version Build Channel`
> 
> 如果上述结果不是空的，则意味着您使用conda安装的TF，当使用conda安装TF时，它将安装所有依赖项，甚至包括CUDA和cuDNN，但是cuDNN版本对于TF非常低，因此会带来兼容性问题。因此，您可以卸载conda安装的cuDNN和CUDA，然后运行TF，然后它将起作用。

What if it is empty?I have CUDA 10.0, cuDNN 7.4.1 (also tried 7.6.5), ubuntu 18.04
For tensorflow-gpu==2.0.0 setting up allow_growth = True didn't help
setting up allow_growth = True helped for tensorflow-gpu==1.14.0> I have CUDA 10.0, cuDNN 7.4.1 (also tried 7.6.5), ubuntu 18.04
> For tensorflow-gpu==2.0.0 setting up allow_growth = True didn't help
> setting up allow_growth = True helped for tensorflow-gpu==1.14.0

I had the same issue for TF2, Cuda-10, Cudnn-7.4/7.6

this workaround worked for me for cudnn failure as mentioned above
physical_devices = tf.config.experimental.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], True)

Note if you want to use Keras:fit_generator(), multiprocessing=True will again cause memory errors, so better to write your own custom multiprocessing queue.Why is this ticket closed? Has the Tensorflow team make any fix for this in the sources? I have been even compiling Tensorflow from scratch against CUDA 10.1 and CUDA 10.2 on ubuntu 18.04 using the latest sources and it still fails with the same error.
The workaround with allow_growth=True helps only with smaller models, but is still only a workaround and not the fix.Why is this ticket closed? Has the Tensorflow team make any fix for this in the sources? I have been even compiling Tensorflow from scratch against CUDA 10.1 and CUDA 10.2 on ubuntu 18.04 using the latest sources and it still fails with the same error.
The workaround with allow_growth=True helps only with smaller models, but is still only a workaround and not the fix.

___________I agree with you!!Same problem here

nvidia-driver-440.59
Ubuntu 18.04.4 LTS
Nvidia RTX 2060
CUDA 10.2
Nvida Docker 2
TF 2.1 (2.1.0-gpu-py3-jupyter)

Doesn't matter if the container was just started or already run some times, always the same error, so it can't be memory usage.

Trying to run "https://www.tensorflow.org/tutorials/quickstart/advanced"
This thing happened to me after installing keras-vis and downgrading to scipy 1.1.0, but I'm not sure it's related, because reverting these changes, didn't solve the issues. However a simple reboot solved the issue. By the way, I often find that "nonsense" TF errors are solved by reboots. :)

Update: I just quickly double checked, and downgrading to scipy 1.1.0 seemed to be reproduce and cancel this problem after upgrading back to 1.4.1.

Update: Another black magic which seems to help a lot of times is just inserting this snippet.
    config = tf.ConfigProto(allow_soft_placement=True,
                            log_device_placement=False)
    config.gpu_options.allow_growth = False
    config.gpu_options.per_process_gpu_memory_fraction = 0.8
    sess = tf.Session(graph=tf.get_default_graph(),
                      config=config)@karkirowle
That gives me
```
AttributeError: module 'tensorflow' has no attribute 'ConfigProto'
```

For me
```
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True
session = tf.compat.v1.InteractiveSession(config=config)
```
is working, but that's still just a workaround. The docker hub tensorflow 2.1 container in my opinion should work out of the box without any error messages.Hello. I think that I have the same problem.

nvidia-driver-442.19
Windows 10
Nvidia RTX 2080 TI
CUDA Version 10.0.130
CUDnn = 7.6.5

λ pip3 list | grep tensorflow
tensorflow            1.15.0
tensorflow-estimator  1.15.1

conda list cudnn : empty

I'm trying to directly convert real-person videos to the motion of animation models (i.e. Miku, Anmicius) following the instructions located here :

https://github.com/peterljq/OpenMMD

and this :

https://www.youtube.com/watch?v=hKx6jl9a5-I

I'm stuck here,when it says : "After that, proceed to the FCRN-DepthPrediction-vmd folder and run VideoToDepth.dat"

so :

λ python tensorflow/predict_video.py --model_path tensorflow/data/NYU_FCRN.ckpt --video_path rp.mov --baseline_path /Pers/cg/MMD/OpenMMD/3d-pose-baseline-vmd/json_rp_3d_20200224_191201_idx01 --interval 10 --verbose 3
2020-02-24 19:32:27.891927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
INFO:__main__:深度推定出力開始
DEBUG:__main__:width: 1920.0, height: 1080.0
DEBUG:__main__:scale: 0.26666666666666666
DEBUG:__main__:width: 512, height: 288
WARNING:tensorflow:From tensorflow/predict_video.py:68: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From tensorflow/predict_video.py:68: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From K:\Pers\cg\MMD\OpenMMD\FCRN-DepthPrediction-vmd\tensorflow\models\network.py:161: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From K:\Pers\cg\MMD\OpenMMD\FCRN-DepthPrediction-vmd\tensorflow\models\network.py:161: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From K:\Pers\cg\MMD\OpenMMD\FCRN-DepthPrediction-vmd\tensorflow\models\network.py:127: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From K:\Pers\cg\MMD\OpenMMD\FCRN-DepthPrediction-vmd\tensorflow\models\network.py:127: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From K:\Pers\cg\MMD\OpenMMD\FCRN-DepthPrediction-vmd\tensorflow\models\network.py:193: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From K:\Pers\cg\MMD\OpenMMD\FCRN-DepthPrediction-vmd\tensorflow\models\network.py:193: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From K:\Pers\cg\MMD\OpenMMD\FCRN-DepthPrediction-vmd\tensorflow\models\network.py:291: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From K:\Pers\cg\MMD\OpenMMD\FCRN-DepthPrediction-vmd\tensorflow\models\network.py:291: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From tensorflow/predict_video.py:75: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From tensorflow/predict_video.py:75: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-24 19:32:30.767433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-02-24 19:32:30.791709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:01:00.0
2020-02-24 19:32:30.791955: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-02-24 19:32:30.795334: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-02-24 19:32:30.797579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-02-24 19:32:30.798576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-02-24 19:32:30.801752: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-02-24 19:32:30.803828: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-02-24 19:32:30.809762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-02-24 19:32:30.810085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-02-24 19:32:30.810332: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-02-24 19:32:30.812172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:01:00.0
2020-02-24 19:32:30.812316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-02-24 19:32:30.812387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-02-24 19:32:30.812455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-02-24 19:32:30.812523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-02-24 19:32:30.812590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-02-24 19:32:30.812687: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-02-24 19:32:30.812762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-02-24 19:32:30.813033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-02-24 19:32:31.239492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-24 19:32:31.239602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0
2020-02-24 19:32:31.239664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N
2020-02-24 19:32:31.240105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9530 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
WARNING:tensorflow:From tensorflow/predict_video.py:78: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From tensorflow/predict_video.py:78: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

INFO:tensorflow:Restoring parameters from tensorflow/data/NYU_FCRN.ckpt
INFO:tensorflow:Restoring parameters from tensorflow/data/NYU_FCRN.ckpt
INFO:__main__:深度推定: n=0
2020-02-24 19:32:34.592124: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-02-24 19:32:35.977148: E tensorflow/stream_executor/cuda/cuda_dnn.cc:319] Loaded runtime CuDNN library: 7.5.0 but source was compiled with: 7.6.0.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.
2020-02-24 19:32:35.979070: E tensorflow/stream_executor/cuda/cuda_dnn.cc:319] Loaded runtime CuDNN library: 7.5.0 but source was compiled with: 7.6.0.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.
Traceback (most recent call last):
  File "C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\client\session.py", line 1365, in _do_call
    return fn(*args)
  File "C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\client\session.py", line 1350, in _run_fn
    target_list, run_metadata)
  File "C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\client\session.py", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[{{node conv1/Conv2D}}]]
         [[ConvPred/ConvPred/_791]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[{{node conv1/Conv2D}}]]
0 successful operations.
0 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "tensorflow/predict_video.py", line 264, in <module>
    main()
  File "tensorflow/predict_video.py", line 261, in main
    predict_video(args.model_path, args.video_path, args.baseline_path, interval, smoothed_2d)
  File "tensorflow/predict_video.py", line 111, in predict_video
    pred = sess.run(net.get_output(), feed_dict={input_node: img})
  File "C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\client\session.py", line 956, in run
    run_metadata_ptr)
  File "C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\client\session.py", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File "C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\client\session.py", line 1359, in _do_run
    run_metadata)
  File "C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\client\session.py", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node conv1/Conv2D (defined at C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\ops.py:1748) ]]
         [[ConvPred/ConvPred/_791]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node conv1/Conv2D (defined at C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\ops.py:1748) ]]
0 successful operations.
0 derived errors ignored.

Original stack trace for 'conv1/Conv2D':
  File "tensorflow/predict_video.py", line 264, in <module>
    main()
  File "tensorflow/predict_video.py", line 261, in main
    predict_video(args.model_path, args.video_path, args.baseline_path, interval, smoothed_2d)
  File "tensorflow/predict_video.py", line 71, in predict_video
    net = models.ResNet50UpProj({'data': input_node}, batch_size, 1, False)
  File "K:\Pers\cg\MMD\OpenMMD\FCRN-DepthPrediction-vmd\tensorflow\models\network.py", line 71, in __init__
    self.setup()
  File "K:\Pers\cg\MMD\OpenMMD\FCRN-DepthPrediction-vmd\tensorflow\models\fcrn.py", line 6, in setup
    .conv(7, 7, 64, 2, 2, relu=False, name='conv1')
  File "K:\Pers\cg\MMD\OpenMMD\FCRN-DepthPrediction-vmd\tensorflow\models\network.py", line 46, in layer_decorated
    layer_output = op(self, layer_input, *args, **kwargs)
  File "K:\Pers\cg\MMD\OpenMMD\FCRN-DepthPrediction-vmd\tensorflow\models\network.py", line 166, in conv
    output = convolve(input_data, kernel)
  File "K:\Pers\cg\MMD\OpenMMD\FCRN-DepthPrediction-vmd\tensorflow\models\network.py", line 159, in <lambda>
    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding='VALID')
  File "C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\ops\nn_ops.py", line 2010, in conv2d
    name=name)
  File "C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\ops\gen_nn_ops.py", line 1071, in conv2d
    data_format=data_format, dilations=dilations, name=name)
  File "C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\op_def_library.py", line 794, in _apply_op_helper
    op_def=op_def)
  File "C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\util\deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\ops.py", line 3357, in create_op
    attrs, op_def, compute_device)
  File "C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\ops.py", line 3426, in _create_op_internal
    op_def=op_def)
  File "C:\Users\marietto2020\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\ops.py", line 1748, in __init__
    self._traceback = tf_stack.extract_stack()This problem is still an issue for me. I have to strictly work with TF2.0 to make it work, none of the solution works with tf1.14 or tf1.15 which I need to use because my professor doesn't want us using tf1 for any of her assignment. @oluwayetty 
Did you try to call 
```
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True
session = tf.compat.v1.InteractiveSession(config=config)
```
?
This was working for me for TF 2.0@xam-ps  : excusme,I'm a newbie. I'm trying to do like you suggest,but for me it does not work. Where should I write the commands that u suggest ? I did that after having enabled tensorflow (that I have upgraded to 2.1),but this is what happened :

(tensorflow) λ config = tf.compat.v1.ConfigProto()
"config" is not recognized as an interal or external command.For anyone who has this error with tf2, try using conda as your virtual environment. It worked for me. Conda often solves CUDA and CuDNN issues.
`conda install tensorflow-gpu`So I followed this entire thread, and still have issues.

- Windows 10 (v1903 - build 18362.657)
- GTX 2060 (NVIDIA driver 442.50)
- Conda venv
- Jupyter Notebook
- Python 3.7
- TensorFlow 2.1
- CUDA: 10.2
- cuDNN: 7.6.5


I've tried all of the above, and I can avoid this error when I don't have TensorFlow-GPU installed in my conda venv, but when I install TensorFlow-GPU, the problem arises again. 

I've followed all the installation instructions from [here](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-windows) and [here](https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html) word for word. **I've installed them in the recommended locations. Do I need to do anything special for the venv?**

tf.ConfigProto() and all the various mentions above didn't work. `pip uninstall/install hdf5` and `pip uninstall/install h5py` didn't work (yes I made sure not both were installed at the same time).

I've even completely wiped my SSD of all Python, Anaconda, and various packages and started from scratch. Still didn't work. 

Any suggestions? I'm about to try Docker to see if that helps, but at this point I'm out of my depth. I'm a DS/stats guy and not a CS guy, unfortunately. 



@awrgold 
I was using tensorflow 2.1 trough (nvidia2) docker and have the issue anyways. So I don't think that solves the problem.I had same issue on ubuntu 18.04, tensorflow 2.1.0. I resolved it through allowing gpu growth. After a while I got same error and I don't know why. 

Now I find reason, it is because of asynchronous learning model that I implemented through threaing.Thread. Other models work properly. If you have this error, check if you are using threading or mulitiprocessing.> Did you try setting up allow_growth = True? That resolved the problem for me.

When I set up allow_growth = True, the issue disappears. However, when I set two virtual GPU devices with only one physical GPU device, allow_growth can not be set True. So, how can I solve the issue? Do you have any idea? When I run my code in Colab, it is ok without setting allow_growth. I am quite confused.I tried the same, it doesn't help at all. For now I've been training on the CPU but I'd really like to speed things up. I've even tried going down to CUDA 9 and TF 1.15 to see if that helped, but to no avail.> > Did you try setting up allow_growth = True? That resolved the problem for me.
> 
> When I set up allow_growth = True, the issue disappears. However, when I set two virtual GPU devices with only one physical GPU device, allow_growth can not be set True. So, how can I solve the issue? Do you have any idea? When I run my code in Colab, it is ok without setting allow_growth. I am quite confused.

You have to clarify your issue. Why do you need two virtual devices and one physical device? Secondly, do you use a docker container or a local environment? What are your specs? Colab uses other GPUs then you, why shouldn't it work there?@Man7hano 
There is only one physical GPU in the local environment, therefore, I create two virtual GPU devices to train the neural network in a  distributed way. 
Local env: RTX2060; Cuda 10.1; cuDNN 7.6.4. I do not use a docker container.
I run Colab in Google drive with only one GPU device.
I am not sure whether the issue about cuDNN initialization stems from the configuration allow_growth=True or env version.> config = tf.compat.v1.ConfigProto()
> config.gpu_options.allow_growth = True
> session = tf.compat.v1.InteractiveSession(config=config)

this worked for me. cuda 10.1, cudnn 7.6.5, tf 2.1, windows 10> @Man7hano
> There is only one physical GPU in the local environment, therefore, I create two virtual GPU devices to train the neural network in a distributed way.
> Local env: RTX2060; Cuda 10.1; cuDNN 7.6.4. I do not use a docker container.
> I run Colab in Google drive with only one GPU device.
> I am not sure whether the issue about cuDNN initialization stems from the configuration allow_growth=True or env version.

As far as I know, distribution makes only sense if you have multiple physical GPUs. Otherwise, you are splitting the performance of the physical one. If you have to split it, you should limit the memory growth of the virtual GPUs. You can find the docs on Tensorflow.
Google Colab probably uses bigger GPUs then you are using and half the performance is just fine, or they reallocate to other GPUs available.
However, I would suggest the official Docker container of Tensorflow for local development.I had this issue with TF 2.0, so I wiped everything out (conda, CUDA, cudatools, cudnn) and started over. I ran "conda install tensorflow-gpu" on my brand new miniconda install (3.7) and the issue reappeared. Adding:
```
physical_devices = tf.config.experimental.list_physical_devices('GPU')
assert len(physical_devices) > 0, "Not enough GPU hardware devices available"
tf.config.experimental.set_memory_growth(physical_devices[0], True)
```

fixed it, for now.Please try set memory limit, that resolve my problem: REF: https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth> @oluwayetty
> Did you try to call
> 
> ```
> config = tf.compat.v1.ConfigProto()
> config.gpu_options.allow_growth = True
> session = tf.compat.v1.InteractiveSession(config=config)
> ```
> 
> ?
> This was working for me for TF 2.0

Hey, yes the solution above works for tf2.0 but not for tf1.14 or tf1.15. I needed it for a project I'm working on that's based on tf1.x. ThanksI face the same problem, finally I find because my cudnn version is wrong. I think you have the same issue. May this would help you.

> 2020-02-24 19:32:35.979070: E tensorflow/stream_executor/cuda/cuda_dnn.cc:319] Loaded runtime CuDNN library: 7.5.0 but source was compiled with: 7.6.0. CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version. If using a binary install, upgrade your CuDNN library. If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.

exm :
cuda10.1
cuDNN7.6
tensorflow1.13
it seems that all codes following doesn't work for me:
![image](https://user-images.githubusercontent.com/61641190/77849210-86791180-71fc-11ea-9624-bdcd9f9c8f1e.png)

could u please give me a "debug" answer,thx

ps:the first three error:Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node Conv1_2/convolution}}]]
	 [[{{node Mean_2}}]]
the last two error:
module 'tensorflow' has no attribute 'config'Have the same issue even using official tensorflow docker (v 1.15.2 + object detection api for v 1.13.0)@HazelSCUT 
Do u have find solution?
exm :
cuda9.1
cuDNN7.1
tensorflow1.15Also noticed that the docker image works well on another machine (GTX 1080 Ti) while fails on mine (RTX 2080 SUPER). Tried to completely reinstall everything related to nvidia, including drivers (also tried to downgrade them) - nothing helped.@pryadchenko 
Same issue here. Using the official TF-Docker image. Working fine on GTX cards, having cuDNN error on RTX cards. Google should really do sth. about that!!
No clue why this bug is closed already...The same problem here. It appeared after upgrading GPU from Nvidia GTX1060 3GB to GTX 1660 Super 6GB.
I've already tried to install clean: GPU drivers, CUDA 10.2, cuDNN for CUDA 10.2. Nothing works so far.
I've also reinstalled Tensorflow (previous was a conda installation), this time I've used pip version 2,1,0-cp37-cp37-win-amd64.

I keep digging...This error I got on my machine due to out of memory (The trace back didn't told me that), I found out because 4th solution (Given below) worked for me. And interesting thing was that I had two machines with following specs:

### Machine 1:
1. *OS:*           Windows 10 x64  
2. *GPU:*         GTX 1060 6GB,  
3. *Cuda:*       10.0, 
4. *CuDNN:*    v7.6.4.38 
5. *TF:*             1.15 GPU
6. *conda/pip?* Installed using ``` pip install tensorflow-gpu==1.15 ```
7. *Python:*      3.7

### Machine 2:
1. *OS:*           Windows 10 x64  
2. *GPU:*         GTX 1660 Ti 6GB,  
3. *Cuda:*       10.0, 
4. *CuDNN:*    v7.6.4.38 
5. *TF:*             1.15 GPU
6. *conda/pip?* Installed using ``` pip install tensorflow-gpu==1.15 ```
7. *Python:*      3.7

The code worked on Machine 1 very well but on Machine 2 it will give the error: *Failed to get convolution algorithm. This is probably because cuDNN failed to initialize*. In my case 2nd solution in 4 part (the last one) solved my issue.

I've seen this error message for four different reasons, with different solutions: 

### 1. You have cache issues
I regularly work around this error by shutting down my python process, removing the ~/.nv directory (on linux, rm -rf ~/.nv), and restarting the Python process. I don't exactly know why this works. It's probably at least partly related to the second option:

### 2. You're out of memory
The error can also show up if you run out of graphics card RAM. With an nvidia GPU you can check graphics card memory usage with nvidia-smi. This will give you not only a readout of how much GPU RAM you have in use (something like 6025MiB /  6086MiB if you're almost at the limit) as well as a list of what processes are using GPU RAM.

If you've run out of RAM, you'll need to restart the process (which should free up the RAM) and then take a less memory-intensive approach. A few options are:

reducing your batch size
using a simpler model
using less data
limit TensorFlow GPU memory fraction: For example, the following will make sure TensorFlow uses <= 90% of your RAM:
```
import keras
import tensorflow as tf

config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.9
keras.backend.tensorflow_backend.set_session(tf.Session(config=config))
```

This can slow down your model evaluation if not used together with the items above, presumably since the large data set will have to be swapped in and out to fit into the small amount of memory you've allocated.

### 3. You have incompatible versions of CUDA, TensorFlow, NVIDIA drivers, etc.
If you've never had similar models working, you're not running out of VRAM and your cache is clean, I'd go back and set up CUDA + TensorFlow using the best available installation guide - I have had the most success with following the instructions at https://www.tensorflow.org/install/gpu rather than those on the NVIDIA / CUDA site. Lambda Stack: https://lambdalabs.com/lambda-stack-deep-learning-software is also a good way to go.

### 4. While using Keras, Keras layers(classes) were directly imported from keras instead of tensorflow.keras 

Keras is included in TensorFlow 2.0 above. So

remove ``` import keras ``` and
replace ``` from keras.module.module import class ``` statement to --> from ``` tensorflow.keras.module.module import class ```

For example
Replace 
``` from keras.layers import Conv3D,ConvLSTM2D,Conv3DTranspose, Input```
with this:
``` from tensorflow.keras.layers import Conv3D,ConvLSTM2D,Conv3DTranspose, Input ```

Maybe your GPU memory is filled. So use allow ``` growth = True ``` in GPU option. This is deprecated now. But use this below code snippet after imports may solve your problem.

```
import tensorflow as tf
from tensorflow.compat.v1.keras.backend import set_session


config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU
config.log_device_placement = True  # to log device placement (on which device the operation ran)
sess = tf.compat.v1.Session(config=config)
set_session(sess)
print('\nTensorflow GPU installed: '+str(tf.test.is_built_with_cuda()))
print('Is Tensorflow using GPU: \n'+str(tf.test.is_gpu_available()))
```
### If the above code does not resolve the issue then try the following code, and put the following write after imports:
```
import tensorflow as tf
 gpus = tf.config.experimental.list_physical_devices('GPU')
    #The variable GB is the memory size you want to use.
    config = [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=(1024*GB))]
    if gpus:
      # Restrict TensorFlow to only allocate 1*X GB of memory on the first GPU
      try:
        tf.config.experimental.set_virtual_device_configuration(gpus[0], config)
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
      except RuntimeError as e:
        # Virtual devices must be set before GPUs have been initialized
        print(e)
``` 

In the above code at line#4 the Variable GB represents the memory you want to to use from your total memory of GPU. It is recommended to use at least 1 GB less than your total GPU Memory size. If still problem exist try lowering the value of the Variable GB. Eventually it will work.@RobKwiatkowski Please try one of them : https://github.com/tensorflow/tensorflow/issues/24828#issuecomment-609426655

I hope this will solve your issue. And please let me know whether it solved your issue or not.@irdanish11, thank You for trying to help, but I think we have slightly different reasons for this issue. As for me, none of the cases you've listed are relevant: 
1) this issue come within just started container (no cache);
2) this issue comes with even simple model (i.e. one conv layer with one filter) - so, it cannot be out of memory error at all;
3) everything within an official docker image is compatible (i.e. CUDA, cuDNN, tf). Working around nvidia drivers on the host machine doesn't help at all;
4) always import from tf.keras - dose not matter.

Anyway, thank you!I use a new conda create --name myenv python=3.XX...
I install tf-gpu=1.15.0 and keras=2.24,
And I plus 
```
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True
session = tf.compat.v1.InteractiveSession(config=config)
```

Finally,I can run.
I don't know why....
 ```
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True
session = tf.compat.v1.InteractiveSession(config=config)
```

this works (one can find this snippet everywhere), but it is a hack, not a solution.for people getting this issue on an AWS notebook instance I found that using a conda_amazonei_tensorflow_p36 instead of a conda_tensorflow_p36 kernel solves it.I had this issue on a machine with multiple available GPUs, some of which were in use. I restricted my model to only use a single GPU that was not in use via masking away the rest before running my script; set the following environment variable

CUDA_VISIBLE_DEVICES= (some GPU id)

Seems to work for me, good luck!> @RobKwiatkowski Please try one of them : [#24828 (comment)](https://github.com/tensorflow/tensorflow/issues/24828#issuecomment-609426655)

The last part solved my issue. I dont quite understand what units the memory is in but I figured out how to make it run with a little experimentation. are the GB in SI units or are they in binary units? it looks like they are in Binary MiB units when looking at the output from the invidia-smi command but the math doesnt seem to work when I try to allocate my memory using that conversion. 

more clearly- it looks like I have 7982MiB from invidia-smi. which would be 7982x(2^10)^2 which equals 8.37x10^9 bytes right? but in python, when I try to allocate even something as low as 7.0x10^4 I get an error and it exceeds my GPU memory.

` [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=(7e4))]`

running the above code exceeds my GPU memory when I check on invidia-smi. How is this possible? Am I not converting properly from Mib to bytes? I am experiencing this issue when trying to execute my code on an AWS SageMaker ml.p2.xlarge instance.
- TensorFlow 2.1.0
- Cuda version 10.0.13 (from nvcc --version)
- Python 3.6.1.

I have tried the allow_growth=True suggestions which did not solve the issue. I also tried the conda_amazonei_tensorflow_p36 notebook instance that @raynaa-75 suggested but it is not compatible with some of my dependencies such as tensorflow_federated. Would anyone have any additional recommendations for potential solutions for the error?This solved the error for me:
https://stackoverflow.com/questions/53698035/failed-to-get-convolution-algorithm-this-is-probably-because-cudnn-failed-to-in

adjusting the IMAGES_PER_GPU  in the config file to a lower number solved my problem

you could also try to modify STEPS_PER_EPOCH, IMAGE_MAX_DIM, TRAIN_ROIS_PER_IMAGE or whatever other hyper-parameters which consume your GPU.

Another option is to choose a more powerful machine if you are working in the cloudIt was an error caused by the CUDA version (10.2). I used this bash script to change the cuda version of the instance to 10.1 and it worked. 
https://github.com/phohenecker/switch-cuda
Wrote my own custom layer for conv and that finally worked.This worked for me with tensorflow 2.1 and doesn't depend on tf.compat:
`physical_devices = tf.config.experimental.list_physical_devices('GPU')
for physical_device in physical_devices:
    tf.config.experimental.set_memory_growth(physical_device, True)`

Video Card: Nvidia GT 1030Was getting this with tf2.2.0rc4 on ubuntu 20.04 and py3.7, with an nvidia rtx 2070 (440 driver, cuda toolkit 10.1 most recent upgrade). Switching to python 3.8 remedied the issue.I was using the tensorflow docker container `tensorflow/tensorflow:latest-gpu-py3-jupyter` on an Nvidia RTX 2080 Super and
```python
physical_devices = tf.config.experimental.list_physical_devices('GPU') 
for physical_device in physical_devices: 
    tf.config.experimental.set_memory_growth(physical_device, True)
```
worked for me> I was using the tensorflow docker container `tensorflow/tensorflow:latest-gpu-py3-jupyter` on an Nvidia RTX 2080 Super and
> 
> ```python
> physical_devices = tf.config.experimental.list_physical_devices('GPU') 
> for physical_device in physical_devices: 
>     tf.config.experimental.set_memory_growth(physical_device, True)
> ```
> 
> worked for me

it works thank you :)> I was using the tensorflow docker container `tensorflow/tensorflow:latest-gpu-py3-jupyter` on an Nvidia RTX 2080 Super and
> 
> ```python
> physical_devices = tf.config.experimental.list_physical_devices('GPU') 
> for physical_device in physical_devices: 
>     tf.config.experimental.set_memory_growth(physical_device, True)
> ```
> 
> worked for me

Works fine on tensorflow==2.2.0> This worked for me with tensorflow 2.1 and doesn't depend on tf.compat:
> `physical_devices = tf.config.experimental.list_physical_devices('GPU') for physical_device in physical_devices: tf.config.experimental.set_memory_growth(physical_device, True)`
> 
> Video Card: Nvidia GT 1030

Thank you very much, solved all my problems :)> > Did you try setting up allow_growth = True? That resolved the problem for me.
> 
> Yes, it helps!
> Thanks.
> @aishwaryap
> You can try setting up allow_growth:
> 
> config = tf.ConfigProto()
> config.gpu_options.allow_growth = True
> sess = tf.Session(config=config)

This solution worked for me!! Thanks a lot!Did anyone use tensorflow 1.   success ？
I use this code 
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.Session(config=config)
But it doesn’t work.
```python
physical_devices = tf.config.experimental.list_physical_devices('GPU') 
for physical_device in physical_devices: 
    tf.config.experimental.set_memory_growth(physical_device, True)
```
Also worked for me on tensorflow 2.2.0. 

Now I just need to figure out the last error (3rd in a row):
```ssh
type tensorflow.python.framework.ops.EagerTensor doesn't define __round__ method
```

edit: ok everything works now yay   I solved the problem by **uninstall tensorflow-gpu**  from conda and pip environment .  And use **conda to install tensorflow-gpu=1.14  conda install keras=2.2.5**.  The dependencies will also be installed. But there is still problem,  then  just tf-gpu and keras  are removed from conda env, by usage "conda   remove --force tensorflow-gpu=1.14  ".  After that , using pip install tensorflow-gpu==1.14  and  keras==2.2.5.  If  raise error " there is no module of tensorflow" ，using pip  install tf-gpu again . Then the problem solved.I was facing the same issue recently. I have an RTX 2060 and CUDA 10.2, OS: Ubuntu.

I installed tf-gpu 2.2 using conda. See image for cudnn and Cuda version.
![nvidia-cuda-cudnn](https://user-images.githubusercontent.com/65457337/84581611-68768280-ade3-11ea-83c2-51e99e82a6d9.png)

For me, this worked:
gpus = tf.config.experimental.list_physical_devices('GPU')
    #The variable GB is the memory size you want to use.
    config = [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=(1024*GB))]
    if gpus:
      # Restrict TensorFlow to only allocate 1*X GB of memory on the first GPU
      try:
        tf.config.experimental.set_virtual_device_configuration(gpus[0], config)
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
      except RuntimeError as e:
        # Virtual devices must be set before GPUs have been initialized
        print(e)

Thanks @irdanish11 
link to comment: https://github.com/tensorflow/tensorflow/issues/24828#issuecomment-609426655

i have two envs and the above method also worked on:
![tf1](https://user-images.githubusercontent.com/65457337/84582087-a7a6d280-ade7-11ea-8df8-756bb2ff4ebc.png)



_**> I also tried:
>      config = tf.compat.v1.ConfigProto()
>      config.gpu_options.allow_growth = True
>      session = tf.compat.v1.InteractiveSession(config=config)
> 
> but it didn't work.**_


what also worked is:

physical_devices = tf.config.experimental.list_physical_devices('GPU') 
for physical_device in physical_devices: 
    tf.config.experimental.set_memory_growth(physical_device, True)



I am also facing this issue:

> (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
> 	 [[node sequential/conv1d/conv1d (defined at <ipython-input-13-75dbd6bef7ba>:1) ]]
> 	 [[gradient_tape/sequential/embed/embedding_lookup/Reshape/_40]]

Unfortunetely I have tried both setting memory growth:

> physical_devices = tf.config.experimental.list_physical_devices('GPU') 
> for physical_device in physical_devices: 
>     tf.config.experimental.set_memory_growth(physical_device, True)

and limiting GPU memory allocation:

> [gpus = tf.config.experimental.list_physical_devices('GPU')
> if gpus:
>     # Restrict TensorFlow to only allocate 1GB * 2 of memory on the first GPU
>     try:
>         tf.config.experimental.set_virtual_device_configuration(
>             gpus[0],
>             [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 2)])
>         logical_gpus = tf.config.experimental.list_logical_devices('GPU')
>         print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
>     except RuntimeError as e:
>         # Virtual devices must be set before GPUs have been initialized
>         print(e)](url)

I'm not really sure if the latter worked at all though, as after hitting the error `nvidia-smi` returns the following processes:

> | NVIDIA-SMI 440.82       Driver Version: 440.82       CUDA Version: 10.2     |
> |-------------------------------+----------------------+----------------------+
> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
> |===============================+======================+======================|
> |   0  GeForce RTX 2060    Off  | 00000000:01:00.0 Off |                  N/A |
> | N/A   59C    P2    28W /  N/A |   5925MiB /  5934MiB |      3%      Default |
> +-------------------------------+----------------------+----------------------+
>                                                                                
> +-----------------------------------------------------------------------------+
> | Processes:                                                       GPU Memory |
> |  GPU       PID   Type   Process name                             Usage      |
> |=============================================================================|
> |    0      1165      G   /usr/lib/xorg/Xorg                            28MiB |
> |    0      1329      G   /usr/bin/gnome-shell                          51MiB |
> |    0      1581      G   /usr/lib/xorg/Xorg                           152MiB |
> |    0      1755      G   /usr/bin/gnome-shell                         140MiB |
> |    0      2219      G   /usr/lib/firefox/firefox                       3MiB |
> |    0      6942      G   /usr/lib/firefox/firefox                       3MiB |
> |    0      7295      G   /usr/lib/firefox/firefox                       3MiB |
> |    0     14435      G   /usr/lib/firefox/firefox                       3MiB |
> |    0     22390      C   /home/kuba/anaconda3/envs/tf2.1/bin/python  5531MiB |
> +-----------------------------------------------------------------------------+

I installed Tensorflow using `conda install tensorflow-gpu` and my setup is as follows:

> _# Name                    Version                   Build  Channel
> cudnn                     7.6.5                cuda10.1_0_  
>  _# Name                    Version                   Build  Channel
> cudatoolkit               10.1.243             h6bb024c_0  

I've tried both with tensorflow 2.2 and 2.1, but the issue occurs no matter of the tf version.@KubaMichalczyk Your GPU is already in use i think. Does the training start or it does not start at all? You can also download any of the following two tools to monitor your gpu better:
https://www.linuxuprising.com/2019/06/2-tools-for-monitoring-nvidia-gpus-on.html

It would be good to know if your training started or it returned some error.@vkyprmr So here's the interesting thing: the training starts and crashes just after first batch with tensorflow 2.1, but doesn' seem to start with tensorflow 2.2. I attach full error message from the latter:

> 
> Epoch 1/20
> 
> ---------------------------------------------------------------------------
> UnknownError                              Traceback (most recent call last)
> <ipython-input-12-75dbd6bef7ba> in <module>
> ----> 1 history = model.fit(X_train, Y_train,
>       2                     epochs=20,
>       3                     batch_size=128,
>       4                     validation_split=0.2,
>       5                     callbacks=callbacks)
> 
> ~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
>      64   def _method_wrapper(self, *args, **kwargs):
>      65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
> ---> 66       return method(self, *args, **kwargs)
>      67 
>      68     # Running inside `run_distribute_coordinator` already.
> 
> ~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
>     846                 batch_size=batch_size):
>     847               callbacks.on_train_batch_begin(step)
> --> 848               tmp_logs = train_function(iterator)
>     849               # Catch OutOfRangeError for Datasets of unknown size.
>     850               # This blocks until the batch has finished executing.
> 
> ~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
>     578         xla_context.Exit()
>     579     else:
> --> 580       result = self._call(*args, **kwds)
>     581 
>     582     if tracing_count == self._get_tracing_count():
> 
> ~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
>     642         # Lifting succeeded, so variables are initialized and we can run the
>     643         # stateless function.
> --> 644         return self._stateless_fn(*args, **kwds)
>     645     else:
>     646       canon_args, canon_kwds = \
> 
> ~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
>    2418     with self._lock:
>    2419       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
> -> 2420     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
>    2421 
>    2422   @property
> 
> ~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs)
>    1659       `args` and `kwargs`.
>    1660     """
> -> 1661     return self._call_flat(
>    1662         (t for t in nest.flatten((args, kwargs), expand_composites=True)
>    1663          if isinstance(t, (ops.Tensor,
> 
> ~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
>    1743         and executing_eagerly):
>    1744       # No tape is watching; skip to running the function.
> -> 1745       return self._build_call_outputs(self._inference_function.call(
>    1746           ctx, args, cancellation_manager=cancellation_manager))
>    1747     forward_backward = self._select_forward_and_backward_functions(
> 
> ~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
>     591       with _InterpolateFunctionError(self):
>     592         if cancellation_manager is None:
> --> 593           outputs = execute.execute(
>     594               str(self.signature.name),
>     595               num_outputs=self._num_outputs,
> 
> ~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
>      57   try:
>      58     ctx.ensure_initialized()
> ---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
>      60                                         inputs, attrs, num_outputs)
>      61   except core._NotOkStatusException as e:
> 
> UnknownError: 2 root error(s) found.
>   (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
> 	 [[node sequential/conv1d/conv1d (defined at <ipython-input-12-75dbd6bef7ba>:1) ]]
> 	 [[gradient_tape/sequential/embed/embedding_lookup/Reshape/_40]]
>   (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
> 	 [[node sequential/conv1d/conv1d (defined at <ipython-input-12-75dbd6bef7ba>:1) ]]
> 0 successful operations.
> 0 derived errors ignored. [Op:__inference_train_function_1137]
> 
> Function call stack:
> train_function -> train_function@KubaMichalczyk 
Did you try reducing the batch size to 32???

Did you install tensorflow with pip or conda?
@vkyprmr Yes, I have tried with lower batch size as well. The error pops out always after first batch with tensorflow 2.1 and even before first batch with tensorflow 2.2. I installed it with conda.@KubaMichalczyk can you share your entire code?@vkyprmr sure, here it is: https://gist.github.com/KubaMichalczyk/0d01e2378edab0f3680e1de6fbcf30aa@KubaMichalczyk are you using Ubuntu? If so, perhaps another option is to try it out in Windows. I made a basic model, and it worked better in Windows than Ubuntu. Only drawback, Ubuntu has tf 2.2 whereas windows has 2.1Yes, I'm on Ubuntu, and I'm quite reluctant to switching to Windows. Thanks for suggestion though!@KubaMichalczyk  did you solve the issue with the "Error: failed to get convolution algorithm"? I think you might have to downgrade from 2.1 as i'm getting the same issue on windows with tf 2.1@KubaMichalczyk and @shini-tm can you guys may be give me your code and an idea about your data, maybe i can run it on my pc and let you guys know if it works on mine or not.I managed to not get the error when installing tensorflow 2.0 in a virtual environment. @vkyprmr its just this line that spits the error: pred_img = new_model.predict(test_img) in 2.1@vkyprmr You can easily run my code attached earlier as a gist - the data used are located in `tensorflow.keras.imdb`, so you should have it already available with your tf installation.
@shini-tm No, I did notwith me the training worked on your code @KubaMichalczyk 
I tried to run it dynamically, with allow_memory_growth=True and i got the following output:
![dynamic](https://user-images.githubusercontent.com/65457337/85116110-1a1b1680-b21d-11ea-94e3-c8d49d1d181e.png)


Then I tried to run it with static or given amount of GPU memory:
![staticmode](https://user-images.githubusercontent.com/65457337/85116154-2d2de680-b21d-11ea-8651-198b70cb9624.png)


Both the times the training started and i terminated it myself. 

Tensorflow version: 2.1.0 on Windows.
Unfortunately I have uninstalled Ubuntu, but I am sure it would have run on Ubuntu as well.

I just added a few lines of code to yours which included argparse, to run it with different batchsize and epochs from the command line/terminal. 

FYI: I ran it with a batch size of 64.

Here is the code that i added or the changes i made in your code:
`
import argparse
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing import sequence

#%%
parser = argparse.ArgumentParser()
parser.add_argument("-gm", "--gpumemory",dest = "gpu_memory", help="GPU Memory to use")
parser.add_argument("-m", "--mode",dest = "mode", help="Mode: 'static':'s' or 'dynamic':'d'")
parser.add_argument("-bs", "--batchsize",dest = "batch_size", help="Batch size")
parser.add_argument("-e", "--epochs",dest = "epochs", help="Epochs")


args = parser.parse_args()

batch_size = int(args.batch_size)
mode = args.mode.lower()
epochs = int(args.epochs)



#%%

if mode=='s' or mode=='static':
    gpu_mem = int(args.gpu_memory)
    gpus = tf.config.experimental.list_physical_devices('GPU')
    #The variable GB is the memory size you want to use.
    try:
        config = [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=(1024*gpu_mem))]
        if gpus:
            # Restrict TensorFlow to only allocate 1*X GB of memory on the first GPU
            try:
                tf.config.experimental.set_virtual_device_configuration(gpus[0], config)
                logical_gpus = tf.config.experimental.list_logical_devices('GPU')
                print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
            except RuntimeError as e:
                # Virtual devices must be set before GPUs have been initialized
                print(e)
    except:
        print('Static mode selected but no memory limit set. Please set a memory limit by adding the flag -gm=X (gb) or --gpumemory=x (gb) after -m=s or --memory=s')
        quit()
else:
    physical_devices = tf.config.experimental.list_physical_devices('GPU') 
    for physical_device in physical_devices: 
        tf.config.experimental.set_memory_growth(physical_device, True)`

and at the end:
`history = model.fit(X_train, Y_train,
                    epochs=epochs,
                    batch_size=batch_size,
                    validation_split=0.2,
                    callbacks=callbacks)`@shini-tm Sorry I did not fully understand you> @irdanish11, thank You for trying to help, but I think we have slightly different reasons for this issue. As for me, none of the cases you've listed are relevant:
> 
> 1. this issue come within just started container (no cache);
> 2. this issue comes with even simple model (i.e. one conv layer with one filter) - so, it cannot be out of memory error at all;
> 3. everything within an official docker image is compatible (i.e. CUDA, cuDNN, tf). Working around nvidia drivers on the host machine doesn't help at all;
> 4. always import from tf.keras - dose not matter.
> 
> Anyway, thank you!
In reference: [609607243](https://github.com/tensorflow/tensorflow/issues/24828#issuecomment-609607243) pryadchenko
@pryadchenko I agree with you on this point that you cannot have memory issues when you  have simple model (i.e. one conv layer with one filter), In my [original comment](https://github.com/tensorflow/tensorflow/issues/24828#issuecomment-609426655) I have represented a comparison between GTX1060 & GTX1660 Ti, both have same amount of memory the code worked fine on GTX1060 but gives the error on GTX1660 Ti, but I use the second solution it get solved. I also got the error on simplest Convnet  (i.e 1 conv layer and 1 filter) but with adding the code lines from 2nd solution solved the issue. I don't know what is the problem maybe there is an issue with tensorflow build for newer GPU's e.g GTX16 series.restarting the computer solved my problem :)@vkyprmr Finally, I managed to get it worked, firstly by running your code from terminal and then checking what's different in my jupyter notebook. The only difference I have found was checking if tensorflow is even available with `tf.test.gpu_device_name()`. It's super weird, but everytime I run a kernel with this line at the beginning cuDNN fails to initialise, but the problem is absent when I comment this line, restart the kernel and run again. Maybe it's something that `tf.test.gpu_device_name()` does under the hood? I also updated my nvidia drivers from 440.082 to 440.100, not sure if that helped.@KubaMichalczyk We had the same issue with this line (`tf.test.gpu_device_name()`). The problem was that calling it with `allow_memory_growth=True` was working fine, but without `allow_memory_growth=True` then the program would crash down the road with the cuDNN error.

I really don't understand how a simple check `tf.test.gpu_device_name()` which is not supposed to modify **anything** under the hoods can cause such a big difference in behavior...> @vkyprmr Finally, I managed to get it worked, firstly by running your code from terminal and then checking what's different in my jupyter notebook. The only difference I have found was checking if tensorflow is even available with `tf.test.gpu_device_name()`. It's super weird, but everytime I run a kernel with this line at the beginning cuDNN fails to initialise, but the problem is absent when I comment this line, restart the kernel and run again. Maybe it's something that `tf.test.gpu_device_name()` does under the hood? I also updated my nvidia drivers from 440.082 to 440.100, not sure if that helped.

@KubaMichalczyk I am glad that the issue is resolved. To be honest, I would never have figured that out myself. It is a really weird. Thanks for sharing your experience and knowledge.Epoch 1/15
---------------------------------------------------------------------------
UnknownError                              Traceback (most recent call last)
<ipython-input-11-01c6f78f4d4f> in <module>
      4     epochs=epochs,
      5     validation_data=val_data_gen,
----> 6     validation_steps=total_val // batch_size
      7 )

~/miniconda3/envs/handn/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    322               'in a future version' if date is None else ('after %s' % date),
    323               instructions)
--> 324       return func(*args, **kwargs)
    325     return tf_decorator.make_decorator(
    326         func, new_func, 'deprecated',

~/miniconda3/envs/handn/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1477         use_multiprocessing=use_multiprocessing,
   1478         shuffle=shuffle,
-> 1479         initial_epoch=initial_epoch)
   1480 
   1481   @deprecation.deprecated(

~/miniconda3/envs/handn/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---> 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

~/miniconda3/envs/handn/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
    846                 batch_size=batch_size):
    847               callbacks.on_train_batch_begin(step)
--> 848               tmp_logs = train_function(iterator)
    849               # Catch OutOfRangeError for Datasets of unknown size.
    850               # This blocks until the batch has finished executing.

~/miniconda3/envs/handn/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    578         xla_context.Exit()
    579     else:
--> 580       result = self._call(*args, **kwds)
    581 
    582     if tracing_count == self._get_tracing_count():

~/miniconda3/envs/handn/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    609       # In this case we have created variables on the first call, so we run the
    610       # defunned version which is guaranteed to never create variables.
--> 611       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
    612     elif self._stateful_fn is not None:
    613       # Release the lock early so that multiple threads can perform the call

~/miniconda3/envs/handn/lib/python3.7/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   2418     with self._lock:
   2419       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2420     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2421 
   2422   @property

~/miniconda3/envs/handn/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs)
   1663          if isinstance(t, (ops.Tensor,
   1664                            resource_variable_ops.BaseResourceVariable))),
-> 1665         self.captured_inputs)
   1666 
   1667   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

~/miniconda3/envs/handn/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1744       # No tape is watching; skip to running the function.
   1745       return self._build_call_outputs(self._inference_function.call(
-> 1746           ctx, args, cancellation_manager=cancellation_manager))
   1747     forward_backward = self._select_forward_and_backward_functions(
   1748         args,

~/miniconda3/envs/handn/lib/python3.7/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    596               inputs=args,
    597               attrs=attrs,
--> 598               ctx=ctx)
    599         else:
    600           outputs = execute.execute_with_cancellation(

~/miniconda3/envs/handn/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node sequential/conv2d/Conv2D (defined at <ipython-input-9-01c6f78f4d4f>:6) ]] [Op:__inference_train_function_933]

Function call stack:
train_function
Unable to get past:
`UnknownError: 2 root error(s) found.
  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.`

Full output at: https://gist.github.com/somyamohanty/b5dddf0952e9931b5ad852c2a7ca5d1c
**Config:**
Ubuntu 16.04
Cuda: 10.1
Driver: 418.87.01
Cuddn: 7.5.4
Tensorflow: 2.2 (tried with 2.0)
GPU: 1080Ti

Using the gist (provided by @KubaMichalczyk ). Tried most of the solutions given here. The only thing that works is downgrading tensorflow to 1.8. Looking at the GPU utilization, it does not reach the max memory utilization. Not sure whats going on. even though mentioned cuDNN failed to initialize, it is not necessarily a version mismatch problem
if you tried methods above and did not work，it is probably because GPU memory is exhausted
`os.environ['CUDA_VISIBLE_DEVICES'] = "-1"`
just use CPU ：）Hi, it should be somehow cudnn and cuda incompatibility. Using this to solve
`pip uninstall tensorflow-gpu`
`conda install tensorflow-gpu==2.1.0`

It works for me> I solved the problem by **uninstall tensorflow-gpu** from conda and pip environment . And use **conda to install tensorflow-gpu=1.14 conda install keras=2.2.5**. The dependencies will also be installed. But there is still problem, then just tf-gpu and keras are removed from conda env, by usage "conda remove --force tensorflow-gpu=1.14 ". After that , using pip install tensorflow-gpu==1.14 and keras==2.2.5. If raise error " there is no module of tensorflow" ，using pip install tf-gpu again . Then the problem solved.



> ```python
> physical_devices = tf.config.experimental.list_physical_devices('GPU') 
> for physical_device in physical_devices: 
>     tf.config.experimental.set_memory_growth(physical_device, True)
> ```
> 
> Also worked for me on tensorflow 2.2.0.
> 
> Now I just need to figure out the last error (3rd in a row):
> 
> ```
> type tensorflow.python.framework.ops.EagerTensor doesn't define __round__ method
> ```
> 
> edit: ok everything works now yay

This works for me using the official Docker Tensorflow-gpu-latest in Ubuntu 20.4 and GTX1060TiI faced the same problem and it got resolved by updating the Nvidia drivers to latest version 451.48
Following is my configuration:
Windows 10
# Name                    Version                   Build  Channel
cudnn                     7.6.5                cuda10.0_0
cudatoolkit               10.0.130                      0    anaconda
tf.__version__ = 2.0.0
> Hi, it should be somehow cudnn and cuda incompatibility. Using this to solve
> `pip uninstall tensorflow-gpu`
> `conda install tensorflow-gpu==2.1.0`
> 
> It works for me



> Hi, it should be somehow cudnn and cuda incompatibility. Using this to solve
> `pip uninstall tensorflow-gpu`
> `conda install tensorflow-gpu==2.1.0`
> 
> It works for me

Listen man this works> > Hi, it should be somehow cudnn and cuda incompatibility. Using this to solve
> > `pip uninstall tensorflow-gpu`
> > `conda install tensorflow-gpu==2.1.0`
> > It works for me
> 
> Listen man this works

What combination work?  I am still getting "cuDNN failed to initialize"
I had a previous conda install of tensorflow 2.2 so I ran:

conda remove --name tf_gpu --all
conda clean --all
conda create -n tf_gpu -c anaconda -y tensorflow-gpu==2.1.0
conda activate tf_gpu
git clone https://github.com/tensorflow/benchmarks.git
cd benchmarks/scripts/tf_cnn_benchmarks/
python3 tf_cnn_benchmarks.py --num_gpus=1 --model resnet50 --batch_size 32
** still get the cuDNN message **

I tried to move back to tensorflow-gpu=1.8.0, but conda wouldn't let me and said not compatible with cuda version 11 thats on my system from nvidia driver install.  What combination using conda works?  Thanks!> OK, I was able to execute my CNN. I'm using tensorflow tf-nightly-gpu-2.0-preview, and running on a ipython notebook. I had to add this to my notebook:
> 
> from tensorflow.compat.v1 import ConfigProto
> from tensorflow.compat.v1 import InteractiveSession
> 
> config = ConfigProto()
> config.gpu_options.allow_growth = True
> session = InteractiveSession(config=config)
> 
> [Here](https://www.tensorflow.org/guide/using_gpu) are some more details
> 
> Also, this issue is associated with [24496] (#24496)

Thank you so much this really helped
> 
> 
> > Did you try setting up allow_growth = True? That resolved the problem for me.
> 
> Yes, it helps!
> Thanks.
> @aishwaryap
> You can try setting up allow_growth:
> 
> config = tf.ConfigProto()
> config.gpu_options.allow_growth = True
> sess = tf.Session(config=config)

This resolved my issue as well, but I think a permanent solution should be implemented. To everyone here: TF 2.3 (compiled from source with CUDA 11 and cudnn 8.0) solved this issue for me, no need for any workaround now :)This problem also in general can happen if there is not enough VRAM available for the `model.fit()`. This cryptic exception happens instead of the common OOM error when using convolutional layers. (Using TF 2.2 on Linux) Allowing growth does not help in this case, if no VRAM is available.> OK, I was able to execute my CNN. I'm using tensorflow tf-nightly-gpu-2.0-preview, and running on a ipython notebook. I had to add this to my notebook:
> 
> from tensorflow.compat.v1 import ConfigProto
> from tensorflow.compat.v1 import InteractiveSession
> 
> config = ConfigProto()
> config.gpu_options.allow_growth = True
> session = InteractiveSession(config=config)
> 
> [Here](https://www.tensorflow.org/guide/using_gpu) are some more details
> 
> Also, this issue is associated with [24496] (#24496)

Using Tf 2.1.0 CUDA 11.0 CuDNN 7.6.4 and using python 2.7 
Had the same issue. Fixed it using the above fix.> OK, I was able to execute my CNN. I'm using tensorflow tf-nightly-gpu-2.0-preview, and running on a ipython notebook. I had to add this to my notebook:
> 
> from tensorflow.compat.v1 import ConfigProto
> from tensorflow.compat.v1 import InteractiveSession
> 
> config = ConfigProto()
> config.gpu_options.allow_growth = True
> session = InteractiveSession(config=config)
> 
> [Here](https://www.tensorflow.org/guide/using_gpu) are some more details
> 
> Also, this issue is associated with [24496] (#24496)

yeah, it's ok, but it only used half video memoryThis worked for me
For Linux:
Set the `TF_FORCE_GPU_ALLOW_GROWTH` environment variable to `true`.
In your terminal, run this command.
`$ export TF_FORCE_GPU_ALLOW_GROWTH=true` it was a very horrible problem, I fixed by upgrading my cudnn to the version that corresponds to cuda10.0. 

I created a new conda environment with tf-gpu=1.15.0 (this ensures compatibility) then removed tf-gpu=1.15.0 from this environment, then installed tf-gpu=1.15.2 (which I was interested in). 

hope it helps some others. I had the same problem in Ubuntu 16.04 with Nvidia 418 , Tensorflow-GPU 1.15 , Cuda 10.1, cuDNN 7.6.5.
I downgraded the cuDNN to 7.6.4 with the following command and now it works!

`sudo apt-get install  libcudnn7=7.6.4.38-1+cuda10.1  \
    libcudnn7-dev=7.6.4.38-1+cuda10.1`
 I faced this problem on RTX2070 super while training efficientdet_d0. Reducing the batch size for training worked for me. (TF2.0 repo .config file had training size 64 I changed it to 4)
I earlier faced the same problem and limit growth rate worked.
'config = tf.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.Session(config=config)'
ps- I am using opensource NVIDIA drivers.I have a RTX 2070 and GTX 1060 running with a batch size of 16 that seems to work okay using proprietary Nvidia drivers
> Same issue here. I have an RTX 2070, cuda 10, cudnn 7.4.1 and tensorflow 2.0 running on ubuntu 18.04. Downgraded cudnn to 7.3.0 but still same error. I see it helped for some people downgrading tensorflow but I guess that's not an option for me. Any help is much appreciated.

Hi @oscarlinux ,
Were you able to solve the issue? I have similar situation and my environment setup is as thus below:
Software Specs:
 Nvidia Geforce Experience Driver 418.96
 CudNN 10.1 (windows 7 version)
 Cuda 10.1.243
 Conda Python 3.7.4
 Tensorflow 2.1.0 
 Keras 2.3.1

PC Specs:
 Windows 7 (64 bits)
 GTX 1080
 48GB Intel i7-6700 (3.4GHz) 

Please let me know if you were able to get a solution to the issue.


> I also have the same error with TF 1.12,1.11, and I have Cuda 9.0, and cuDnn 7.3.1, 7.4.2. Sometimes it works but sometimes not, what is causing this error to happen. Did anyone solve this error?

This happens as your GPU memory runs out of memory.I solved the problem last week. This happens as the GPU memory runs out of memory.
Append the snippet below to your code; it works fine for me since then, at least.

import tensorflow as tf
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))
config = tf.compat.v1.ConfigProto(allow_soft_placement=True)

config.gpu_options.per_process_gpu_memory_fraction = 0.3
tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))


PS: the print line is not important!This happened to me when someone else on the same computer was performing training. I didn't know. When the training stopped the GPU was not used at all and then code executed without any issue.

I believe it has to do something with GPU sharing.

My packages were 
```
# Name                    Version                   Build  Channel
tensorflow-estimator      2.3.0                    pypi_0    pypi
tensorflow-gpu            2.3.0                    pypi_0    pypi
cudnn                     7.6.5                cuda10.1_0 
```I have the same issue with the following configuration : 
Nvidia Quadro RTX3000
Cuda 10.1
Cudnn 7.6.4.38Same issue. I can vaguely workaround if I:

1. `pip uninstall` both tensorflow and tensorflow-gpu
2. `pip cache purge`
3. go to the folder .../python38/Lib/Site-packages and delete tensorflow folders
4. fresh `pip install tensorflow --no-cache-dir`

But that only works one time and then I have to repeat the whole process again... :(Check to confirm that your cuDNN version matches with CUDA and tensorflow versions. I think that's the reason. You may also consider re-installing as suggested but it didn't work for me until I fix the version issues.Was facing the same issue, I resolved it by reducing the batch size.> 
> 
> Check to confirm that your cuDNN version matches with CUDA and tensorflow versions. I think that's the reason. You may also consider re-installing as suggested but it didn't work for me until I fix the version issues.

I just updated everything (CUDA + cuDNN + TF) to the latest version. It's all the same...It doesn't have to be the latest version for all. You need to check the matching version. For instance, CudNN 10.1 (windows 7 version); Cuda 10.1.243; and Tensorflow 2.1.0 were the versions that matched in my case. 

PS: the OS is also a factor to consider.There is a problem then, as Tensorflow [recommends](https://www.tensorflow.org/install/source_windows#gpu) a combination of cuDNN 7.4 and CUDA 10.1 but the cuDNN [archive](https://developer.nvidia.com/rdp/cudnn-archive) only has cuDNN 7.4 compatibility up to CUDA 10.0...

EDIT: Meanwhile I'm using python 3.7 to fulfill the upper-mentioned criteria and **this seems to work so far!** (thank you @tsorewilly)可能是你同时打开了不同版本下的spyder和jupyterWindows 10 machine with RTX 2060 SUPER. The problem doesn't appear on TF2.1 and CUDA 10.1 but it does on ```tf-nightly 2.5.0-dev20201121```, latest CUDA (11.1, 8.0.5), Python 3.8, PyCharm but, what's even more interesting, the issue doesn't appear on the latter TF-nightly & CUDA 11.1 version on GTX780M! I don't understand how it can be...> 
> 
> Windows 10 machine with RTX 2060 SUPER. The problem doesn't appear on TF2.1 and CUDA 10.1 but it does on `tf-nightly 2.5.0-dev20201121`, latest CUDA (11.1, 8.0.5), Python 3.8, PyCharm but, what's even more interesting, the issue doesn't appear on the latter TF-nightly & CUDA 11.1 version on GTX780M! I don't understand how it can be...

By what I experienced it is more a question of the combination of the different versions, rather than one of them alone (TF + CUDA + cuDNN)i love tensorflow, but the gpu compatibility problem from their beginning is still a big question why dont they work on a robust solution!! instead of new versions, i believe they should focus on making tensorflow robust and save our valuable time!

i am having same problem, 
``` Ubuntu 18.04
RTX 2070 Super ```

tried tensorflow 1.14 gpu with cuda 10.1 cudnn 7.6.5 . 

i used this command , `conda install -c anaconda tensorflow-gpu=1.14` 
i am having this issue whenever i try to run a convolutional neural network. SOMEBODY HELP!Another surprise happened to me. Two machines with identical specs, OS, graphic card drivers etc., ```tf-nightly 2.5.0-dev20201121```, latest CUDA (11.1, 8.0.5), Python 3.8. On one computer: everything work; the other one: has problems right after the message about successfully loading cublas64_11.dll and before cublasLt64_11.dll. No idea why! Wasted 1.5 working days, uninstalled, installed everything around CUDA and Python over and over again trying each possible combination of CUDA + cuDNN, copied and pasted all required files and settings from the working machine to the other one. 

I gave up. Staying with TF 2.3 since it works on every machine I work on so far.> This worked for me
> For Linux:
> Set the `TF_FORCE_GPU_ALLOW_GROWTH` environment variable to `true`.
> In your terminal, run this command.
> `$ export TF_FORCE_GPU_ALLOW_GROWTH=true`

After going over all the proposed solutions, this one is what solved it for me 
NOTE:  windows 10, cuda 10.0, cudnn 7.6> This error may be related to installation TF with `conda`.
> 
> The possible solution is like this:
> In the command line issue this command:
> `conda list cudnn`
> It will print:
> ` Name Version Build Channel`
> 
> If the result is not empty as the above, so it means you used conda installed TF, when using conda for installing TF, then it will install all the dependencies even CUDA and cuDNN, but the cuDNN version is very low for TF, so it will bring compatibility problem. So you can uninstall the cuDNN and the CUDA which was installed by conda, and then run TF, then it will work.

Thanks, this worked on Tensorflow-GPU installed on Ubuntu 20.04 using conda.

If you have installed Tensorflow-gpu using Conda, then install the **cudnn** and **cudatoolkit** which were installed along with it and re-run the notebook.

**NOTE**: Trying to uninstall only these two packages in conda would **force** a chain of other packages to be uninstalled as well. So, use the following command to uninstall only these packages

**(1)** To remove the cuda

`conda remove --force cudatookit`

**(2)** To remove the cudnn

`conda remove --force cudnn`

Now run Tensorflow, it should work!I tried with:

1. `pip uninstall tensorflow-gpu` as my pc just installed tensorflow-gpu
2. `pip cache purge`
3. Deleted tensorflow folders in .../python38/Lib/Site-packages
4. `pip install tensorflow-gpu --no-cache-dir`

But it raise me same error.

System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): WIndows 10 64bit
TensorFlow installed from (source or binary): pip install tensorflow-gpu
TensorFlow version: tensorflow-gpu 2.4.0
Python version: Python 3.7
Installed using virtualenv? pip? conda?: pip
CUDA/cuDNN version: CUDA11, cuDNN 8.0.5
GPU model and memory: RTX3070 8GB OC

The log shown as below:
```
2021-01-06 18:21:30.484673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:09:00.0 name: GeForce RTX 3070 computeCapability: 8.6
coreClock: 1.755GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2021-01-06 18:21:30.485159: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-01-06 18:21:30.485494: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-01-06 18:21:30.486402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-01-06 18:21:30.486726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-01-06 18:21:30.487637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-01-06 18:21:30.487971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-01-06 18:21:30.488935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2021-01-06 18:21:30.489355: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-01-06 18:21:30.489743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-01-06 18:21:36.156145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-06 18:21:36.156275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0
2021-01-06 18:21:36.157045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N
2021-01-06 18:21:36.157466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6589 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:09:00.0, compute capability: 8.6)
2021-01-06 18:21:36.158785: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-06 18:21:37.935914: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-01-06 18:21:38.345639: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-01-06 18:21:44.113075: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2021-01-06 18:21:44.113322: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2021-01-06 18:21:44.114653: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2021-01-06 18:21:44.116732: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2021-01-06 18:21:44.117351: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2021-01-06 18:21:44.118153: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2021-01-06 18:21:44.683728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-01-06 18:21:48.700894: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2021-01-06 18:21:48.701422: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2021-01-06 18:21:48.701512: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_ops_fused_impl.h:697 : Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
```@hansheng0512 Install TensorFlow GPU on a conda environment and just uninstall the default **cudatoolkit** and **cudnn** that is installed along with it.

**(1)** To remove the cuda

`conda remove --force cudatookit`

**(2)** To remove the cudnn

`conda remove --force cudnn`> @hansheng0512 Install TensorFlow GPU on a conda environment and just uninstall the default **cudatoolkit** and **cudnn** that is installed along with it.
> 
> **(1)** To remove the cuda
> 
> `conda remove --force cudatookit`
> 
> **(2)** To remove the cudnn
> 
> `conda remove --force cudnn`

Hi,

FYI I'm using pip only, I don't use conda environment as conda environment dont support CUDA 11. I'm using RTX3070> > @hansheng0512 Install TensorFlow GPU on a conda environment and just uninstall the default **cudatoolkit** and **cudnn** that is installed along with it.
> > **(1)** To remove the cuda
> > `conda remove --force cudatookit`
> > **(2)** To remove the cudnn
> > `conda remove --force cudnn`
> 
> Hi,
> 
> FYI I'm using pip only, I don't use conda environment as conda environment dont support CUDA 11. I'm using RTX3070

Okay, I haven't tried it with pip. Goodluck!> OK, I was able to execute my CNN. I'm using tensorflow tf-nightly-gpu-2.0-preview, and running on a ipython notebook. I had to add this to my notebook:
> 
> from tensorflow.compat.v1 import ConfigProto
> from tensorflow.compat.v1 import InteractiveSession
> 
> config = ConfigProto()
> config.gpu_options.allow_growth = True
> session = InteractiveSession(config=config)
> 
> [Here](https://www.tensorflow.org/guide/using_gpu) are some more details
> 
> Also, this issue is associated with [24496] (#24496)

This solution worked for me. Just to add on - if you set `allow_growth = True` during training, you have to configure the gpu in the same way when restoring the model otherwise you will have issues.> > OK, I was able to execute my CNN. I'm using tensorflow tf-nightly-gpu-2.0-preview, and running on a ipython notebook. I had to add this to my notebook:
> > from tensorflow.compat.v1 import ConfigProto
> > from tensorflow.compat.v1 import InteractiveSession
> > config = ConfigProto()
> > config.gpu_options.allow_growth = True
> > session = InteractiveSession(config=config)
> > [Here](https://www.tensorflow.org/guide/using_gpu) are some more details
> > Also, this issue is associated with [24496] (#24496)
> 
> This solution worked for me. Just to add on - if you set `allow_growth = True` during training, you have to configure the gpu in the same way when restoring the model otherwise you will have issues.

Yea it works! Actually what is the concept behind by enabling `allow_growth = True`?> `import tensorflow as tf`
> `config = tf.ConfigProto()`
> `config.gpu_options.allow_growth = True`
> `sess = tf.Session(config=config)`

I tried this solution but doesn't work, my system specifications are:
TF version: 2.2
OS: Windows Server 2019
cuda version: 10.1
cuDNN: 7.6.4
GPU: GTeslaV100
can you help please?> > `import tensorflow as tf`
> > `config = tf.ConfigProto()`
> > `config.gpu_options.allow_growth = True`
> > `sess = tf.Session(config=config)`
> 
> I tried this solution but doesn't work, my system specifications are:
> TF version: 2.2
> OS: Windows Server 2019
> cuda version: 10.1
> cuDNN: 7.6.4
> GPU: GTeslaV100
> can you help please?

```
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], True)
```

Try with this.See, I made a solution. 
First install graphics respective of your graphics drivers
Install Anaconda
```
conda update conda
conda update anaconda

then 

conda create -n py36 python=3.6

# first thing you do
conda install tensorflow-gpu=1.15
# this install cudatoolkit=10.0 cudnn=7.6.5 and of course tensorflow-gpu=1.15
```
Now if you want to want to run tensorflow with eager execution then
```
import tensorflow as tf
tf.enable_eager_execution()
```
This makes tensorflow>=2.0.0 codes to run and even you can make them

else if you want to stick with older version tensorflow<2.0.0 then run as usual with tf.Session(), tf.placeholders, tf.Variables, ... and so on.Confirming that I hit this error while training a model on an RTX 2060, and setting `TF_FORCE_ALLOW_GROWTH` to `True` resolved the error. Had a similar issue on a machine with 2 A100s. There was some device ambiguity and so looping through the devices and setting the memory growth manually worked in a tensorflow 2.x environment.

`gpu_devices = tf.config.experimental.list_physical_devices('GPU')`
`for device in gpu_devices:  tf.config.experimental.set_memory_growth(device, True)`

Taken from a different issue

https://github.com/tensorflow/tensorflow/issues/25446#issuecomment-562232813What worked for my Win10 using Anaconda (Python 3.5.x and NVIDIA GTX1650 was:
-Downgrade to CUDA 9.0 (with Matching CUDNN 7.x)
-Downgrade to Tensorflow 1.8.0 (check by 'pip show tensorflow')
-Downgrade to Tensorflow-GPU 1.8.0 (check by 'pip show tensorflow-gpu)
-Ensure overwrite the CUDNN files (For some reason I had to overwrite the existing cudnn.lib file -C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64 with the CUDNN.zip download. The version downgrade left the more recent version, which had to be replaced to remove the "failed convolution" error to go away

--Hope this helps--It probably because of the memory growth under tensorflow framework, so try to add 
import tensorflow as tf
from keras import backend as K
config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.4## max GPU occupation
K.set_session(tf.Session(config=config))
K.get_session().run(tf.global_variables_initializer())
before the whole code... It works for me.try:

import tensorflow as tf
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)

    except RuntimeError as e:
        print(e)Hy I hope that  you all are doing good. I need to train my mrcnn model on gtx 3070. Model loads onto the gpu but stuck while starting training no error appears but it stuck. When I list tensorflow device it show GPU exists but training not starts.

![Screenshot from 2021-04-18 12-53-28](https://user-images.githubusercontent.com/29427728/115138389-3bb77b00-a045-11eb-9534-90d55308cfef.png)



Versions I am using:

1. Tensorflow 2.4
2. cudnn 8
3. cuda 11.0
4. nvidia-drivers 460


![Screenshot from 2021-04-18 12-45-13](https://user-images.githubusercontent.com/29427728/115138252-681ec780-a044-11eb-9e7d-c567d1219df0.png)

![Screenshot from 2021-04-18 12-45-37](https://user-images.githubusercontent.com/29427728/115138260-6ead3f00-a044-11eb-8e35-7fb1f976b51e.png)

![Screenshot from 2021-04-18 12-47-57](https://user-images.githubusercontent.com/29427728/115138273-7ec51e80-a044-11eb-91df-b8f536cb8952.png)


I will really be thankful to you for helping me out. Thank you

> If the result is not empty as the above, so it means you used conda installed TF, when using conda for installing TF, then it will install all the dependencies even CUDA and cuDNN, but the cuDNN version is very low for TF, so it will bring compatibility problem. So you can uninstall the cuDNN and the CUDA which was installed by conda, and then run TF, then it will work.

So one should reinstall using the nvidia installer?

This solve my problem [here](https://www.tensorflow.org/install/source#gpu). Try to match the verison.@sauravsolanki
> This solve my problem [here](https://www.tensorflow.org/install/source#gpu). Try to match the verison.

So you managed to make it work with these following versions ?
tensorflow-2.4.0 | python 3.6-3.8 | GCC&nbsp;7.3.1 | Bazel&nbsp;3.1.0 | cuDNN 8.0 | CUDA 11.0


@q-55555 Yes.


> This solve my problem [here](https://www.tensorflow.org/install/source#gpu). Try to match the verison.

especially cuDNN version and tensorflow version, I downgraded tf version to match cuDNN version, then it's ok.I had the same problem and I solved it with this code
`import tensorflow as tf`
`config = tf.compat.v1.ConfigProto()`
`config.gpu_options.allow_growth = True`
`sess = tf.compat.v1.InteractiveSession(config=config)`> i also has same problem
> try it delete the old cuDNN SDK (i remember it's no for 9.0)
> download the cudnn-9.0-windows10-x64-v7.4.1.5
> new cudnn-9.0-windows10-x64-v7.4.2.24.zip also work well
> for 9.0 9.0 9.0
> it's very important
> then it work well
> 
> system win 10
> tensorflow 1.12
> CUDA 9.0
> cuDNN SDK 7.4.1.5
> GPU GTX1060

is works !