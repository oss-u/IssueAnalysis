Are there plans to support Cuda compute capability 3. 
Officially, Cuda compute capability 3.5 and 5.2 are supported. You can try to enable other compute capability by modifying the build script: 

 LINKLINK 
Thanks! Will try it and report here.
This is not officially supported yet. But if you want to enable Cuda 3.0 locally, here are the additional places to change: 

 LINKLINK 
 LINKLINK 
Where the smaller GPU device is ignored. 

The official support will eventually come in a different form, where we make sure the fix works on all different computational environment.
I made the changes to the lines above, and was able to compile and run the basic example on the Getting Started page: LINKLINK it did not complain about gpu, but it didn't report using the gpu either.

How can I help with next steps?
infojunkie, could you post your step and upload the log?

If you were following this example: 

bazel build c opt config cuda tensorflow cc: tutorials example trainer
bazel bin tensorflow cc tutorials example trainer use gpu

If you see the following line, the GPU logic device is being created: 

Creating TensorFlow device gpu:0 device: name: pci bus id: 

If you want to be absolutely sure GPU was used, set CUDA PROFILE 1 and enable Cuda profiler. If the Cuda profiler logs were generated, it was a sure sign GPU was used. 

 LINKLINK 
I got the following log: 

 CODELCODEL 

I guess it means the GPU was found and used. I can try the CUDA profiler if you think it's useful.
Please prioritize this issue. It is blocking gpu usage on both OSX and AWS's K520 and for many people this is the only environments available.
Thanks!
Not the nicest fix, but just comment out the the cuda compute version check at gpu device. c line LINKLINK to LINKLINK, recompile, and amazon g2 GPU acceleration seems to works fine:

 LINKLINK 
For reference, here's my very primitive patch to work with Cuda 3. LINKLINK 
 infojunkie I applied your fix, but I got lots of nan's in the computation output:

 CODELCODEL 
 markusdr, this is very strange. Could you post the completely steps you build the binary? 

Could what GPU and OS are you running with? Are you using Cuda 7.0 and Cudnn 6.5 V2? 
Just thumbs up to fix this problem on AWS as soon as possible. We don't have any other GPU cards for our research.
Hi, not sure if this is a separate issue but I'm trying to build with a CUDA 3.0 GPU Geforce 660 Ti and am getting many errors with config cuda. See the attached file below. It seems unrelated to the recommended changes above. I've noticed that it tries to compile a temporary compute 52. cpp1. ii file which would be the wrong version for my GPU.

I'm on Ubuntu 15.10. I modified the host config. h in the Cuda includes to remove the version check on gcc. I'm using Cuda 7.0 and cuDNN 6.5 v2 as recommended, although I have newer versions installed as well.

 LINKLINK 
Yes, I was using Cuda 7.0 and Cudnn 6.5 on an EC2 g2.2xlarge instance with this AIM:
cuda 7 ami thumbs down 2fd8178
ubuntu 14.04, gcc 4. cuda 7. atlas, and opencv.
To build, I followed the instructions on tensorflow. org.
It looks like we are seeing an API incompatibility between Compute Capability v3 and Compute Capability v3.5; post infojunkie's patch fix, I stumped onto this issue

I tensorflow core common runtime gpu gpu device. cc:643 Creating TensorFlow device gpu:0 device: 0, name: Quadro K2100M, pci bus id: 0000:01:00.0 
I tensorflow core common runtime local session. cc:45 Local session inter op parallelism threads: 8
F tensorflow stream executor cuda cuda blas. cc:229 Check failed: f! nullptr could not find cublasCreate v2 in cuBLAS DSO ; dlerror: bazel bin tensorflow cc tutorials example trainer: undefined symbol: cublasCreate v2

I run on Ubuntu 15.04, gcc 4.2, CUDA Toolkit 7. cuDNN 6.5;

 thumbs up for having Compute Capability v3 Support 
is cublas installed? and where does it link to 
ls lah usr local cuda lib64 libcublas. so?
 allanzelener, what OS and GCC versions do you have? Your errors seem to come from incompatible C++ compilers.

It is recommended to use Ubuntu 14.04 and GCC 4.8 with TensorFlow. 
 vsrikarunyan, it is better to use CUDA Toolkit 7. as recommended. You can install an older CUDA Toolkit along with your newer toolkit. Just point TensorFlow configure and maybe LD LIBRARY PATH to the CUDA 7.0 when you run TensorFlow. 
 avostryakov, infojunkie's early patch should work on AWS. 

 LINKLINK 

An official patch is working its way through the pipeline. It would expose a configuration option to let you choose your compute target. But underneath, it does similar changes. I've tried it on AWS g2, and find out once things would work, after I completely uninstall NVIDIA driver, and reinstall the latest GPU driver from NVIDIA. 

Once again, the recommended setting on AWS at this point is the following. 
Ubuntu 14.04, GCC 4. CUDA Toolkit 7.0 and CUDNN 6. For the last two, it is okay to install them without affecting your existing installation of other versions. Also the official recommended versions for the last two might change soon as well. 
I applied the same patch on a g2.2xlarge instance and got the same result as markusdr. a bunch of nan's. 
 zheng xq Yes, I'm on Ubuntu 15.10 and I was using GCC 5.1. The issue was the compiler. I couldn't figure out how to change the compiler with bazel but simply installing gcc 4.8 and using update alternatives to change the symlinks in usr bin seems to have worked. More info: LINKLINK. Thanks for the help, I'll report back if I experience any further issues.
I did get this to work on a g2.2xlarge instance and got the training example to run, and verified that the gpu was active using the nvidia smi tool, but when running mnist's convolutional. py, it ran out of memory. I suspect this just has to do with the batch size and the fact that the aws gpus don't have a lot of memory, but just wanted to throw that out there to make sure it sounds correct. To clarify, I ran the following, and it ran for like 15 minutes, and then ran out of memory. 

python tensorflow models image mnist convolutional. py
 nbenhaim, just what did you have to do to get it to work?
 markusdr, jbencook, the NAN is quite troubling. I ran the same thing myself, and didn't have any problem. 

If you use the recommended software setting: Ubuntu 14.04, GCC 4. Cuda 7.0 and Cudnn 6. then my next guess is the Cuda driver. Could you uninstall and reinstall the latest Cuda driver. 

This is the sequence I tried on AWS, your mileage may vary:

sudo apt get remove purge nvidia 
wget LINKLINK 
sudo. NVIDIA Linux x86 64 352.55. run accept license no x check no recursion
Thanks for following up zheng xq I'll give that a shot today.
Another thumbs up for supporting pre 3.5 GPUs, as someone else whose only realistic option for training on real data is AWS GPU instances.

Even for local testing, turns out my recent, developer laptop's GPU doesn't support 3. 
 anjishnu I just followed infojunkie 's patch LINKLINK after doing a clean install and build by following the directions.

A few comments The AMI I was using had the NVIDIA cuda toolkit 6.5 installed, so when I followed the link in the tensorflow getting started guide, I downloaded the 7. run file for ubuntu 14.04, upgraded the driver, and installed cuda 7.0 into usr local cuda 7.0 without creating a symlink to usr local cuda since I already had 6.5 installed and didn't wanna kill it

Then, when building I just specified the right location of cuda 7. One confusing thing is that when builting the python library, the tutorial doesn't remind you to specify config cuda, but you have to do that if you want the python lib to utilize gpu
 markusdr, jbencook, I got an NaN and all kinds of messed up values as well when I applied the patch initially, but what fixed it was doing a bazel clean and rebuilding from scratch after making the proposed changes outlined in infojunkie 's patch. Did you try this?
Interesing. no I haven't had a chance yet. Did you try running the CNN from the Getting Started guide?

 CODELCODEL 

Curious to hear if that worked correctly.
 jbencook as I mentioned, convolutional. py seems to run correctly, but after like 15 minutes it crashes due to out of memory, but the output looks correct and I used nvidia smi's tool to verify that it's actually running on the GPU and it is. I suspect that this is because the batch size. i know that the gpus on ec2 don't have that much memory, but I'm really unsure at this moment why it ran out of memory
The convolutional. py example ran out of GPU memory for me too, on a GeForce GTX 780 Ti.
I was able to install it on AWS after lots of pain. See LINKLINK – I also built an AMI: ami cf5028a5 in Virginia region 

It works on g2.2xlarge and g2.8xlarge and it detects the devices correctly 1 and 4 respectively. However I'm not seeing any speedup from the 4 GPU cards on the g2.8xlarge. Both machines process about 330 examples sec running the CIFAR 10 example with multiple GPUs. Also very similar performance on the MNIST convolutional example. It also crashes after about 15 minutes with Out of GPU memory, see memory state dump above as some other people mentioned above

I've run the CIFAR example for about an hour and it seems to chug along quite well so far
As for building for Cuda 3.0 device, if you sync the latest TensorFlow code, you can do the following. The official documentation will update soon. But this is what it looks like: 

 TF UNOFFICIAL SETTING 1. configure
. Same as the official settings above

WARNING: You are configuring unofficial settings in TensorFlow. Because some
external libraries are not backward compatible, these settings are largely
untested and unsupported.

Please specify a list of comma separated Cuda compute capabilities you want to 
build with. You can find the compute capability of your device at: 
 LINKLINK. 
Please note that each additional compute capability significantly increases 
your build time and binary size. 3.0

Setting up Cuda include
Setting up Cuda lib64
Setting up Cuda bin
Setting up Cuda nvvm
Configuration finished
 nbenhaim markusdr 

Out of memory issue may be due to fact that CODESCODES runs evaluation on the whole test dataset 10000 examples. It happens after training is finished, as the last step:

 LINKLINK 

Can you try slicing CODESCODES and CODESCODES to make is smaller?
I can confirm that with erikbern's install script and the latest TensorFlow master branch the CODESCODES works as expected on the GPU:

 CODELCODEL 

Although LINKLINK now breaks because of the code changes.

Also if I take 1000 test samples the CODESCODES example works too.

EDIT: The CODESCODES example also works without giving me a bunch of nan's.
I confirm that the latest build supports specifying the compute capability via 
 CODESCODES 
without need for a patch. Thanks!

I think this issue can be closed, unless someone encounters an actual function that fails for Cuda 3.
Actually, let me take that back: The CODESCODES script modifies the source code by changing the relevant lines with the hand specified Cuda versions. Then git reports uncommitted changes and it becomes very difficult to work with this codebase without reverting the change, CODESCODES ing, and configuring again, not to mention submitting contributions.

A better approach would be to read those version settings from a config file.
ErikBern above and his AMI is working for cifar for me ami cf5028a5 

Getting 320 samples per sec versus my i7 windows box on docker which gets 105 samples per second for cifar10 train. py
 infojunkie: yes, this isn't ideal zheng xq and I discussed this a bit during the review!

We'll try to think of a better way to handle this, though we would like to keep the ability for the runtime device filtering to be in sync with the way the binary was built hence needing to edit the source code for both compile and runtime. Otherwise users get hard to debug errors.

We'll continue to work on making this easier, but hopefully this allows some forward progress for you.
 vrv: yes, I can definitely continue my work with these fixes. Thanks for the support!
Just curious, as c4.4xlarge with 16 vCpus is about.88 per hour versus the gpu instance which is.65 per hour, wouldn't that be better to use multiple cpu than gpu?
 timshephard I doubt it, but feel free to run some benchmarks – you can install my AMI ami cf5028a5 on a c4.4xlarge and run cifar10 train. py
Actually, the g2.2xlarge has 8 cpus alongside the GPU. Going to try that.
multi threaded CPU is supported, but if you want to do any real training,
GPU 4 Life, until they release the distributed implementation

 Erik Bernhardsson 











I was only getting a 3x speed up for amazon GPU over my windows CPU on docker. Nice, but that was only 1 of my cores. All 4 cores on my windows box could probably beat an amazon GPU.
that's interesting, because with caffe, I didn't do any actual benchmarks,
but training in CPU mode is horrible, like order of magnitude or more
difference. Maybe TF is optimized better in CPU mode wouldnt surprise
me.

 timshephard 
wrote:









Please bear in mind that the cifar10 tutorial as it is is not meant to be a benchmark. It is meant to show case a few different features, such as saver and summary. In its current form, it will be CPU limited, even with GPU. To benchmark, one will have to be more careful and only use essential features.
Could be just amazon GPUs are slow for some reason LINKLINK 
Interesting report: A g2.2xlarge is a downclocked GK104 797 MHz, that would make it 1 4 the speed of the recently released TitanX and 2.7x slower than a GTX 980. 
fwiw, getting 2015 thumbs down 1 thumbs down 3 00:38:05.472034: step 20, loss 4.64 362.5 examples sec; 0.353 sec batch 
now with 7 cpus and cifar10 multi gpu train. py. I changed the all of the device references from gpu to cpu, if that makes sense. 

ok, weird. 2015 thumbs down 1 thumbs down 3 00:43:56.914273: step 10, loss 4.65 347.4 examples sec; 0.368 sec batch and using 2 cpus, so clearly something failed here. Must be using the GPU still. Interesting that it processes a bit faster than single gpu version of the script. 
even with erikbern's instructions I am still getting 

AssertionError: Model diverged with loss NaN when I try cifar train. py and this when running mnist convolutional. py

Epoch 1.63
Minibatch loss: nan, learning rate: nan
Minibatch error: 90.6 
Validation error: 90.4 
Epoch 1.75
Minibatch loss: nan, learning rate: 0.000000
Minibatch error: 92.2 
Validation error: 90.4 
Epoch 1.86
Minibatch loss: nan, learning rate: 0.000000
I got it to run on GPU on AWS, but like the others I am getting unimpressive speeds.
I was able to get the convolutional. py example running without running out of memory after using the correct fix suggested by zheng xq of setting the option when running configure
The install script provided by erikbern no longer works as of commit 9c3043ff3bf31a6a81810b4ce9e87ef936f1f529

The most recent commit introduced this bug, keveman already made a note on the commit here:
 LINKLINK 
Hi! I have a problem with compilation of tensorflow with GTX 670. I run 

 CODELCODEL 

I got error:

 CODELCODEL 

Information about my card from NVIDIA samples deviceQuery:

 CODELCODEL 

Any ideas why it is not working?
Thanks!
the ldg primitive only exists for 3.5+ I think. We have an internal fix to support both that we'll try to push out soon.

See LINKLINK for more details
Thanks! Adding fix from 320 helped me, I can compile with a lot of warnings and execute 

 CODELCODEL 

When I run examples:

 CODELCODEL 

I get warning that:

 CODELCODEL 

How to enable GPU in examples from tensorflow models images?
 erikbern
did you figure out multiple GPU issue on Amazon? I am also running CIFAR multiple GPU instance but see no speedup.

Here is the GPU utilization status, it seems like all GPUs are in use but they do not do anything.

+ +
 NVIDIA SMI 346.46 Driver Version: 346.46 
 + + +
 GPU Name Persistence M Bus Id Disp. A Volatile Uncorr. ECC 
 Fan Temp Perf Pwr: Usage Cap Memory Usage GPU Util Compute 
 + + 
 0 GRID K520 Off 0000:00:03.0 Off N A 
 N A 54C P0 55W 125W 3832MiB 4095MiB 37 Default 
+ + + +
 1 GRID K520 Off 0000:00:04.0 Off N A 
 N A 42C P0 42W 125W 3796MiB 4095MiB 0 Default 
+ + + +
 2 GRID K520 Off 0000:00:05.0 Off N A 
 N A 46C P0 43W 125W 3796MiB 4095MiB 0 Default 
+ + + +
 3 GRID K520 Off 0000:00:06.0 Off N A 
 N A 43C P0 41W 125W 3796MiB 4095MiB 0 Default 
+ + + +

+ +
 Processes: GPU Memory 
 GPU PID Type Process name Usage 
 
 0 60160 C python 3819MiB 
 1 60160 C python 3783MiB 
 2 60160 C python 3783MiB 
 3 60160 C python 3783MiB 
+ +
 mhejrati according to a comment on LINKLINK it seems like you can't do it in AWS:



Not sure how trustworthy HN comments are, but that's all I know so far
 erikbern mhejrati I'm not so sure that specific property of Xen is a problem. P2P copies don't seem to be necessary as the cpu can still assign work to each GPU without GPUs needing to communicate to each other. It's still strange that all GPUs on the instance seem to be in this semi utilized state but work proceeds without error.
I'll close this bug. Please open a new one with a more specific title if some issues in here remain unresolved.
Does it means that the last version of tensorflow works on Amazon g2 instances without any hacks? And Does it mean that it works more than one GPU there?

And is it possible to execute code on two or more GPUs on an amazon instance? For example, data parallelism for training a model like in CIFAR example. Several guys just 5 comments above this comment wrote that it was not possible.
I don't know. But if that's still an issue with 0.0, it should be a bug, just a more specific one about multiple GPUs.
I am using 0.0 on ubuntu, not able to use more than one GPUs. The GPU utilization on one GPU is always Just for point of reference, renting a K40 or K80 is not actually prohibitively expensive. Amazon doesn't have them, but several of the options on LINKLINK do. Some for as low as like 3 hr 
Theano and Torch have no problem with compute 3.0 whatsoever. Can we expect TensorFlow to support compute 3.0 anytime soon?

Or at least add the ability to override the restriction without having to recompile.
 Dringite, you can enable Cuda 3.0 using the following: 

TF UNOFFICIAL SETTING 1. configure

It should be functional. And if it doesn't, feel free to file another issue to track it. 
The tensorflow install guide now includes a fix for cuda 3.0 as well

 zheng xq wrote:













I think current guide does not work for gpu's the test returns nan's as reported before.
In particular you still need to do this:
TF UNOFFICIAL SETTING 1. configure
I can't find the install guide including a fix for cuda 3. could someone point out for me? THX!


7.5 is the cuda version, 3.0 is the compute.
Still no performance improvement for multiple GPUs at Amazon CUDA 7. cudnn 4. compute 3.0 comparing with single GPU.
anyone succeed on Cuda compute capability 2.
Verified that 'TF UNOFFICIAL SETTING 1. configure' works on a macbook pro with at GeForce GT 750M. Thanks!
Is there an ETA for the official fix? It's really a pain to maintain for example build images with our own dockerfile in production.
My laptop gives me this log when I try to run mnist sample:
 Ignoring gpu device device: name: GeForce GT 635M, pci bus id with Cuda compute capability 2. The minimum required Cuda capability is 3. 
So does this mean that I can't use GPU version because the minimum Cuda for tensorflow is 3.
Thanks
If you use the prebuilt binaries, yes. If you build from source you can
build with Cuda 2.1 support but I don't know if that actually works. It's
likely that the effective minimum is cuda 3.
On Sat, Sep 10, 2016 at 11:51 Mojtaba Tabatabaie 
wrote:















 smtabatabaie Have you tried to build cuDNN from source as suggested by martinwicke, I am facing exactly same issues as yours and it would help me a lot if you share your exprience?
Some help please. I'm getting the same error message with Ignoring visible gpu device device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0 with Cuda compute capability 3. The minimum required Cuda capability is 3. 

I've read through the posts from others, the only issue is that this is a direct windows installation and not on AWS as I'm assuming most of the people here have. In the tensorflow website, it's stated that a minimum of 3.0 is required, why am I unable to use this? and how can I get around it? 

Suggestions on how to do this welcome please. gunan mrry are the windows packages not built with cuda 3. Is that why
they are so small?
 martinwicke The nightlies are and rc1 should be too.nightlies yes.
rc0 I think was 3.
Did we cherrypick the change to use 3.0 to r0.12?We did cherrypick the change.
 cydal you may use the nightly builds at here:
 LINKLINK 

Or you can wait for 0.12.0rc1, which should be landing in a few days.Thanks guys for the quick response, I wasn't expecting one for a while at least. Sorry if this sounds like a bi of a dumb question, how do I install this? do I simply pip install it? if so, do I removed the previous tensorflow gpu? or does it do so automatically? or does it require downloading it and manually installing it in some way? consider me a bit of a newbie.The link points to a PIP package.
If you used the CODESCODES command, you should be able to use the same command with CODESCODES flag.
Or you can run CODESCODES and then install the package listed above.
Once you give pip command the URL, it will automatically download and install.

This is all I can give with limited knowledge on your system, your python distribution, etc.
Consider doing a google search for more details on how pip package installation works with your python distribution.Hi, I simply uninstalled the previous one and reinstalled and it works! Thank you so much, you saved me from buying a new laptop.Hi gunan with the latest change for 3.5 compatibility, I get following log: 
 CODELCODEL 
How can I get around it? Suggestions on how to do this most welcome. kay10 It looks like it worked. That error message on the last line is innocuous, and going to be removed in the release.As i see in this thread, everyone has a compatibility level For those who has a compability of 2, is there any solution without compiling source code? 
I tried nightly build shared by gunan and got the error:
 CODESCODES 
it is not a linux wheel and i realised it a bit soon.

Current situation on a 16.04 Ubuntu.
 I tensorflow core common runtime gpu gpu device. cc:948 Ignoring visible gpu device device: 0, name: GeForce GTX 590, pci bus id: 0000:03:00.0 with Cuda compute capability 2. The minimum required Cuda capability is 3.
I tensorflow core common runtime gpu gpu device. cc:948 Ignoring visible gpu device device: 1, name: GeForce GTX 590, pci bus id: 0000:04:00.0 with Cuda compute capability 2. The minimum required Cuda capability is 3.
  batuhandayioglugil too many of our GPU kernels rely on functionality that is only available in in 3.0 and above, so unfortunately you will need a newer GPU. You might also consider trying one of the cloud services. vrv i came to this point after spending quite time on these issues and buying a new PSU so it costed me a lot. To avoid further waste of time, i want to ask a question: there are at least 15 deep learning library that i heard. Cuda and cuDNN was necessary for tensorflow. Is this situation compute capability special for cuda library? May i have any other chances? if not, i will give up right know and go on to work with CPU Forgive my ignorence I think it will be more trouble than it's worth trying to get your 2.0 card working it's possible your existing CPU might be as fast or faster than your specific GPU, and a lot less trouble to get started. I do not know what other libraries require, unfortunately.is it already support GPU compute 3. yes. martinwicke thank you for fast response. do I still have to build it from source, or just directly pip install it? Im on Arch linux and struggle to build it from source giving error with c compiler.I think it should work from binary.I have the same problem ： Ignoring gpu device device: name: GeForce GT 635M, pci bus id with Cuda compute capability 2. The minimum required Cuda capability is 3. smtabatabaie martinwicke alphajatin. help!Compute capability 2.1 is too low to run TensorFlow. You'll need a newer or more powerful graphics card to run TensorFlow on a GPU.The url of answer to the question is invalid. Can you update it?For nightly pip packages, recommended way to install is to use CODESCODES command.
ci. tensorflow. org is deprecated.